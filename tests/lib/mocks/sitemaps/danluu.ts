//
//
// as of : Thu Feb  3 19:27:00 CST 2022
// curl https://danluu.com/sitemap.xml >> danluu.ts
export const sitemap = `
<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
  <url>
    <loc>https://danluu.com/cocktail-ideas/</loc>
    <lastmod>2022-02-02T00:00:00+00:00</lastmod>
  </url>
  <url>
    <loc>https://danluu.com/cgroup-throttling/</loc>
    <lastmod>2021-12-18T00:00:00+00:00</lastmod>
  </url>
  <url>
    <loc>https://danluu.com/writing-non-advice/</loc>
    <lastmod>2021-12-13T00:00:00+00:00</lastmod>
  </url>
  <url>
    <loc>https://danluu.com/latency-pitfalls/</loc>
    <lastmod>2021-12-06T00:00:00+00:00</lastmod>
  </url>
  <url>
    <loc>https://danluu.com/corrections/</loc>
    <lastmod>2021-11-22T00:00:00+00:00</lastmod>
  </url>
  <url>
    <loc>https://danluu.com/people-matter/</loc>
    <lastmod>2021-11-15T00:00:00+00:00</lastmod>
  </url>
  <url>
    <loc>https://danluu.com/culture/</loc>
    <lastmod>2021-11-08T00:00:00+00:00</lastmod>
  </url>
  <url>
    <loc>https://danluu.com/look-stupid/</loc>
    <lastmod>2021-10-21T00:00:00+00:00</lastmod>
  </url>
  <url>
    <loc>https://danluu.com/learn-what/</loc>
    <lastmod>2021-10-18T00:00:00+00:00</lastmod>
  </url>
  <url>
    <loc>https://danluu.com/productivity-velocity/</loc>
    <lastmod>2021-10-15T00:00:00+00:00</lastmod>
  </url>
  <url>
    <loc>https://danluu.com/in-house/</loc>
    <lastmod>2021-09-29T00:00:00+00:00</lastmod>
  </url>
  <url>
    <loc>https://danluu.com/why-benchmark/</loc>
    <lastmod>2021-08-27T00:00:00+00:00</lastmod>
  </url>
  <url>
    <loc>https://danluu.com/essential-complexity/</loc>
    <lastmod>2020-12-29T00:00:00+00:00</lastmod>
  </url>
  <url>
    <loc>https://danluu.com/car-safety/</loc>
    <lastmod>2020-06-30T00:06:34-07:00</lastmod>
  </url>
  <url>
    <loc>https://danluu.com/voyager-story/</loc>
    <lastmod>2020-06-02T00:05:34-07:00</lastmod>
  </url>
  <url>
    <loc>https://danluu.com/tracing-analytics/</loc>
    <lastmod>2020-05-31T00:06:34-07:00</lastmod>
  </url>
  <url>
    <loc>https://danluu.com/metrics-analytics/</loc>
    <lastmod>2020-05-30T00:06:34-07:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/corp-eng-blogs/</loc>
    <lastmod>2020-03-11T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/cli-complexity/</loc>
    <lastmod>2020-03-03T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/discontinuities/</loc>
    <lastmod>2020-02-18T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/p95-skill/</loc>
    <lastmod>2020-02-07T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/algorithms-interviews/</loc>
    <lastmod>2020-01-05T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/deconstruct-files/</loc>
    <lastmod>2019-07-12T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/overwatch-gender/</loc>
    <lastmod>2019-02-19T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/fsyncgate/</loc>
    <lastmod>2018-03-28T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/input-lag/</loc>
    <lastmod>2017-12-24T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/bad-decisions/</loc>
    <lastmod>2017-11-21T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/android-updates/</loc>
    <lastmod>2017-11-12T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/ui-compatibility/</loc>
    <lastmod>2017-11-09T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/filesystem-errors/</loc>
    <lastmod>2017-10-23T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/keyboard-latency/</loc>
    <lastmod>2017-10-16T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/branch-prediction/</loc>
    <lastmod>2017-08-23T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/sattolo/</loc>
    <lastmod>2017-08-09T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/term-latency/</loc>
    <lastmod>2017-07-18T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/keyboard-v-mouse/</loc>
    <lastmod>2017-06-13T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/startup-options/</loc>
    <lastmod>2017-06-07T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/web-bloat/</loc>
    <lastmod>2017-02-08T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/hn-comments/</loc>
    <lastmod>2016-10-23T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/programming-books/</loc>
    <lastmod>2016-10-16T01:06:34-07:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/hiring-lemons/</loc>
    <lastmod>2016-10-09T02:44:14-07:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/sounds-easy/</loc>
    <lastmod>2016-10-03T01:14:27-07:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/bimodal-compensation/</loc>
    <lastmod>2016-09-26T23:33:26-07:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/learning-to-program/</loc>
    <lastmod>2016-09-12T01:41:26-07:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/concurrency-bugs/</loc>
    <lastmod>2016-08-04T20:32:26-07:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/programming-blogs/</loc>
    <lastmod>2016-04-18T00:06:34-07:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/google-sre-book/</loc>
    <lastmod>2016-04-11T01:00:58-07:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/programmer-moneyball/</loc>
    <lastmod>2016-03-21T00:23:44-07:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/su3su2u1/hpmor/</loc>
    <lastmod>2016-03-01T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/su3su2u1/physics/</loc>
    <lastmod>2016-03-01T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/perf-tracing/</loc>
    <lastmod>2016-01-24T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/cpu-bugs/</loc>
    <lastmod>2016-01-10T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/wat/</loc>
    <lastmod>2015-12-29T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/startup-tradeoffs/</loc>
    <lastmod>2015-12-17T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/file-consistency/</loc>
    <lastmod>2015-12-12T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/why-ecc/</loc>
    <lastmod>2015-11-27T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/butler-lampson-1999/</loc>
    <lastmod>2015-11-23T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/infinite-disk/</loc>
    <lastmod>2015-11-01T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/intel-cat/</loc>
    <lastmod>2015-10-04T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/limplock/</loc>
    <lastmod>2015-09-30T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/yegge-predictions/</loc>
    <lastmod>2015-08-31T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/postmortem-lessons/</loc>
    <lastmod>2015-08-20T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/slashdot-sourceforge/</loc>
    <lastmod>2015-05-31T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/googlebot-monopoly/</loc>
    <lastmod>2015-05-27T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/boring-languages/</loc>
    <lastmod>2015-05-25T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/monorepo/</loc>
    <lastmod>2015-05-17T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/dunning-kruger/</loc>
    <lastmod>2015-03-29T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/testing/</loc>
    <lastmod>2015-03-10T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/navigate-url/</loc>
    <lastmod>2015-03-07T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/percentile-latency/</loc>
    <lastmod>2015-03-05T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/customer-service/</loc>
    <lastmod>2015-02-15T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/cpu-backdoors/</loc>
    <lastmod>2015-02-03T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/blog-ads/</loc>
    <lastmod>2015-01-24T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/new-cpu-features/</loc>
    <lastmod>2015-01-11T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/julialang/</loc>
    <lastmod>2014-12-28T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/integer-overflow/</loc>
    <lastmod>2014-12-17T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/malloc-tutorial/</loc>
    <lastmod>2014-12-04T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/tech-discrimination/</loc>
    <lastmod>2014-12-01T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/linux-devs-say/</loc>
    <lastmod>2014-11-24T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/everything-is-broken/</loc>
    <lastmod>2014-11-18T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/octopress-speedup/</loc>
    <lastmod>2014-11-17T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/broken-builds/</loc>
    <lastmod>2014-11-10T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/empirical-pl/</loc>
    <lastmod>2014-11-07T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/clwb-pcommit/</loc>
    <lastmod>2014-11-05T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/2choices-eviction/</loc>
    <lastmod>2014-11-03T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/tests-v-reason/</loc>
    <lastmod>2014-11-03T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/assembly-intrinsics/</loc>
    <lastmod>2014-10-19T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/google-wage-fixing/</loc>
    <lastmod>2014-08-14T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/bugalytics/</loc>
    <lastmod>2014-04-06T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/edit-binary/</loc>
    <lastmod>2014-03-23T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/gender-gap/</loc>
    <lastmod>2014-03-09T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/anon-benchmark/</loc>
    <lastmod>2014-03-05T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/teach-debugging/</loc>
    <lastmod>2014-02-08T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/math-bias/</loc>
    <lastmod>2014-01-09T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/3c-conflict/</loc>
    <lastmod>2014-01-02T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/linear-hammer/</loc>
    <lastmod>2013-12-13T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/hardware-unforgiving/</loc>
    <lastmod>2013-11-10T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/discourage-oss/</loc>
    <lastmod>2013-10-27T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/randomize-hn/</loc>
    <lastmod>2013-10-04T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/pl-troll/</loc>
    <lastmod>2013-09-15T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/why-hardware-development-is-hard/</loc>
    <lastmod>2013-09-07T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/about/</loc>
    <lastmod>2013-09-01T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/latency-mitigation/</loc>
    <lastmod>2013-03-05T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/karajack/</loc>
    <lastmod>2013-02-12T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/open-social-networks/</loc>
    <lastmod>2010-01-01T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/mit-stanford/</loc>
    <lastmod>2010-01-01T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/symbolics-lisp-machines/</loc>
    <lastmod>2007-11-16T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/subspace-history/</loc>
    <lastmod>2006-02-01T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/glenn-henry-interview/</loc>
    <lastmod>2004-06-09T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/threads-faq/</loc>
    <lastmod>2001-08-01T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/risc-definition/</loc>
    <lastmod>2001-07-29T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/norstad/risk-time/</loc>
    <lastmod>2000-04-01T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/microsoft-culture/</loc>
    <lastmod>2000-01-01T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/mcilroy-unix/</loc>
    <lastmod>1978-08-01T00:00:00+00:00</lastmod>
  </url>
  
  <url>
    <loc>https://danluu.com/</loc>
    <lastmod>2022-02-02T00:00:00+00:00</lastmod>
    <priority>0</priority>
  </url>
  
  <url>
    <loc>https://danluu.com/popular/</loc>
  </url>
  
  <url>
    <loc>https://danluu.com/bridge/</loc>
    <priority>0</priority>
  </url>
  
  <url>
    <loc>https://danluu.com/bridge/meckwell-lite/</loc>
  </url>
  
  <url>
    <loc>https://danluu.com/norstad/</loc>
    <lastmod>2000-04-01T00:00:00+00:00</lastmod>
    <priority>0</priority>
  </url>
  
  <url>
    <loc>https://danluu.com/post/</loc>
    <lastmod>2022-02-02T00:00:00+00:00</lastmod>
    <priority>0</priority>
  </url>
  
  <url>
    <loc>https://danluu.com/su3su2u1/</loc>
    <lastmod>2016-03-01T00:00:00+00:00</lastmod>
    <priority>0</priority>
  </url>
  
</urlset>`;

// as of : Thu Feb  3 19:27:00 CST 2022
// curl https://danluu.com/atom.xml >> danluu.ts # actual an RSS feed
export const rss = `<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <link>https://danluu.com/atom/index.xml</link>
    <description>Recent content on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 02 Feb 2022 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://danluu.com/atom/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Cocktail party ideas</title>
      <link>https://danluu.com/cocktail-ideas/</link>
      <pubDate>Wed, 02 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://danluu.com/cocktail-ideas/</guid>
      <description>

&lt;p&gt;You don&#39;t have to be at party to see this phenomenon in action, but there&#39;s a curious thing I regularly see at parties in social circles where people value intelligence and cleverness without similarly valuing on-the-ground knowledge or intellectual rigor. People often discuss the standard trendy topics (some recent ones I&#39;ve observed at multiple parties are how to build a competitor to Google search and how to solve the problem of high transit construction costs) and explain why people working in the field today are doing it wrong and then explain how they would do it instead. I occasionally have good conversations that fit that pattern (with people with very deep expertise in the field who&#39;ve been working on changing the field for years), but the more common pattern is that someone with cocktail-party level knowledge of a field will give their ideas on how the field can be fixed.&lt;/p&gt;

&lt;p&gt;Asking people why they think their solutions would solve valuable problems in the field has become a hobby of mine when I&#39;m at parties where this kind of superficial pseudo-technical discussion dominates the party. What I&#39;ve found when I&#39;ve asked for details is that, in areas where I have some knowledge, people &lt;a href=&#34;https://danluu.com/sounds-easy/&#34;&gt;generally don&#39;t know what sub-problems need to be solved to solve the problem they&#39;re trying to address, making their solution hopeless&lt;/a&gt;. After having done this many times, my opinion is that the root cause of this is generally that many people who have a superficial understanding of topic assume that the topic is as complex as their understanding of the topic instead of realizing that only knowing a bit about a topic means that they&#39;re missing an understanding of the full complexity of a topic.&lt;/p&gt;

&lt;p&gt;Since I often attend parties with programmers, this means I often hear programmers retelling their cocktail-party level understanding of another field (the search engine example above notwithstanding). If you want a sample of similar comments online, you can often see these when programmers discuss &amp;quot;trad&amp;quot; engineering fields. An example I enjoyed was &lt;a href=&#34;https://twitter.com/danluu/status/1162469763374673920&#34;&gt;this Twitter thread where Hillel Wayne discussed how programmers without knowledge of trad engineering often have incorrect ideas about what trad engineering is like&lt;/a&gt;, where many of the responses are from programmers with little to no knowledge of trad engineering who then reply to Hillel with their misconceptions. When Hillel completed his &lt;a href=&#34;https://www.hillelwayne.com/tags/crossover-project/&#34;&gt;crossover project&lt;/a&gt;, where he interviewed people who&#39;ve worked in a trad engineering field as well as in software, &lt;a href=&#34;https://twitter.com/danluu/status/1484268111687663620&#34;&gt;he got even more such comments&lt;/a&gt;. Even when people are warned that naive conceptions of a field are likely to be incorrect, many can&#39;t help themselves and they&#39;ll immediately reply with their opinions about a field they know basically nothing about.&lt;/p&gt;

&lt;p&gt;Anyway, in the crossover project, Hillel compared the perceptions of people who&#39;d actually worked in multiple fields to pop-programmer perceptions of trad engineering. One of the many examples of this that Hillel gives is when people talk about bridge building, where he notes that programmers say things like&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The predictability of a true engineer’s world is an enviable thing. But ours is a world always in flux, where the laws of physics change weekly. If we did not quickly adapt to the unforeseen, the only foreseeable event would be our own destruction.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;No one thinks about moving the starting or ending point of the bridge midway through construction.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But Hillel interviewed a civil engineer who said that they had to move a bridge! Of course, civil engineers don&#39;t move bridges as frequently as programmers deal with changes in software but, if you talk to actual, working, civil engineers, many civil engineers frequently deal with changing requirements after a job has started that&#39;s not fundamentally different from what programmers have to deal with at their jobs. People who&#39;ve worked in both fields or at least talk to people in the other field tend to think the concerns faced by engineers in both fields are complex, but people with a cocktail-party level of understanding of the field often claim that the field they&#39;re not in is simple, unlike their field.&lt;/p&gt;

&lt;p&gt;A line I often hear from programmers is that programming is like &amp;quot;having to build a plane while it&#39;s flying&amp;quot;, implicitly making the case that programming is harder than designing and building a plane since people who design and build planes can do so before the plane is flying&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:N&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:N&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. But, of course, someone who designs airplanes could just as easily say &amp;quot;gosh, my job would be very easy if I could build planes with 4 9s of uptime and my plane were allowed to crash and kill all of the passengers for 1 minute every week&amp;quot;. Of course, the constraints on different types of projects and different fields make different things hard, but people often seem to have a hard time seeing constraints other fields have that their field doesn&#39;t. One might think that understanding that their own field is more complex than an outsider might naively think would help people understand that other fields may also have hidden complexity, but that doesn&#39;t generally seem to be the case.&lt;/p&gt;

&lt;p&gt;If we look at the rest of the statement Hillel was quoting (which is from the top &amp;amp; accepted answer to a stack exchange question), the author goes on to say:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It&#39;s much easier to make accurate projections when you know in advance exactly what you&#39;re being asked to project rather than making guesses and dealing with constant changes.&lt;/p&gt;

&lt;p&gt;The vast majority of bridges are using extremely tried and true materials, architectures, and techniques. A Roman engineer could be transported two thousand years into the future and generally recognize what was going on at a modern construction site. There would be differences, of course, but you&#39;re still building arches for load balancing, you&#39;re still using many of the same materials, etc. Most software that is being built, on the other hand . . .&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is typical of the kind of error people make when they&#39;re discussing cocktail-party ideas. Programmers legitimately gripe when clueless execs who haven&#39;t been programmers for a decade request unreasonable changes to a project that&#39;s in progress, but this is not so different and actually more likely to be reasonable than when politicians who&#39;ve never been civil engineers require project changes on large scale civil engineering projects. It&#39;s plausible that, on average, programming projects have more frequent or larger changes to the project than civil engineering projects, I&#39;d guess that the intra-field variance is at least as large as the inter-field variance.&lt;/p&gt;

&lt;p&gt;And, of course, only someone who hasn&#39;t done serious engineering work in the physical world could say something like &amp;quot;The predictability of a true engineer’s world is an enviable thing. But ours is a world always in flux, where the laws of physics change weekly&amp;quot;, thinking that the (relative) fixity of physical laws means that physical work is predictable. When I worked as a hardware engineer, a large fraction of the effort and complexity of my projects went into dealing with physical uncertainty and civil engineering is no different (if anything, the tools civil engineers have to deal with physical uncertainty on large scale projects are much worse, resulting in a larger degree of uncertainty and a reduced ability to prevent delays due to uncertainty).&lt;/p&gt;

&lt;p&gt;If we look at how Roman engineering or even engineering from 300 years ago differs from modern engineering, a major source of differences is our much better understanding of uncertainty that comes from the physical world. It didn&#39;t used to be shocking when a structure failed not too long after being built without any kind of unusual conditions or stimulus (e.g., building collapse, or train accident due to incorrectly constructed rail). This is now rare enough that it&#39;s major news if it happens in the U.S. or Canada and this understanding also lets us build gigantic structures in areas where it would have been previously considered difficult or impossible to build moderate-sized structures.&lt;/p&gt;

&lt;p&gt;For example, if you look at a large-scale construction project in the Vancouver area that&#39;s sitting on the delta (Delta, Richmond, much of the land going out towards Hope), it&#39;s only relatively recently that we discovered the knowledge necessary to build some large scale structures (e.g., tall-ish buildings) reliably on that kind of ground, which is one of the many parts of modern civil engineering a Roman engineer wouldn&#39;t understand. A lot of this comes from a field called geotechnical engineering, a sub-field of civil engineering (alternately, arguably its own field and also arguably a subfield of geological engineering) that involves the ground, i.e., soil mechanics, rock mechanics, geology, hydrology, and so on and so forth. One fundamental piece of geotechnical engineering is the idea that you can apply &lt;a href=&#34;https://en.wikipedia.org/wiki/Mechanics&#34;&gt;mechanics&lt;/a&gt; to reason about soil. The first known application of mechanics to soils, a fundamental part of geotechnical engineering, was in 1773 and geotechnical engineering as it&#39;s thought of today is generally said to have started in 1925. While Roman engineers did a lot of impressive work, &lt;a href=&#34;https://www.patreon.com/posts/61946482&#34;&gt;the mental models they were operating with precluded understanding much of modern civil engineering&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Naturally, for this knowledge to have been able to change what we can build, it must change how we build. If we look at what a construction site on  compressible Vancouver delta soils that uses this modern knowledge looks like, by wall clock time, it mostly looks like someone put a pile of sand on the construction site (preload). While a Roman engineer would know what a pile of sand is, they wouldn&#39;t know how someone figured out how much sand was needed and how long it needed to be there (in some cases, Romans would use piles or rafts where we would use preload today, but in many cases, they had no answer to the problems preload solves today).&lt;/p&gt;

&lt;p&gt;Geotechnical engineering and the resultant pile of sand (preload)  is one of tens of sub-fields where you&#39;d need expertise when doing a modern, large scale, civil engineering project that a Roman engineer would need a fair amount of education to really understand.&lt;/p&gt;

&lt;p&gt;Coming back to cocktail party solutions I hear, one common set of solutions is how to fix high construction costs and slow construction. There&#39;s a set of trendy ideas that people throw around about why things are so expensive, why projects took longer than projected, etc. Sometimes, these comments are similar to what I hear from practicing engineers that are involved in the projects but, more often than not, the reasons are pretty different. When the reasons are the same, it seems that &lt;a href=&#34;https://twitter.com/danluu/status/1420866014493822980&#34;&gt;they must be correct by coincidence since they don&#39;t seem to understand the body of knowledge necessary to reason through the engineering tradeoffs&lt;/a&gt;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:D&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:D&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Of course, like cocktail party theorists, &lt;a href=&#34;https://twitter.com/danluu/status/1483162978224463872&#34;&gt;civil engineers with expertise in the field also think that modern construction is wasteful&lt;/a&gt;, but the reasons they come up with are often quite different from what I hear at parties&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:C&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:C&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;. It&#39;s easy to come up with cocktail party solutions to problems by not understanding the problem, assuming the problem is artificially simple, and then coming up with a solution to the imagined problem. It&#39;s harder to understand the tradeoffs in play among the tens of interacting engineering sub-fields required to do large scale construction projects and have an actually relevant discussion of what the tradeoffs should be and how one might motivate engineers and policy makers to shift where the tradeoffs land.&lt;/p&gt;

&lt;p&gt;A widely cited study on the general phenomena of people having wildly oversimplified and incorrect models of how things work is &lt;a href=&#34;https://link.springer.com/content/pdf/10.3758/BF03195929.pdf&#34;&gt;this study by Rebecca Lawson on people&#39;s understanding of how bicycles work&lt;/a&gt;, which notes:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Recent research has suggested that people often overestimate their ability to explain how things function. Rozenblit and Keil (2002) found that people overrated their understanding of complicated phenomena. This illusion of explanatory depth was not merely due to general overconfidence; it was specific to the understanding of causally complex systems, such as artifacts (crossbows, sewing machines, microchips) and natural phenomena (tides, rainbows), relative to other knowledge domains, such as facts (names of capital cities), procedures (baking cakes), or narratives (movie plots).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It would be unsurprising if nonexperts had failed to explain the intricacies of how gears work or why the angle of the front forks of a bicycle is critical. Indeed, even physicists disagree about seemingly simple issues, such as why bicycles are stable (Jones, 1970; Kirshner, 1980) and how they steer (Fajans, 2000). What is striking about the present results is that so many people have virtually no knowledge of how bicycles function.​​&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In &amp;quot;experiment 2&amp;quot; in the study, people were asked to draw a working bicycle and focus on the mechanisms that make the bicycle work (as opposed to making the drawing look nice) and 60 of the 94 participants had at least one gross error that caused the drawing to not even resemble a working bicycle. If we look at a large-scale real-world civil engineering project, a single relevant subfield, like geotechnical engineering, contains many orders of magnitude more complexity than a bicycle and it&#39;s pretty safe to guess that, to the nearest percent, zero percent of lay people (or Roman engineers) could roughly sketch out what the relevant moving parts are.&lt;/p&gt;

&lt;p&gt;For a non-civil engineering example, Jamie Brandon quotes this excerpt from &lt;a href=&#34;https://amzn.to/3HrzkSc&#34;&gt;Jim Manzi&#39;s Uncontrolled&lt;/a&gt;, which is a refutation of a &amp;quot;clever&amp;quot; nugget that I&#39;ve frequently heard trotted out at parties:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The paradox of choice is a widely told folktale about a single experiment in which putting more kinds of jam on a supermarket display resulted in less purchases. The given explanation is that choice is stressful and so some people, facing too many possible jams, will just bounce out entirely and go home without jam. This experiment is constantly cited in news and media, usually with descriptions like &amp;quot;scientists have discovered that choice is bad for you&amp;quot;.
But if you go to a large supermarket you will see approximately 12 million varieties of jam. Have they not heard of the jam experiment? Jim Manzi relates in &lt;a href=&#34;https://amzn.to/3HrzkSc&#34;&gt;Uncontrolled&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;First, note that all of the inference is built on the purchase of a grand total of thirty-five jars of jam. Second, note that if the results of the jam experiment were valid and applicable with the kind of generality required to be relevant as the basis for economic or social policy, it would imply that many stores could eliminate 75 percent of their products and cause sales to increase by 900 percent. That would be a fairly astounding result and indicates that there may be a problem with the measurement.&lt;/p&gt;

&lt;p&gt;... the researchers in the original experiment themselves were careful about their explicit claims of generalizability, and significant effort has been devoted to the exact question of finding conditions under which choice overload occurs consistently, but popularizers telescoped the conclusions derived from one coupon-plus-display promotion in one store on two Saturdays, up through assertions about the impact of product selection for jam for this store, to the impact of product selection for jam for all grocery stores in America, to claims about the impact of product selection for all retail products of any kind in every store, ultimately to fairly grandiose claims about the benefits of choice to society. But as we saw, testing this kind of claim in fifty experiments in different situations throws a lot of cold water on the assertion.&lt;/p&gt;

&lt;p&gt;As a practical business example, even a simplification of the causal mechanism that comprises a useful forward prediction rule is unlikely to be much like &#39;Renaming QwikMart stores to FastMart will cause sales to rise,&#39; but will instead tend to be more like &#39;Renaming QwikMart stores to FastMart in high-income neighborhoods on high-traffic roads will cause sales to rise, as long as the store is closed for painting for no more than two days.&#39; It is extremely unlikely that we would know all of the possible hidden conditionals before beginning testing, and be able to design and execute one test that discovers such a condition-laden rule.&lt;/p&gt;

&lt;p&gt;Further, these causal relationships themselves can frequently change. For example, we discover that a specific sales promotion drives a net gain in profit versus no promotion in a test, but next year when a huge number of changes occurs - our competitors have innovated with new promotions, the overall economy has deteriorated, consumer traffic has shifted somewhat from malls to strip centers, and so on - this rule no longer holds true. To extend the prior metaphor, we are finding our way through our dark room by bumping our shins into furniture, while unobserved gremlins keep moving the furniture around on us. For these reasons, it is not enough to run an experiment, find a causal relationship, and assume that it is widely applicable. We must run tests and then measure the actual predictiveness of the rules developed from these tests in actual implementation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;p&gt;So far, we&#39;ve discussed examples of people with no background in a field explaining how a field works or should work, but the error of taking a high-level view and incorrectly assuming that things are simple also happens when people step back and have a high-level view of their own field that&#39;s disconnected from the details. For example, back when I worked at Centaur and we&#39;d not yet shipped a dual core chip, a nearly graduated PhD student in computer architecture from a top school asked me, &amp;quot;why don&#39;t you just staple two cores together to make a dual core chip like Intel and AMD? That&#39;s an easy win&amp;quot;.&lt;/p&gt;

&lt;p&gt;At that time, we&#39;d already been working on going from single core to multi core for more than one year. Making a single core chip multi-core or even multi-processor capable with decent performance requires significant additional complexity to the cache and memory hierarchy, the most logically complex part of the chip. As a rough estimate, I would guess that taking a chip designed for single-core use and making it multi-processor capable at least doubles the amount of testing/verification effort required to produce a working chip (and the majority of the design effort that goes into a chip is on testing/verification). More generally, a computer architect is only as good as their understanding of the tradeoffs their decisions impact. Great ones have a strong understanding of the underlying fields they must interact with. A common reason that a computer architect will make a bad decision is that they have a cocktail party level understanding of the fields that are one or two levels below computer architecture. An example of a bad decision that&#39;s occurred multiple times in industry is when a working computer architect decides to add &lt;a href=&#34;https://en.wikipedia.org/wiki/Simultaneous_multithreading&#34;&gt;SMT&lt;/a&gt; to a chip because it&#39;s basically a free win. You pay a few percent extra area and get perhaps 20% better performance. I know of multple attempts to do this that completely failed for predictable reasons because the architect failed to account for the complexity and verification cost of adding SMT. Adding SMT adds much more complexity than adding a second core because the logic has to be plumbed through everything and it causes an explosion in the complexity of verifying the chip for the same reason. Intel famously added SMT to the P4 and did not enable in the first generation it was shipped in because it was too complex to verify in a single generation and had critical, showstopping, bugs. With the years of time they had to shake the bugs out on one generation of architeecture, they fixed their SMT implementation and shipped it in the next generation of chip. This happened again when they migrated to the Core architecture and added SMT to that. A working computer architect should know that this happened twice to Intel, implying that verifying an SMT implementation is hard, and yet there have been multiple instances where someone had a cocktail party level of understanding of the complexity of SMT and suggested adding it to a design that did not have the verification budget to ever ship a working chip with SMT.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/&#34;&gt;And, of course, this isn&#39;t really unique to computer architecture&lt;/a&gt;. I used the dual core example because it&#39;s one that happens to currently be top-of-mind for me, but I can think of tens of similar &lt;a href=&#34;https://twitter.com/danluu/status/814167684954738688&#34;&gt;examples&lt;/a&gt; off the top of my head and I&#39;m pretty sure I could write up a few hundred examples if I spent a few days thinking about similar examples. &lt;a href=&#34;https://twitter.com/altluu/status/1484589911873261568&#34;&gt;People working in a field still have to be very careful to avoid having an incorrect, too abstract, view of the world that elides details and draws comically wrong inferences or conclusions as a result&lt;/a&gt;. When people outside a field explain how things should work, their explanations are generally even worse than someone in the field who missed a critical consideration and &lt;a href=&#34;https://www.patreon.com/posts/54329188&#34;&gt;they generally present&lt;/a&gt; &lt;a href=&#34;https://yosefk.com/blog/the-high-level-cpu-challenge.html&#34;&gt;crank ideas&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Bringing together the Roman engineering example and the CPU example, going from 1 core to 2 (and, in general, going from 1 to 2, as in 1 datacenter to 2 datacenters or a monolith to a distributed system) is something every practitioner should understand is hard, even if some don&#39;t. Somewhat relatedly, if someone showed off a 4 THz processor that had 1000x the performance of a 4 GHz processor, that&#39;s something any practitioner should recognize as alien technology that they definitely do not understand. Only a lay person with no knowledge of the field could reasonably think to themselves, &amp;quot;it&#39;s just a processor running at 1000x the clock speed; an engineer who can make a 4 GHz process would basically understand how a 4 THz processor with 1000x the performance works&amp;quot;. We are so far from being able to scale up performance by 1000x by running chips 1000x faster that doing so would require many fundamental breakthroughs in technology and, most likely, the creation of entirely new fields that contain more engineering knowledge than exists in the world today. Similarly, only a lay person could look at Roman engineering and modern civil engineering and think &amp;quot;Romans built things and we build things that are just bigger and more varied; a Roman engineer should be able to understand how we build things today because the things are just bigger&amp;quot;. Geotechnical engineering alone contains more engineering knowledge than existed in all engineering fields combined in the Roman era and it&#39;s only one of the &lt;a href=&#34;https://www.patreon.com/posts/61946482&#34;&gt;new fields that had to be invented to allow building structures like we can build today&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Of course, I don&#39;t expect random programmers to understand geotechnical engineering, but I would hope that someone who&#39;s making a comparison between programming and civil engineering would at least have some knowledge of civil engineering and not just assume that the amount of knowledge that exists in the field is roughly equal to their knowledge of the field when they know basically nothing about the field.&lt;/p&gt;

&lt;p&gt;Although &lt;a href=&#34;https://www.patreon.com/posts/60185075&#34;&gt;I seem to try a lot harder than most folks to avoid falling into the trap of thinking something is simple because I don&#39;t understand it&lt;/a&gt;, I still fall prey to this all the time and the best things I&#39;ve come up with to prevent this, while better than nothing, are not reliable.&lt;/p&gt;

&lt;p&gt;One part of this is that I&#39;ve tried to cultivate noticing &amp;quot;the feeling of glossing over something without really understanding it&amp;quot;. I think of this is analogous to (and perhaps it&#39;s actually the same thing as) something that&#39;s become trendy over the past twenty years, paying attention to how emotions feel in your body and understanding your emotional state by noticing feelings in your body, e.g., a certain flavor of tight feeling in a specific muscle is a sure sign that I&#39;m angry.&lt;/p&gt;

&lt;p&gt;There&#39;s a specific feeling I get in my body when I have a fuzzy, high-level, view of something and am mentally glossing over it. I can easily miss it if I&#39;m not paying attention and I suspect I can also miss it when I gloss over something in a way where the non-conscious part of the brain that generates the feeling doesn&#39;t even know that I&#39;m glossing over something. Although noticing this feeling is inherently unreliable, I think that everything else I might do that&#39;s self contained to check my own reasoning fundamentally relies on the same mechanism (e.g., if I have a checklist to try to determine if I haven&#39;t glossed over something when I&#39;m reasoning about a topic, some part of that process will still rely on feeling or intuition). I do try to postmortem cases where I missed the feeling to figure out happened, and that&#39;s basically how I figured out that I have a feeling associated with this error in the first place (I thought about what led up to this class of mistake in the past and noticed that I have a feeling that&#39;s generally associated with it), but that&#39;s never going to perfect or even &lt;a href=&#34;https://danluu.com/p95-skill/&#34;&gt;very good&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Another component is doing what I think of as &amp;quot;checking inputs into my head&amp;quot;. When I was in high school, I noticed that a pretty large fraction of the &amp;quot;obviously wrong&amp;quot; things I said came from letting incorrect information into my head. I didn&#39;t and still don&#39;t have a good, cheap, way to tag a piece of information with how reliable it is, so I find it much easier to either fact-check or discard information on consumption.&lt;/p&gt;

&lt;p&gt;Another thing I try to do is &lt;a href=&#34;https://danluu.com/writing-non-advice/#appendix-getting-feedback&#34;&gt;get feedback&lt;/a&gt;, which is unreliable and also intractable in the general case since the speed of getting feedback is so much slower than the speed of thought that slowing down general thought to the speed of feedback would result in having relatively few thoughts&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:W&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:W&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Although, &lt;a href=&#34;https://danluu.com/teach-debugging/&#34;&gt;unlike in some areas, there&#39;s no mechanical, systematic, set of steps&lt;/a&gt; that can be taught that will solve the problem, I do think this is something that can be practiced and improved and there are some fields where similar skills are taught (often implicitly). For example, when discussing the prerequisites for an advanced or graduate level textbook, it&#39;s not uncommon to see a book say something like &amp;quot;Self contained. No prerequisites other than mathematical maturity&amp;quot;. This is a shorthand way of saying &amp;quot;This book doesn&#39;t require you to know any particular mathematical knowledge that a high school student wouldn&#39;t have picked up, but you do need to have ironed out a kind of fuzzy thinking that almost every untrained person has when it comes to interpreting and understanding mathematical statements&amp;quot;. Someone with a math degree will have a bunch of explicit knowledge in their head about things like &lt;a href=&#34;https://en.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality&#34;&gt;Cauchy-Schwarz inequality&lt;/a&gt; and the &lt;a href=&#34;https://en.wikipedia.org/wiki/Bolzano%E2%80%93Weierstrass_theorem&#34;&gt;Bolzano-Weierstrass theorem&lt;/a&gt;, but the important stuff for being able to understand the book isn&#39;t the explicit knowledge, but the general way one thinks about math.&lt;/p&gt;

&lt;p&gt;Although there isn&#39;t really a term for the equivalent of mathematical rigor in other fields, e.g., people don&#39;t generally refer to &amp;quot;systems designs rigor&amp;quot; as something people look for in &lt;a href=&#34;https://twitter.com/danluu/status/1470890504833228801&#34;&gt;systems design interviews&lt;/a&gt; (at least in software; rigor in systems design is a term civil and environmental engineers sometimes use), the analogous skill exists even though it doesn&#39;t have a name. And likewise for just thinking about topics where one isn&#39;t a trained expert, like a non-civil engineer thinking about why a construction project cost what it did and took as long as it did, a sort of general rigor of thought&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:R&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:R&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Thanks to &lt;font size=+1&gt;&lt;b&gt;&lt;a rel=&#34;sponsored&#34; href =&#34;https://www.reforge.com/all-programs?utm_source=danluu&amp;utm_medium=referral&amp;utm_campaign=spring22_newsletter_test&amp;utm_term=&amp;utm_content=engineering&#34;&gt;Reforge - Engineering Programs&lt;/a&gt;&lt;/b&gt;&lt;/font&gt; and &lt;font size=+1&gt;&lt;b&gt;&lt;a rel=&#34;sponsored&#34; href =&#34;https://flatironsdevelopment.com/&#34;&gt;Flatirons Development&lt;/a&gt;&lt;/b&gt;&lt;/font&gt; for helping to make this post possible by &lt;a href=&#34;https://patreon.com/danluu&#34;&gt;sponsoring me at the Major Sponsor tier&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Also, thanks to Pam Wolf, Ben Kuhn, Yossi Kreinin, Fabian Giesen, Laurence Tratt, Danny Lynch, and Justin Blank for comments/corrections discussion.&lt;/p&gt;

&lt;h4 id=&#34;appendix-related-discussions&#34;&gt;Appendix: related discussions&lt;/h4&gt;

&lt;p&gt;An anonymous blog reader gave this example of their own battle with cocktail party ideas:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Your most recent post struck a chord with me (again!), as I have recently learned that I know basically nothing about making things cold, even though I&#39;ve been a low-temperature physicist for nigh on 10 years, now. Although I knew the broad strokes of cooling, and roughly how a dilution refrigerator works, I didn&#39;t appreciate the sheer challenge of keeping things at milliKelvin (mK) temperatures. I am the sole physicist on my team, which otherwise consists of mechanical engineers. We have found that basically every nanowatt of dissipation at the mK level matters, as does every surface-surface contact,  every material choice, and so on.&lt;/p&gt;

&lt;p&gt;Indeed, we can say that the physics of thermal transport at mK temperatures is well understood, and we can write laws governing the heat transfer as a function of temperature in such systems. They are usually written as P = aT^n. We know that different classes of transport have different exponents, n, and those exponents are well known. Of course, as you might expect, the difference between having &#39;hot&#39; qubits vs qubits at the base temperature of the dilution refrigerator (30 mK) is entirely wrapped up in the details of exactly what value of the pre-factor a happens to be in our specific systems. This  parameter can be guessed, usually to within a factor of 10, sometimes to within a factor of 2. But really, to ensure that we&#39;re able to keep our qubits cold, we need to measure those pre-factors. Things like type of fastener (4-40 screw vs M4 bolt), number of fasteners, material choice (gold? copper?), and geometry all play a huge role in the actual performance of the system. Oh also, it turns out n changes wildly as you take a metal from its normal state to its superconducting state. Fun!&lt;/p&gt;

&lt;p&gt;We have spent over a year carefully modeling our cryogenic systems, and in the process have discovered massive misconceptions held by people with 15-20 years of experience doing low-temperature measurements. We&#39;ve discovered material choices and design decisions that would&#39;ve been deemed insane had any actual thermal modeling been done to verify these designs.&lt;/p&gt;

&lt;p&gt;The funny thing is, this was mostly fine if we wanted to reproduce the results of academic labs, which mostly favored simpler experiment design, but just doesn&#39;t work as we leave the academic world behind and design towards our own purposes.&lt;/p&gt;

&lt;p&gt;P.S. Quantum computing also seems to suffer from the idea that controlling 100 qubits (IBM is at 127) is not that different from 1,000 or 1,000,000. I used to think that it was just PR bullshit and the people at these companies responsible for scaling were fully aware of how insanely difficult this would be, but after my own experience and reading you post, I&#39;m a little worried that most of them don&#39;t truly appreciate the titanic struggle ahead for us.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is just a long-winded way of saying that I have held cocktail party ideas about a field in which I have a PhD and am ostensibly an expert, so your post was very timely for me. I like to use your writing as a springboard to think about how to be better, which has been very difficult. It&#39;s hard to define what a good physicist is or does, but I&#39;m sure that trying harder to identify and grapple with the limits of my own knowledge seems like a good thing to do.&lt;/p&gt;

&lt;p&gt;For a broader and higher-level discussion of clear thinking, see Julia Galef&#39;s Scout Mindset:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;WHEN YOU THINK of someone with excellent judgment, what traits come to mind? Maybe you think of things like intelligence, cleverness, courage, or patience. Those are all admirable virtues, but there’s one trait that belongs at the top of the list that is so overlooked, it doesn’t even have an official name.&lt;/p&gt;

&lt;p&gt;So I’ve given it one. I call it scout mindset: the motivation to see things as they are, not as you wish they were.&lt;/p&gt;

&lt;p&gt;Scout mindset is what allows you to recognize when you are wrong, to seek out your blind spots, to test your assumptions and change course. It’s what prompts you to honestly ask yourself questions like “Was I at fault in that argument?” or “Is this risk worth it?” or “How would I react if someone from the other political party did the same thing?” As the late physicist Richard Feynman once said, “The first principle is that you must not fool yourself—and you are the easiest person to fool.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;As a tool to improve thought, the book has &lt;a href=&#34;https://twitter.com/danluu/status/1477789638387322880&#34;&gt;a number of chapters that give concrete checks that one can try&lt;/a&gt;, which makes it more (or at least more easily) actionable than this post, which merely suggests that you figure out what it feels like when you&#39;re glossing over something. But I don&#39;t think that the ideas in the book are a substitute for this post, in that the self-checks the book suggests don&#39;t directly attack the problem discussed in this post.&lt;/p&gt;

&lt;p&gt;In one chapter, Galef suggests leaning into confusion (e.g., if some seemingly contradictory information gives rise to a feeling of confusion), which I agree with. I would add that there are a lot of other feelings that are useful to observe that don&#39;t really have a good name. When it comes to evaluating ideas, some that I try to note, beside the already mentioned &amp;quot;the feeling that I&#39;m glossing over important details&amp;quot;, are &amp;quot;the feeling that a certain approach is likely to pay off if pursued&amp;quot;, &amp;quot;the feeling that an approach is really fraught/dangerous&amp;quot;, &amp;quot;the feeling that there&#39;s critical missing information&amp;quot;, &amp;quot;the feeling that something is really wrong&amp;quot;, along with similar feelings that don&#39;t have great names.&lt;/p&gt;

&lt;p&gt;For a discussion of how the movie Don&#39;t Look Up promotes the idea that the world is simple and we can easily find cocktail party solutions to problems, see &lt;a href=&#34;https://astralcodexten.substack.com/p/movie-review-dont-look-up&#34;&gt;this post by Scott Alexander&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Also, John Salvatier notes that &lt;a href=&#34;http://johnsalvatier.org/blog/2017/reality-has-a-surprising-amount-of-detail&#34;&gt;reality has a surprising amount of detail&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:N&#34;&gt;Another one I commonly hear is that, unlike trad engineers, &lt;a href=&#34;https://twitter.com/danluu/status/1162469760900091904&#34;&gt;programmers do things that have never been done before&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:N&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:D&#34;&gt;&lt;p&gt;Discussions about construction delays similarly ignore geotechnical reasons for delays. As with the above, I&#39;m using geotechnical as an example of a sub-field that explains many delays because it&#39;s something I happen to be familiar with, not because it&#39;s the most important thing, but it is a major cause of delays and, on many kinds of projects, the largest cause of delays.&lt;/p&gt;

&lt;p&gt;Going back to our example that a Roman engineer might, at best, superficially understand, the reason that we pile dirt onto the ground before building is that much of Vancouver has poor geotechnical conditions for building large structures. The ground is soft and will get unevenly squished down over time if something heavy is built on top of it. The sand is there as a weight, to pre-squish the ground.&lt;/p&gt;

&lt;p&gt;As described in the paragraph above, this sounds straightforward. Unfortunately, it&#39;s anything but. As it happens, I&#39;ve been spending a lot of time driving around with a geophysics engineer (a field that&#39;s related to but quite distinct from geotechnical engineering). When we drive over a funny bump or dip in the road, she can generally point out the geotechnical issue or politically motivated decision to ignore the geotechnical engineer&#39;s guidance that caused the bump to come into existence. The thing I find interesting about this is that, even though the level of de-risking done for civil engineering projects is generally much higher than is done for the electrical engineering projects I&#39;ve worked on, where in turn it&#39;s much higher than on any software project I&#39;ve worked on, enough &amp;quot;bugs&amp;quot; still make it into &amp;quot;production&amp;quot; that you can see tens or hundreds of mistakes in a day if you drive around, are knowledgeable, and pay attention.&lt;/p&gt;

&lt;p&gt;Fundamentally, the issue is that humanity does not have the technology to understand the ground at anything resembling a reasonable cost for physically large projects, like major highways. One tool that we have is to image the ground with ground penetrating radar, but this results in highly &lt;a href=&#34;https://en.wikipedia.org/wiki/Underdetermined_system&#34;&gt;underdetermined&lt;/a&gt; output. Another tool we have is to use something like a core drill or soil augur, which is basically digging down into the ground to see what&#39;s there. This also has inherently underdetermined output because we only get to see what&#39;s going on exactly where we drilled and the ground sometimes has large spatial variation in its composition that&#39;s not obvious from looking at it from the surface. A common example is when there&#39;s an unmapped remnant creek bed, which can easily &amp;quot;dodge&amp;quot; the locations where soil is sampled. Other tools also exist, but they, similarly, leave the engineer with an incomplete and uncertain view of the world when used under practical financial constraints.&lt;/p&gt;

&lt;p&gt;When I listen to cocktail party discussions of why a construction project took so long and compare it to what civil engineers tell me caused the delay, the cocktail party discussion almost always exclusively discusses reasons that civil engineers tell me are incorrect. There are many reasons for delays and &amp;quot;unexpected geotechnical conditions&amp;quot; are a common one. Civil engineers are in a bind here since drilling cores is time consuming and expensive and people get mad when they see that the ground is dug up and no &amp;quot;real work&amp;quot; is happening (and likewise when preload is applied — &amp;quot;why aren&#39;t they working on the highway?&amp;quot;), which creates pressure on politicians which indirectly results in timelines that don&#39;t allow sufficient time to understand geotechnical conditions. This sometimes results in a geotechnical surprise during a project (typically phrased as &amp;quot;unforseen geotechnical conditions&amp;quot; in technical reports), which can result in major parts of a project having to switch to slower and more expensive techniques or, even worse, can necessitate a part of a project being redone, resulting in cost and schedule overruns.&lt;/p&gt;

&lt;p&gt;I&#39;ve never heard a cocktail party discussion that discusses geotechnical reasons for project delays. Instead, people talk about high-level reasons that are plausible sounding to a lay person, but completely fabricated, reasons that are disconnected from reality. But if you want to discuss how things can be built more quickly and cheaply, &amp;quot;&lt;a href=&#34;https://www.theatlantic.com/science/archive/2019/07/we-need-new-science-progress/594946/&#34;&gt;progress studies&lt;/a&gt;&amp;quot;, etc., this cannot be reasonably done without having some understanding of the geotechnical tradeoffs that are in play (as well as the tradeoffs from other civil engineering fields we haven&#39;t discussed).&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:D&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:C&#34;&gt;&lt;p&gt;One thing we could do to keep costs under control is to do less geotechnical work and ignore geotechnical surprises up to some risk bound. Today, some of the &amp;quot;amount of work&amp;quot; done is determined by regulations and much of it is determined by case law, which gives a rough idea of what work needs to be done to avoid legal liability in case of various bad outcomes, such as a building collapse.&lt;/p&gt;

&lt;p&gt;If, instead of using case law and risk of liability to determine how much geotechnical derisking should be done, we compute this based on &lt;a href=&#34;https://en.wikipedia.org/wiki/Quality-adjusted_life_year&#34;&gt;QALYs&lt;/a&gt; per dollar, at the margin, we seem to spend a very large amount of money geotechnical derisking compared to many other interventions.&lt;/p&gt;

&lt;p&gt;This is not just true of geotechnical work and is also true of other fields in civil engineering, e.g., builders in places like the U.S. and Canada do much more slump testing than is done in some countries that have a much faster pace of construction, which reduces the risk of a building&#39;s untimely demise. It would be both scandalous and a serious liability problem if a building collapsed because the builders of the building didn&#39;t do slump testing when they would&#39;ve in the U.S. or Canada,, but buildings usually don&#39;t collapse even when builders don&#39;t do as much slump testing as tends to be done in the U.S. and Canada.&lt;/p&gt;

&lt;p&gt;Countries that don&#39;t build to standards roughly as rigorous as U.S. or Canadian standards sometimes have fairly recently built structures collapse in ways that would be considered shocking in the U.S. and Canada, but the number of lives saved per dollar is very small compared to other places the money could be spent. Whether or not we should change this with a policy decision is a more relevant discussion to building costs and timelines than the fabricated reasons I hear cocktail party discussions of construction costs, but I&#39;ve never heard this or other concrete reasons for project cost brought up outside of civil engineering circles.&lt;/p&gt;

&lt;p&gt;Even if we just confine ourselves to work that&#39;s related to civil engineering as opposed to taking a broader, more EA-minded approach, and looking QALYs for all possible interventions, the tradeoff between resources spent on derisking during construction vs. resources spent derisking on an ongoing basis (inspections, maintenance, etc.), the relative resource levels weren&#39;t determined by a process that should be expected to produce anywhere near an optimal outcome.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:C&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:W&#34;&gt;Some people suggest that writing is a good intermediate step that&#39;s quicker than getting external feedback while being more reliable than just thinking about something, but &lt;a href=&#34;https://mobile.twitter.com/danluu/status/1453454530444619778/photo/1&#34;&gt;I find writing too slow to be usable as a way to clarify ideas&lt;/a&gt; and, after working on identifying when I&#39;m having fuzzy thoughts, I find that trying to think through an idea to be more reliable as well as faster.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:W&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:R&#34;&gt;&lt;p&gt;One part of this that I think is underrated by people who have a self-image of &amp;quot;being smart&amp;quot; is where book learning and thinking about something is sufficient vs. where on-the-ground knowledge of the topic is necessary.&lt;/p&gt;

&lt;p&gt;A fast reader can read the texts one reads for most technical degrees in maybe 40-100 hours. For a slow reader, that could be much slower, but it&#39;s still not really that much time. There are some aspects of problems where this is sufficient to understand the problem and come up with good, reasonable, solutions. &lt;a href=&#34;https://danluu.com/hardware-unforgiving/&#34;&gt;And there are some aspects of problems where this is woefully inefficient and thousands of hours of applied effort are required to really be able to properly understand what&#39;s going on&lt;/a&gt;.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:R&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The container throttling problem</title>
      <link>https://danluu.com/cgroup-throttling/</link>
      <pubDate>Sat, 18 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://danluu.com/cgroup-throttling/</guid>
      <description>

&lt;p&gt;&lt;i&gt;This is an excerpt from an internal document &lt;b&gt;David Mackey&lt;/b&gt; and I co-authored in April 2019. The document is excerpted since much of the original doc was about comparing possible approaches to increasing efficency at Twitter, which is mostly information that&#39;s meaningless outside of Twitter without a large amount of additional explanation/context.&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;At Twitter, most  CPU bound services start falling over at around 50% reserved container CPU utilization and almost all services start falling over at not much more CPU utilization even though CPU bound services should, theoretically, be able to get higher CPU utilizations. Because load isn&#39;t, in general, evenly balanced across shards and the shard-level degradation in performance is so severe when we exceed 50% CPU utilization, this makes the practical limit much lower than 50% even during peak load events.&lt;/p&gt;

&lt;p&gt;This document will describe potential solutions to this problem. We&#39;ll start with describing why we should expect this problem given how services are configured and how the Linux scheduler we&#39;re using works. We&#39;ll then look into case studies on how we can fix this with config tuning for specific services, which can result in a 1.5x to 2x increase in capacity, which can translate into $[redacted]M/yr to $[redacted]M/yr in savings for large services. While this is worth doing and we might get back $[redacted]M/yr to $[redacted]M/yr in &lt;a href=&#34;https://en.wikipedia.org/wiki/Total_cost_of_ownership&#34;&gt;TCO&lt;/a&gt; by doing this for large services, manually fixing services one at a time isn&#39;t really scalable, so we&#39;ll also look at how we can make changes that can recapture some of the value for most services.&lt;/p&gt;

&lt;h3 id=&#34;the-problem-in-theory&#34;&gt;The problem, in theory&lt;/h3&gt;

&lt;p&gt;Almost all services at Twitter run on Linux with &lt;a href=&#34;https://en.wikipedia.org/wiki/Completely_Fair_Scheduler&#34;&gt;the CFS scheduler&lt;/a&gt;, using &lt;a href=&#34;https://www.kernel.org/doc/Documentation/cgroup-v2.txt&#34;&gt;CFS bandwidth control quota&lt;/a&gt; for isolation, with default parameters. The intention is to allow different services to be colocated on the same boxes without having one service&#39;s runaway CPU usage impact other services and to prevent services on empty boxes from taking all of the CPU on the box, resulting in unpredictable performance, which service owners found difficult to reason about before we enabled quotas. The quota mechanism limits the amortized CPU usage of each container, but it doesn&#39;t limit how many cores the job can use at any given moment. Instead, if a job &amp;quot;wants to&amp;quot; use more than that many cores over a quota timeslice, it will use more cores than its quota for a short period of time and then get throttled, i.e., basically get put to sleep, in order to keep its amortized core usage below the quota, which is disastrous for &lt;a href=&#34;https://danluu.com/latency-pitfalls/&#34;&gt;tail latency&lt;/a&gt;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:S&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:S&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Since the vast majority of services at Twitter use thread pools that are much larger than their mesos core reservation, when jobs have heavy load, they end up requesting and then using more cores than their reservation and then throttling. This causes services that are provisioned based on load test numbers or observed latency under load to over provision CPU to avoid violating their &lt;a href=&#34;https://en.wikipedia.org/wiki/Service-level_objective&#34;&gt;SLO&lt;/a&gt;s. They either have to ask for more CPUs per shard than they actually need or they have to increase the number of shards they use.&lt;/p&gt;

&lt;p&gt;An old example of this problem was the JVM Garbage Collector. Prior to work on the JVM to make the JVM container aware, each JVM would default the GC parallel thread pool size to the number of cores on the machine. During a GC, all these GC threads would run simultaneously, exhausting the cpu quota rapidly causing throttling. The resulting effect would be that a subsecond stop-the-world GC pause could take many seconds of wallclock time to complete. While the GC issue has been fixed, the issue still exists at the application level for virtually all services that run on mesos.&lt;/p&gt;

&lt;h3 id=&#34;the-problem-in-practice-case-study&#34;&gt;The problem, in practice [case study]&lt;/h3&gt;

&lt;p&gt;As a case study, let&#39;s look at &lt;code&gt;service-1&lt;/code&gt;, the largest and most expensive service at Twitter.&lt;/p&gt;

&lt;p&gt;Below is the CPU utilization histogram for this service just as it starts failing its load test, i.e., when it&#39;s just above the peak load the service can handle before it violates its SLO. The x-axis is the number of CPUs used at a given point in time and the y-axis is (relative) time spent at that utilization. The service is provisioned for 20 cores and we can see that the utilization is mostly significantly under that, even when running at nearly peak possible load:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://danluu.com/images/cgroup-throttling/cpu-histogram-1.png&#34; alt=&#34;Histogram for service with 20 CPU quota showing that average utilization is much lower but peak utilization is significantly higher when the service is overloaded and violates its SLO&#34; width=&#34;1266&#34; height=&#34;658&#34;&gt;&lt;/p&gt;

&lt;p&gt;The problem is the little bars above 20. These spikes caused the job to use up its CPU quota and then get throttled, which caused latency to drastically increase, which is why the SLO was violated even though average utilization is about 8 cores, or 40% of quota. One thing to note is that the sampling period for this graph was 10ms and the quota period is 100ms, so it&#39;s technically possible to see an excursion above 20 in this graph without throttling, but on average, if we see a lot of excursions, especially way above 20, we&#39;ll likely get throttling.&lt;/p&gt;

&lt;p&gt;After reducing the thread pool sizes to avoid using too many cores and then throttling, we got the following CPU utilization histogram under a load test:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://danluu.com/images/cgroup-throttling/cpu-histogram-2.png&#34; alt=&#34;Histogram for service with 20 CPU quota showing that average utilization is much lower but peak utilization is significantly higher when the service is overloaded and violates its SLO&#34; width=&#34;1216&#34; height=&#34;548&#34;&gt;&lt;/p&gt;

&lt;p&gt;This is at 1.6x the load (request rate) of the previous histogram. In that case, the load test harness was unable to increase load enough to determine peak load for &lt;code&gt;service-1&lt;/code&gt; because the service was able to handle so much load before failure that the service that&#39;s feeding it during the load test couldn&#39;t keep it and send more load (although that&#39;s fixable, I didn&#39;t have the proper permissions to quickly fix it). [later testing showed that the service was able to handle about 2x the capacity after tweaking the thread pool sizes]&lt;/p&gt;

&lt;p&gt;This case study isn&#39;t an isolated example — Andy Wilcox has looked at the same thing for &lt;code&gt;service-2&lt;/code&gt; and found similar gains in performance under load for similar reasons.&lt;/p&gt;

&lt;p&gt;For services that are concerned about latency, we can get significant latency gains if we prefer to get latency gains instead of cost reduction. For &lt;code&gt;service-1&lt;/code&gt;, if we leave the provisioned capacity the same instead of cutting by 2x, we see a 20% reduction in latency.&lt;/p&gt;

&lt;p&gt;The gains for doing this for individual large services are significant (in the case of &lt;code&gt;service-1&lt;/code&gt;, it&#39;s [mid 7 figures per year] for the service and [low 8 figures per year] including services that are clones of it, but tuning every service by hand isn&#39;t scalable. That raises the question: how many services are impacted?&lt;/p&gt;

&lt;h3 id=&#34;thread-usage-across-the-fleet&#34;&gt;Thread usage across the fleet&lt;/h3&gt;

&lt;p&gt;If we look at the number of active threads vs. number of reserved cores for moderate sized services (&amp;gt;= 100 shards), we see that almost all services have many more threads that want to execute than reserved cores. It&#39;s not uncommon to see tens of &lt;a href=&#34;https://access.redhat.com/sites/default/files/attachments/processstates_20120831.pdf&#34;&gt;runnable threads&lt;/a&gt; per reserved core. This makes the &lt;code&gt;service-1&lt;/code&gt; example, above, look relatively tame, at 1.5 to 2 runnable threads per reserved core under load.&lt;/p&gt;

&lt;p&gt;If we look at where these threads are coming from, it&#39;s common to see that a program has multiple thread pools where each thread pool is sized to either twice the number of reserved cores or twice the number of logical cores on the host machine. Both inside and outside of Twitter, It&#39;s common to see advice that thread pool size should be 2x the number of logical cores on the machine. This advice probably comes from a workload like picking how many threads to use for something like a gcc compile, where we don&#39;t want to have idle resources when we could have something to do. Since threads will sometimes get blocked and have nothing to do, going to 2x can increase throughput over 1x by decreasing the odds that any core is every idle, and 2x is a nice, round, number.&lt;/p&gt;

&lt;p&gt;However, there are a few problems with applying this to Twitter applications:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Most applications have multiple, competing, thread pools&lt;/li&gt;
&lt;li&gt;Exceeding the reserved core limit is extremely bad&lt;/li&gt;
&lt;li&gt;Having extra threads working on computations can increase latency&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The &amp;quot;we should provision 2x the number of logical cores&amp;quot; model assumes that we have only one main thread pool doing all of the work and that there&#39;s little to no downside to having threads that could do work sit and do nothing and that we have a throughput oriented workload where we don&#39;t care about the deadline of any particular unit of work.&lt;/p&gt;

&lt;p&gt;With the CFS scheduler, threads that have active work that are above the core reservation won&#39;t do nothing, they&#39;ll get scheduled and run, but this will cause throttling, which negatively impacts tail latency.&lt;/p&gt;

&lt;h3 id=&#34;potential-solutions&#34;&gt;Potential Solutions&lt;/h3&gt;

&lt;p&gt;Given that we see something similar looking to our case study on many services and that it&#39;s difficult to push performance fixes to a lot of services (because service owners aren&#39;t really incentivized to take performance improvements), what can we do to address this problem across the fleet and just on a few handpicked large services? We&#39;re going to look at a list of potential solutions and then discuss each one in more detail, below.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Better defaults for cross-fleet threadpools (eventbus, netty, etc.)&lt;/li&gt;
&lt;li&gt;Negotiating ThreadPool sizes via a shared library&lt;/li&gt;
&lt;li&gt;CFS period tuning&lt;/li&gt;
&lt;li&gt;CFS bandwidth slice tuning&lt;/li&gt;
&lt;li&gt;Other scheduler tunings&lt;/li&gt;
&lt;li&gt;CPU pinning and isolation&lt;/li&gt;
&lt;li&gt;Overprovision at the mesos scheduler level&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;better-defaults-for-cross-fleet-threadpools&#34;&gt;Better defaults for cross-fleet threadpools&lt;/h4&gt;

&lt;p&gt;&lt;b&gt;Potential impact&lt;/b&gt;: some small gains in efficiency&lt;br&gt;
&lt;b&gt;Advantages&lt;/b&gt;: much less work than any comprehensive solution, can be done in parallel with more comprehensive solutions and will still yield some benefit (due to reduced lock contention and context switches) if other solutions are in place.&lt;br&gt;
&lt;b&gt;Downsides&lt;/b&gt;: doesn&#39;t solve most of the problem.&lt;/p&gt;

&lt;p&gt;Many defaults are too large. Netty default threadpool size is 2x the reserved cores. In some parts of [an org], they use a library that spins up &lt;a href=&#34;https://news.ycombinator.com/item?id=26643392&#34;&gt;eventbus&lt;/a&gt; and allocates a threadpool that&#39;s 2x the number of logical cores on the host (resulting in [over 100] eventbus threads) when 1-2 threads is sufficient for most of their eventbus use cases.&lt;/p&gt;

&lt;p&gt;Adjusting these default sizes won&#39;t fix the problem, but it will reduce the impact of the problem and this should be much less work than the solutions below, so this can be done while we work on a more comprehensive solution.&lt;/p&gt;

&lt;h4 id=&#34;negotiating-threadpool-sizes-via-a-shared-library-api&#34;&gt;Negotiating ThreadPool sizes via a shared library (API)&lt;/h4&gt;

&lt;p&gt;[this section was written by &lt;i&gt;Vladimir Kostyukov&lt;/i&gt;]&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Potential impact&lt;/b&gt;: can mostly mitigate the problem for most services.&lt;br&gt;
&lt;b&gt;Advantages&lt;/b&gt;: quite straightforward to design and implement; possible to make it first-class in &lt;a href=&#34;https://kostyukov.net/posts/finagle-101/&#34;&gt;Finagle&lt;/a&gt;/Finatra.&lt;br&gt;
&lt;b&gt;Downsides&lt;/b&gt;: Requires service-owners to opt-in explicitly (adopt a new API for constructing thread-pools).&lt;/p&gt;

&lt;p&gt;CSL’s util library has a package that bridges in some integration points between an application and a JVM (util-jvm), which could be a good place to host a new API for negotiating the sizes of the thread pools required by the application.&lt;/p&gt;

&lt;p&gt;The look and feel of such API is effectively dictated by how granular the negotiation is needed to be. Simply contending on a total number of allowed threads allocated per process, while being easy to implement, doesn’t allow distinguishing between application and IO threads. Introducing a notion of QoS for threads in the thread pool (i.e., “IO thread; can not block”, “App thread; can block”), on the other hand, could make the negotiation fine grained.&lt;/p&gt;

&lt;h4 id=&#34;cfs-period-tuning&#34;&gt;CFS Period Tuning&lt;/h4&gt;

&lt;p&gt;&lt;b&gt;Potential impact&lt;/b&gt;: small reduction tail latencies by shrinking the length of the time period before the process group’s CFS runtime quota is refreshed.&lt;br&gt;
&lt;b&gt;Advantages&lt;/b&gt;: relatively straightforward change requiring few minimal changes.&lt;br&gt;
&lt;b&gt;Downsides&lt;/b&gt;: comes at increased scheduler overhead costs that may offset the benefits and does not address the core issue of parallelism exhausting quota. May result in more total throttling.&lt;/p&gt;

&lt;p&gt;To limit CPU usage, CFS operates over a time window known as the CFS period. Processes in a scheduling group take time from the CFS quota assigned to the cgroup and this quota is consumed over the cfs_period_us in CFS bandwidth slices. By shrinking the CFS period, the worst case time between quota exhaustion causing throttling and the process group being able to run again is reduced proportionately. Taking the default values of a CFS bandwidth slice of 5ms and CFS period of 100ms, in the worst case, a highly parallel application could exhaust all of its quota in the first bandwidth slice leaving 95ms of throttled time before any thread could be scheduled again.&lt;/p&gt;

&lt;p&gt;It&#39;s possible that total throttling would increase because the scheduled time over 100ms might not exceed the threshold even though there are (for example) 5ms bursts that exceed the threshold.&lt;/p&gt;

&lt;h4 id=&#34;cfs-bandwidth-slice-tuning&#34;&gt;CFS Bandwidth Slice Tuning&lt;/h4&gt;

&lt;p&gt;&lt;b&gt;Potential impact&lt;/b&gt;: small reduction in tail latencies by allowing applications to make better use of the allocated quota.&lt;br&gt;
&lt;b&gt;Advantages&lt;/b&gt;: relatively straightforward change requiring minimal code changes.&lt;br&gt;
&lt;b&gt;Downsides&lt;/b&gt;: comes at increased scheduler overhead costs that may offset the benefits and does not address the core issue of parallelism exhausting quota.&lt;/p&gt;

&lt;p&gt;When CFS goes to schedule a process it will transfer run-time between a global pool and CPU local pool to reduce global accounting pressure on large systems.The amount transferred each time is called the &amp;quot;slice&amp;quot;. A larger bandwidth slice is more efficient from the scheduler’s perspective but a smaller bandwidth slice allows for more fine grained execution. In debugging issues in [link to internal JIRA ticket] it was determined that if a scheduled process fails to consume its entire bandwidth slice, the default slice size being 5ms, because it has completed execution or blocked on another process, this time is lost to the process group reducing its ability to consume all available resources it has requested.&lt;/p&gt;

&lt;p&gt;The overhead of tuning this value is expected to be minimal, but should be measured. Additionally, it is likely not a one size fits all tunable, but exposing this to the user as a tunable has been rejected in the past in Mesos. Determining a heuristic for tuning this value and providing a per application way to set it may prove infeasible.&lt;/p&gt;

&lt;h4 id=&#34;other-scheduler-tunings&#34;&gt;Other Scheduler Tunings&lt;/h4&gt;

&lt;p&gt;&lt;b&gt;Potential Impact&lt;/b&gt;: small reduction in tail latencies and reduced throttling.&lt;br&gt;
&lt;b&gt;Advantages&lt;/b&gt;: relatively straightforward change requiring minimal code changes.&lt;br&gt;
&lt;b&gt;Downsides&lt;/b&gt;:  comes at potentially increased scheduler overhead costs that may offset the benefits and does not address the core issue of parallelism exhausting quota.&lt;/p&gt;

&lt;p&gt;The kernel has numerous auto-scaling and auto-grouping features whose impact to scheduling performance and throttling is currently unknown. &lt;code&gt;kernel.sched_tunable_scaling&lt;/code&gt; can adjust &lt;code&gt;kernel.sched_latency_ns&lt;/code&gt; underneath our understanding of its value. &lt;code&gt;kernel.sched_min_granularity_ns&lt;/code&gt; and &lt;code&gt;kernel.sched_wakeup_granularity_ns&lt;/code&gt; can be tuned to allow for preempting sooner, allowing better resource sharing and minimizing delays. &lt;code&gt;kernel.sched_autogroup_enabled&lt;/code&gt; may currently not respect &lt;code&gt;kernel.sched_latency_ns&lt;/code&gt;leading to more throttling challenges and scheduling inefficiencies. These tunables have not been investigated significantly and the impact of tuning them is unknown.&lt;/p&gt;

&lt;h4 id=&#34;cfs-scheduler-improvements&#34;&gt;CFS Scheduler Improvements&lt;/h4&gt;

&lt;p&gt;&lt;b&gt;Potential impact&lt;/b&gt;: better overall cpu resource utilization and minimized throttling due to CFS inefficiencies.&lt;br&gt;
&lt;b&gt;Advantages&lt;/b&gt;: improvements are transparent to userspace.&lt;br&gt;
&lt;b&gt;Downsides&lt;/b&gt;: the CFS scheduler is complex so there is a large risk to the success of the changes and upstream reception to certain types of modifications may be challenging.&lt;/p&gt;

&lt;p&gt;How the CFS scheduler deals with unused slack time from the CFS bandwidth slice has shown to be ineffective. The kernel team has a patch to ensure that this unused time is returned back to the global pool for other processes to use, &lt;a href=&#34;https://lore.kernel.org/patchwork/patch/907450/&#34;&gt;https://lore.kernel.org/patchwork/patch/907450/&lt;/a&gt; to ensure better overall system resource utilization. There are some additional avenues to explore that could provide further enhancements. Another of many recent discussions in this area  that fell out of a k8s throttling issue(&lt;a href=&#34;https://github.com/kubernetes/kubernetes/issues/67577&#34;&gt;https://github.com/kubernetes/kubernetes/issues/67577&lt;/a&gt;) is &lt;a href=&#34;https://lkml.org/lkml/2019/3/18/706&#34;&gt;https://lkml.org/lkml/2019/3/18/706&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Additionally, CFS may lose efficiency due to bugs such as [link to internal JIRA ticket] and &lt;a href=&#34;http://www.ece.ubc.ca/~sasha/papers/eurosys16-final29.pdf&#34;&gt;http://www.ece.ubc.ca/~sasha/papers/eurosys16-final29.pdf&lt;/a&gt;. However, we haven&#39;t spent much time looking at the CFS performance for Twitter’s particular use cases. A closer look at CFS may find ways to improve efficiency.&lt;/p&gt;

&lt;p&gt;Another change which has more upside and downside potential would be to use a scheduler other than CFS.&lt;/p&gt;

&lt;h4 id=&#34;cpu-pinning-and-isolation&#34;&gt;CPU Pinning and Isolation&lt;/h4&gt;

&lt;p&gt;&lt;b&gt;Potential impact&lt;/b&gt;: removes the concept of throttling from the system by making the application developer’s mental model of a CPU map to a physical one. &lt;br&gt;
&lt;b&gt;Advantages&lt;/b&gt;: simplified understanding from application developer’s perspective, scheduler imposed throttling is no longer a concept an application contends with, improved cache efficiency, much less resource interference resulting in more deterministic performance.&lt;br&gt;
&lt;b&gt;Disadvantages&lt;/b&gt;: greater operational complexity, oversubscription is much more complicated, significant changes to current operating environment&lt;/p&gt;

&lt;p&gt;The fundamental issue that allows throttling to occur is that a heavily threaded application can have more threads executing in parallel than the “number of CPUs” it requested resulting in an early exhaustion of available runtime. By restricting the number of threads executing simultaneously to the number of CPUs an application requested there is now a 1:1 mapping and an application’s process group is free to consume the logical CPU thread unimpeded by the scheduler. Additionally, by dedicating a CPU thread rather than a bandwidth slice to the application, the application is now able to take full advantage of CPU caching benefits without having to contend with other applications being scheduled on the same CPU thread while it is throttled or context switched away.&lt;/p&gt;

&lt;p&gt;In Mesos, implementing CPU pinning has proven to be quite difficult. However, in k8s there is existing hope in the form of a project from Intel known as the k8s CPU Manager. The CPU Manager was added as an alpha feature to k8s in 1.8 and has been enabled as a beta feature since 1.10. It has somewhat stalled in beta as few people seem to be using it but the core functionality is present. The performance improvements promoted by the CPU Manager project are significant as shown in examples such as &lt;a href=&#34;https://kubernetes.io/blog/2018/07/24/feature-highlight-cpu-manager/&#34;&gt;https://kubernetes.io/blog/2018/07/24/feature-highlight-cpu-manager/&lt;/a&gt; and &lt;a href=&#34;https://builders.intel.com/docs/networkbuilders/cpu-pin-and-isolation-in-kubernetes-app-note.pdf&#34;&gt;https://builders.intel.com/docs/networkbuilders/cpu-pin-and-isolation-in-kubernetes-app-note.pdf&lt;/a&gt; While these benchmarks should be looked at with some skepticism, it does provide promising hope for exploring this avenue. A cursory inspection of the project highlights a few &lt;a href=&#34;https://github.com/kubernetes/kubernetes/issues/70585&#34;&gt;areas&lt;/a&gt; where work may still be needed but it is already in a usable state for validating the approach. Underneath, the k8s CPU Manager leverages the cpuset cgroup functionality that is present in the kernel.&lt;/p&gt;

&lt;p&gt;Potentially, this approach does reduce the ability to oversubscribe the machines. However, the efficiency gains from minimized cross-pod interference, CPU throttling, a more deterministic execution profile and more may offset the need to oversubscribe. Currently, the k8s CPU Manager does allow for minor oversubscription in the form of allowing system level containers and the daemonset to be oversubscribed, but on a pod scheduling basis the cpus are reserved for that pod’s use.&lt;/p&gt;

&lt;p&gt;Experiments by Brian Martin and others have shown significant performance benefits from CPU pinning that are almost as large as our oversubscription factor.&lt;/p&gt;

&lt;p&gt;Longer term, oversubscription could be possible through a multitiered approach of wherein a primary class of pods is scheduled using CPU pinning but a secondary class of pods that is not as latency sensitive is allowed to float across all cores consuming slack resources from the primary pods. The work on the CPU Manager side would be extensive. However, recently &lt;a href=&#34;https://lwn.net/ml/linux-kernel/20190408214539.2705660-1-songliubraving@fb.com/&#34;&gt;Facebook has been doing some work&lt;/a&gt; on the kernel scheduler side to further enable this concept in a way that minimally impacts the primary pod class that we can expand upon or evolve.&lt;/p&gt;

&lt;h4 id=&#34;oversubscription-at-the-cluster-scheduler-level&#34;&gt;Oversubscription at the cluster scheduler level&lt;/h4&gt;

&lt;p&gt;&lt;b&gt;Potential impact&lt;/b&gt;: can bring machine utilization up to an arbitrarily high level and overprovisioning &amp;quot;enough&amp;quot;.&lt;br&gt;
&lt;b&gt;Advantages&lt;/b&gt;: oversubscription at the cluster scheduler level is independent of the problem described in this doc; doing it in a data-driven way can drive machine utilization up without having to try to fix the specific problems described here. This could simultaneously fix the problem in this doc (low CPU utilization due to overprovisioning to avoid throttling) while also fixing [reference to document describing another problem].&lt;br&gt;
&lt;b&gt;Disadvantages&lt;/b&gt;: we saw in [link to internal doc] that shards of services running on hosts with high load have degraded performance. Unless we change the mesos scheduler to schedule based on actual utilization (as opposed to reservation), some hosts would end up too highly loaded and services with shards that land on those hosts would have poor performance.&lt;/p&gt;

&lt;h4 id=&#34;disable-cfs-quotas&#34;&gt;Disable CFS quotas&lt;/h4&gt;

&lt;p&gt;&lt;b&gt;Potential impact&lt;/b&gt;: prevents throttling and allows services to use all available cores on a box by relying on the &amp;quot;shares&amp;quot; mechanism instead of quota.&lt;br&gt;
&lt;b&gt;Advantages&lt;/b&gt;: in some sense, can gives us the highest possible utilization.&lt;br&gt;
&lt;b&gt;Disadvantages&lt;/b&gt;: badly behaved services could severely interfere with other services running on the same box. Also, service owners would have a much more difficult time predicting the performance of their own service since performance variability between the unloaded and loaded state would be much larger.&lt;/p&gt;

&lt;p&gt;This solution is what was used before we enabled quotas. From a naive hardware utilization standpoint, relying on the shares mechanism seems optimal since this means that, if the box is underutilized, services can take unused cores, but if the box becomes highly utilized, services will fall back to taking their share of cores, proportional to their core reseration. However, when we used this system, most service owners found it too difficult to estimate performance under load for this to be practical. At least one company has tried this solution to fix their throttling problem and has had severe incidents under load because of it. If we switched back to this today, we&#39;d be no better off than we were before we were before we enabled quotes.&lt;/p&gt;

&lt;p&gt;Given how we allocate capacity, two ingredients that would make this work better than it did before include having a more carefully controlled request rate to individual shards and a load testing setup that allowed service owners to understand what things would really look like during a load spike, as opposed to our system, which only allows injection of unrealistic load to individual shards, which both has the problem that the request mix isn&#39;t the same as it is under a real load spike and that the shard with injected load isn&#39;t seeing elevated load from other services running on the same box. Per [another internal document], we know that one of the largest factors impacting shard-level performance is overall load on the box and that the impact on latency is non-linear and difficult to predict, so there&#39;s not really a good way to predict performance under actual load from performance under load tests with the load testing framework we have today.&lt;/p&gt;

&lt;p&gt;Although these missing ingredients are important, high impact, issues, addressing either of these issues is beyond the scope of this doc; [Team X] owns load testing and is working on load testing and it might be worth revisiting this when the problem is solved.&lt;/p&gt;

&lt;p&gt;An intermediate solution would be to set the scheduler quota to a larger value than the number of reserved cores in mesos, which would bound the impact of having &amp;quot;too much&amp;quot; CPU available causing unpredictable performance while potentially reducing throttling when under high load because the scheduler will effective fall back to the shares mechanism if the box is highly loaded. For example, if the cgroup quota was twice the the mesos quota, services that fall over at 50% of reserved mesos CPU usage would then instead fall over at 100% of reserved mesos CPU usage. For boxes at high load, the higher overall utilization would reduce throttling because the increased load from other cores would mean that a service that has too many runnable threads wouldn&#39;t be able to have as many of those threads execute. This has a weaker version of the downside of disabling in quota, in that, from [internal doc], we know that load on a box from other services is one of the largest factors in shard-level performance variance and this would, if we don&#39;t change how many mesos cores are reserved on a box, increase load on boxes. And if we do proportionately decrease the number of mesos reserved cores on a box, that makes the change pointless in that it&#39;s equivalent to just doubling every service&#39;s CPU reservation, except that having it &amp;quot;secretly&amp;quot; doubled would probably reduce the number of people who ask the question, &amp;quot;Why can&#39;t I exceed X% CPU in load testing without the service falling over?&amp;quot;&lt;/p&gt;

&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;

&lt;p&gt;&lt;i&gt;This section was not in the original document from April 2019; it was written in December 2021 and describes work that happened as a result of the original document.&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;The suggestion of changing default thread pool sizes was taken and resulted in minor improvements. More importantly, two major efforts came out of the document. Vladimir Kostyukov (from the &lt;a href=&#34;https://finagle.github.io/blog/2021/03/31/quarterly/&#34;&gt;CSL team&lt;/a&gt;) and Flavio Brasil (from the JVM team) created &lt;a href=&#34;https://github.com/twitter/finagle/blob/develop/finagle-core/src/main/scala/com/twitter/finagle/filter/OffloadFilter.scala&#34;&gt;Finagle Offload Filter&lt;/a&gt; and Xi Yang (my intern&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:I&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:I&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; at the time and now a full-time employee for my team) created a kernel patch which eliminates container throttling (the patch is still internal, but will hopefully eventually upstreamed).&lt;/p&gt;

&lt;p&gt;Almost all applications that run on mesos at Twitter run on top of &lt;a href=&#34;https://kostyukov.net/posts/finagle-101/&#34;&gt;Finagle&lt;/a&gt;. The Finagle Offload Filter makes it trivial for service owners to put application work onto a different thread pool than IO (which was often not previously happening). In combination with sizing thread pools properly, this resulted in, ceteris paribus, applications having &lt;a href=&#34;https://mobile.twitter.com/fbrasisil/status/1163974576511995904&#34;&gt;drastically reduced latency&lt;/a&gt;, enabling them to reduce their provisioned capacity and therefore their cost while meeting their SLO. Depending on the service, this resulted in a 15% to 60% cost reduction for the service.&lt;/p&gt;

&lt;p&gt;The kernel patch implements the obvious idea of preventing containers from using more cores than a container&#39;s quota at every moment instead of allowing a container to use as many cores as are available on the machine and then putting the container to sleep if it uses too many cores to bring its amortized core usage down.&lt;/p&gt;

&lt;p&gt;In experiments on hosts running major services at Twitter, this has the expected impact of eliminating issues related to throttling, giving a roughly 50% cost reduction for a typical service with untuned thread pool sizes. And it turns out the net impact is larger than we realized when we wrote this document due to the reduction in interference caused by preventing services from using &amp;quot;too many&amp;quot; cores and then throttling&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:M&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:M&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;. Also, although this was realized at the time, we didn&#39;t note in the document that the throttling issue causes shards to go from &amp;quot;basically totally fine&amp;quot; to a &amp;quot;throttling death spiral&amp;quot; that&#39;s analogous to a &amp;quot;GC death spiral&amp;quot; with only a small amount of additional load, which increases the difficulty of operating systems reliably. What happens is that, when a service is under high load, it will throttle. Throttling doesn&#39;t prevent requests from coming into the shard that&#39;s throttled, so when the shard wakes up from being throttled, it has even more work to do than it had before it throttled, causing it to use even more CPU and throttle more quickly, which causes even more work to pile up. Finagle has a mechanism that can shed load for shards that are in very bad shape (clients that talk to the dead server will mark the server as dead and stop sending request for a while) but, shards tend to get into this bad state when overall load to the service is high, so marking a node as dead just means that more load goes to other shards, which will then &amp;quot;want to&amp;quot; enter a throttling death spiral. Operating in a regime where throttling can cause a death spiral is &lt;a href=&#34;https://twitter.com/copyconstruct/status/1399766443596472320&#34;&gt;an inherently metastable state&lt;/a&gt;. Removing both of these issues is arguably as large an impact as the cost reduction we see from eliminating throttling.&lt;/p&gt;

&lt;p&gt;Xi Yang has experimented with variations on the naive kernel scheduler change mentioned above, but even the naive change seems to be quite effective compared to no change, even though the naive change does mean that services will often not be able to hit their full CPU allocation when they ask for it, e.g., if a service requests no CPU for the first half a period and then requests infinite CPU for the second half of the period, under the old system, it would get its allocated amount of CPU for the period, but under the new system, it would only get half. Some of Xi&#39;s variant patches address this issue in one way or another, but that has a relatively small impact compared to preventing throttling in the first place.&lt;/p&gt;

&lt;p&gt;An independent change Pratik Tandel drove that reduced the impact of throttling on services by reducing the impact of variance between shards was to move to fewer larger shards. The main goal for that change was to reduce overhead due to duplicate work/memory that happens across all shards, but it also happens to have an impact due to larger per-shard quotas reducing the impact of random noise. Overall, this resulted in 0% to 20% reduced CPU usage and 10% to 40% reduced memory usage of large services at Twitter, depending on the service.&lt;/p&gt;

&lt;h3 id=&#34;appendix-other-container-throttling-related-work&#34;&gt;Appendix: other container throttling related work&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://engineering.indeedblog.com/blog/2019/12/cpu-throttling-regression-fix/&#34;&gt;https://engineering.indeedblog.com/blog/2019/12/cpu-throttling-regression-fix/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Adding burstiness

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://lore.kernel.org/lkml/20180522062017.5193-1-xiyou.wangcong@gmail.com/&#34;&gt;https://lore.kernel.org/lkml/20180522062017.5193-1-xiyou.wangcong@gmail.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lkml.org/lkml/2019/11/26/196&#34;&gt;https://lkml.org/lkml/2019/11/26/196&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lwn.net/Articles/840595/&#34;&gt;https://lwn.net/Articles/840595/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;A container that exceeds its allocation will still throttle, but the idea of &amp;quot;burst capacity&amp;quot; is added, allowing more margin before throttling while keeping basically the same average core utilization

&lt;ul&gt;
&lt;li&gt;Allowing burstiness is independent of our fix, which prevents throttling and, in principle, both ideas could be applied at the same time, which would be somewhat like how network isolation works if you enable htb qdisc&lt;/li&gt;
&lt;li&gt;Given the workloads and configurations that Twitter has, this does not fix the throttling problem for us with respect to either achieving very high per-container CPU utilization or preventing a the metastability caused by threat of throttling death spiral, although it does allow us to use slightly more average CPU than without enabling burstiness&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Runtime level parallelism limiting

&lt;ul&gt;
&lt;li&gt;Since Go typically uses a single thread pool, Uber was able to work around this issue by limiting the maximum number of running goroutines via &lt;a href=&#34;https://github.com/uber-go/automaxprocs&#34;&gt;https://github.com/uber-go/automaxprocs&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Unfortunately for Twitter, a number of Twitter&#39;s largest and most expensive services, including &lt;code&gt;service-1&lt;/code&gt;, use multiple language runtimes, so there isn&#39;t a simple way to bound the parallelism at the runtime level&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;The .NET runtime has had adaptive thread pool sizes for a decade, &lt;a href=&#34;https://twitter.com/danluu/status/1340059907026898944&#34;&gt;one of the many ways the .NET stack is more advanced than what we commonly see at trendy tech companies&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;i&gt;Thanks to Xi Yang, Ilya Pronin, Ian Downes, Rebecca Isaacs, Brian Martin, Vladimir Kotsyukov, Moses Nakamura, Flavio Brasil, Laurence Tratt, Akshay Shah, Julian Squires, Michael Greenberg @synrotek, and Miguel Angel Corral for comments/corrections/discussion&lt;/i&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:S&#34;&gt;if this box is highly loaded, because there aren&#39;t enough cores to go around, then a container may not get all of the cores it requests, but this doesn&#39;t change the fundamental problem.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:S&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:I&#34;&gt;I often joke that &lt;a href=&#34;https://twitter.com/danluu/status/1324416895013986305&#34;&gt;interns get all of the most interesting work&lt;/a&gt;, while us full-time employees are stuck with the stuff interns don&#39;t want to do.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:I&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:M&#34;&gt;In an independent effort, Matt Tejo found that, for a fixed average core utilization, services that throttle cause a much larger negative impact on other services on the same host than services that use a constant number of cores. That&#39;s because a service that&#39;s highly loaded and throttling toggles between attempting to use all of the cores on the box and then using none of the cores on the box, causing an extremely large amount of interference during the periods where it&#39;s attempting to use all of the cores on the box.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:M&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Some thoughts on writing</title>
      <link>https://danluu.com/writing-non-advice/</link>
      <pubDate>Mon, 13 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://danluu.com/writing-non-advice/</guid>
      <description>

&lt;p&gt;I see a lot of essays framed as writing advice which are actually thinly veiled descriptions of how someone writes that basically say &amp;quot;you should write how I write&amp;quot;, e.g., &lt;a href=&#34;https://twitter.com/danluu/status/1437539076324790274&#34;&gt;people who write short posts say that you should write short posts&lt;/a&gt;. As with technical topics, &lt;a href=&#34;https://danluu.com/learn-what/&#34;&gt;I think a lot of different things can work and what&#39;s really important is that you find a style that&#39;s suitable to you and the context you operate in&lt;/a&gt;. &lt;a href=&#34;https://twitter.com/danluu/status/1467235582199812097&#34;&gt;Copying what&#39;s worked for someone else is unlikely to work for you&lt;/a&gt;, making &amp;quot;write how I write&amp;quot; bad advice.&lt;/p&gt;

&lt;p&gt;We&#39;ll start by looking at how much variety there&#39;s been in what&#39;s worked&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:P&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:P&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; for people, come back to what makes it so hard to copy someone else&#39;s style, and then discuss what I try to do in my writing.&lt;/p&gt;

&lt;p&gt;If I look at the most read programming blogs in my extended social circles&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:O&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:O&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; from 2000 to 2017&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:7&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:7&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;, it&#39;s been Joel Spolsky, Paul Graham, Steve Yegge, and Julia Evans (if you&#39;re not familiar with these writers, &lt;a href=&#34;#appendix-some-snippets-of-writing&#34;&gt;see the appendix for excerpts that I think are representative of their styles&lt;/a&gt;). Everyone on this list has a different style in the following dimensions (as well as others):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Topic selection&lt;/li&gt;
&lt;li&gt;Prose style&lt;/li&gt;
&lt;li&gt;Length&lt;/li&gt;
&lt;li&gt;Type of humor (if any)&lt;/li&gt;
&lt;li&gt;Level of technical detail&lt;/li&gt;
&lt;li&gt;Amount of supporting evidence&lt;/li&gt;
&lt;li&gt;Nuance&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To pick a simple one to quantify, length, Julia Evans and I both started blogging in 2013 (she has one post from 2012, but she&#39;s told me that she considers her blog to have started in earnest when she was at &lt;a href=&#34;https://www.recurse.com/scout/click?t=b504af89e87b77920c9b60b2a1f6d5e8&#34;&gt;RC&lt;/a&gt;, in September 2013, the same month I started blogging). Over the years, we&#39;ve compared notes a number of times and, until I paused blogging at the end of 2017, we had a similar word count on our blogs even though she was writing roughly one order of magnitude more posts than I do.&lt;/p&gt;

&lt;p&gt;To look at a few aspects that are difficult to quantify, consider this passage from Paul Graham, which is typical of his style:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;What nerds like is the kind of town where people walk around smiling. This excludes LA, where no one walks at all, and also New York, where people walk, but not smiling. When I was in grad school in Boston, a friend came to visit from New York. On the subway back from the airport she asked &amp;quot;Why is everyone smiling?&amp;quot; I looked and they weren&#39;t smiling. They just looked like they were compared to the facial expressions she was used to.&lt;/p&gt;

&lt;p&gt;If you&#39;ve lived in New York, you know where these facial expressions come from. It&#39;s the kind of place where your mind may be excited, but your body knows it&#39;s having a bad time. People don&#39;t so much enjoy living there as endure it for the sake of the excitement. And if you like certain kinds of excitement, New York is incomparable. It&#39;s a hub of glamour, a magnet for all the shorter half-life isotopes of style and fame.&lt;/p&gt;

&lt;p&gt;Nerds don&#39;t care about glamour, so to them the appeal of New York is a mystery.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It uses multiple aspects of what&#39;s sometimes called &lt;a href=&#34;https://amzn.to/3dRLMgR&#34;&gt;classic style&lt;/a&gt;. In this post, when I say &amp;quot;classical style&amp;quot;, I mean as the term is used by &lt;a href=&#34;https://amzn.to/3dRLMgR&#34;&gt;Thomas &amp;amp; Turner&lt;/a&gt;, not a colloquial meaning. What that means is really too long to reasonably describe in this post, but I&#39;ll say that one part of it is that the prose is clean, straightforward, and simple; an editor whose slogan is &amp;quot;omit needless words&amp;quot; wouldn&#39;t have many comments. Another part is that the clean-ness of the style goes past the prose to what information is presented, so much so that supporting evidence isn&#39;t really presented. Thomas &amp;amp; Turner say &amp;quot;truth needs no argument but only accurate presentation&amp;quot;. An example that exemplifies both of these is this passage from Rochefoucauld:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Madame de Chevreuse had sparkling intelligence, ambition, and beauty in plenty; she was flirtatious, lively, bold, enterprising; she used all her charms to push her projects to success, and she almost always brought disaster to those she encountered on her way.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Thomas &amp;amp; Turner said this about Rochefoucauld&#39;s passage:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This passage displays truth according to an order that has nothing to do with the process by which the writer came to know it. The writer takes the pose of full knowledge. This pose implies that the writer has wide and textured experience; otherwise he would not be able to make such an observation. But none of that personal history, personal experience, or personal psychology enters into the expression. Instead the sentence crystallizes the writer’s experience into a timeless and absolute sequence, as if it were a geometric proof.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Much of this applies to the passage by Paul Graham (though not all, since he tells us an anecdote about a time a friend visited Boston from New York and he explicitly says that you would know such and such &amp;quot;if you&#39;ve lived in New York&amp;quot; instead just stating what you would know).&lt;/p&gt;

&lt;p&gt;My style is opposite in many ways. I often have long, meandering, sentences, not for any particular literary purpose, but just because it reflects how I think. &lt;a href=&#34;https://amzn.to/3s0Adwd&#34;&gt;Strunk &amp;amp; White&lt;/a&gt; would have a field day with my writing. To the extent feasible, I try to have a structured argument and, when possible, evidence, with caveats for cases where the evidence isn&#39;t applicable. Although not presenting evidence makes something read cleanly, that&#39;s not my choice because I don&#39;t like that the reader basically has to take or leave it with respect to bare assertions, such as &amp;quot;what nerds like is the kind of town where people walk around smiling&amp;quot; and would prefer if readers know why I think something so they can agree or disagree based on the underlying reasons.&lt;/p&gt;

&lt;p&gt;With length, style, and the other dimensions mentioned, there isn&#39;t a right way and a wrong way. A wide variety of things can work decently well. Though, if popularity is the goal, then I&#39;ve probably made a sub-optimal choice on length compared to Julia and on prose style when compared to Paul. If I look at what causes other people to gain a following, and what causes my RSS to get more traffic, for me to get more Twitter followers, etc., publishing short posts frequently looks more effective than publishing long posts less frequently.&lt;/p&gt;

&lt;p&gt;I&#39;m less certain about the impact of style on popularity, but my feeling is that, for the same reason that making a lot of confident statements at a job works (gets people promoted), writing confident, unqualified, statements, works (gets people readers). People like confidence.&lt;/p&gt;

&lt;p&gt;But, in both of these cases, one can still be plenty popular while making a sub-optimal choice and, for me, I view optimizing for other goals to be more important than optimizing for popularity. On length, I frequently cover topics that can&#39;t be covered in brief easily, or perhaps at all. One example of this is &lt;a href=&#34;https://danluu.com/branch-prediction/&#34;&gt;my post on branch prediction&lt;/a&gt;, which has two goals: give a programmer with no background in branch prediction or even computer architecture a historical survey and teach them enough to be able to read and understand a modern, state-of-the-art paper on branch prediction. That post comes in at 5.8k words. I don&#39;t see how to achieve the same goals with a post that comes in at the lengths that people recommend for blog posts, 500 words, 1000 words, 1500 words, etc. The post could probably be cut down a bit, but every predictor discussed is either a necessary building block used to explain later predictors except the &lt;code&gt;agree&lt;/code&gt; predictor or of historical importance. But if the &lt;code&gt;agree&lt;/code&gt; predictor wasn&#39;t discussed, it would still be important to discuss at least one interference-reducing scheme since why interference occurs and what can be done to reduce it is a fundamental concept in branch prediction.&lt;/p&gt;

&lt;p&gt;There are other versions of the post that could work. One that explains that branch prediction exists at all could probably be written in 1000 words. That post, written well, would have a wider audience, be more popular, but that&#39;s not what I want to write.&lt;/p&gt;

&lt;p&gt;I have an analogous opinion on style because I frequently want to discuss things in a level of detail and with a level of precision that precludes writing cleanly in the classic style. A specific, small, example is that, on a recent post, a draft reader asked me to remove a double negative and I declined because, in that case, the double negative had different connotations from the positive statement that might&#39;ve replaced it and I had something precise I wanted to convey that isn&#39;t what would&#39;ve been conveyed if I simplified the sentence.&lt;/p&gt;

&lt;p&gt;A more general thing is that Paul writes about a lot of &amp;quot;big ideas&amp;quot; at a high level. That&#39;s something that&#39;s amenable to writing in a clean, simple style; what Paul calls an elegant style. But I&#39;m not interested in writing about &lt;a href=&#34;https://scattered-thoughts.net/writing/on-bad-advice/#context-matters&#34;&gt;big ideas that are disconnected from low-level details&lt;/a&gt; and it&#39;s difficult to effectively discuss low-level details without writing in a style Paul would call inelegant.&lt;/p&gt;

&lt;p&gt;A concrete example of this is &lt;a href=&#34;https://danluu.com/cli-complexity/&#34;&gt;my discussion of command line tools and the UNIX philosophy&lt;/a&gt;. Should we have tools that &amp;quot;do one thing and do it well&amp;quot; and &amp;quot;write programs to handle text streams, because that is a universal interface&amp;quot; or use commands that have many options and can handle structured data? People have been trading the same high-level rebuttals back and forth for decades. But the moment we look at the details, look at what happens when these ideas get exposed to the real world, we can immediately see that one of these sets of ideas couldn&#39;t possibly work as espoused.&lt;/p&gt;

&lt;p&gt;Coming back to writing style, if you&#39;re trying to figure out what stylistic choices are right for you, you should start from your goals and what you&#39;re good at and go from there, not listen to somebody who&#39;s going to tell you to write like them. Besides being unlikely to work for you even if someone is able to describe what makes their writing tick, most advice is written by people who don&#39;t understand how their writing works. This may be difficult to see for writing if you haven&#39;t spent a lot of time analyzing writing, but it&#39;s easy to see this is true if you&#39;ve taken a bunch of dance classes or had sports instruction that isn&#39;t from a very good coach. If you watch, for example, the median dance instructor and listen to their instructions, you&#39;ll see that their instructions are quite different from what they actually do. &lt;a href=&#34;https://news.ycombinator.com/item?id=29524840&#34;&gt;People who listen and follow instructions instead of attempting to copy what the instructor is doing will end up doing the thing completely wrong&lt;/a&gt;. Most writing advice similarly fails to capture what&#39;s important.&lt;/p&gt;

&lt;p&gt;Unfortunately, &lt;a href=&#34;https://www.youtube.com/watch?v=2THVvshvq0Q&#34;&gt;copying someone else&#39;s style isn&#39;t easy either; most people copy entirely the wrong thing&lt;/a&gt;. For example, Natalie Wynn noted that people who copy her style often copy the superficial bits without understanding what&#39;s driving the superficial bits to be the way they are:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;One thing I notice is when people aren’t saying anything. Like when someone’s trying to do a “left tube video essay” and they shove all this opulent shit onscreen because contrapoints, but it has nothing to do with the topic. What’s the reference? What are you saying??&lt;/p&gt;

&lt;p&gt;I made a video about shame, and the look is Eve in Eden because Eve was the first person to experience shame. So the visual is connected to the concept and hopefully it resonates more because of that. So I guess that’s my advice, try to say something&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If you look into what people who excel in their field have to say, you&#39;ll often see analogous remarks about other fields. For example, in Practical Shooting, Rob Leatham says:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;What keeps me busy in my classes is trying to help my students learn how to think. They say, &amp;quot;Rob holds his hands like this...,&amp;quot; and they don&#39;t know that the reason I hold my hands like this is not to make myself look that way. The end result is not to hold the gun that way; holding the gun that way is the end result of doing something else.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And Brian Enos says:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;When I began ... shooting I had only basic ideas about technique. So I did what I felt was the logical thing. I found the best local shooter (who was also competitive nationally) and asked him how I should shoot. He told me without hesitation: left index finger on the trigger guard, left elbow bent and pulling back, classix boxer stance, etcetera, etcetera. I adopted the system blindly for a year or two before wondering whether there might be a system that better suited my structure and attitude, and one that better suited the shooting. This first style that I adopted didn&#39;t seem to fit me because it felt as though I was having to struggle to control the gun; I was never actually flowing with the gun as I feel I do now. My experimentation led me to pull ideas from all types of shooting styles: Isosceles, Modified Weaver, Bullseye, and from people such as Bill Blankenship, shotgunner John Satterwhite, and martial artist Bruce Lee.&lt;/p&gt;

&lt;p&gt;But ideas coming from your environment only steer you in the right direction. These ideas can limit your thinking by their very nature ...  great ideas will arise from a feeling within yourself. This intuitive awareness will allow you to accept anything that works for you and discard anything that doesn&#39;t&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I&#39;m citing those examples because they&#39;re written up in a book, but I&#39;ve heard basically the same comment from instructors in a wide variety of activities, e.g., dance instructors I&#39;ve talked to  complain that people will ask about whether, during a certain motion, the left foot should cross in front or behind the right foot, which is missing the point since what matters is the foot placement is reasonable given how the person&#39;s center of gravity is moving, which may mean that the foot should cross in front or behind, depending on the precise circumstance.&lt;/p&gt;

&lt;p&gt;The more general issue is that a person who doesn&#39;t understand the thing they&#39;re trying to copy will end up copying unimportant superficial aspects of what somebody else is doing and miss the fundamentals that drive the superficial aspects. &lt;a href=&#34;https://danluu.com/hardware-unforgiving/&#34;&gt;This even happens when there are very detailed instructions&lt;/a&gt;. Although watching what other people do can accelerate learning, especially for beginners who have no idea what to do, there isn&#39;t a shortcut to understanding something deeply enough to facilitate doing it well that can be summed up in simple rules, like &amp;quot;omit needless words&amp;quot;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:C&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:C&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;As a result, I view style as something that should fall out of your goals, and goals are ultimately a personal preference. Personally, some goals that I sometimes have are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Explain a technical topic that a lot of people don&#39;t seem to understand at a level that&#39;s accessible to almost any professional programmer

&lt;ul&gt;
&lt;li&gt;Examples: &lt;a href=&#34;https://danluu.com/branch-prediction/&#34;&gt;branch prediction&lt;/a&gt;, &lt;a href=&#34;https://danluu.com/malloc-tutorial/&#34;&gt;malloc&lt;/a&gt;, &lt;a href=&#34;https://danluu.com/intel-cat/&#34;&gt;cache partitioning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Make a case for a minority opinion (or one that was a minority opinion at the time, anyway):

&lt;ul&gt;
&lt;li&gt;Examples: &lt;a href=&#34;https://danluu.com/deconstruct-files/&#34;&gt;files are difficult to use&lt;/a&gt;, &lt;a href=&#34;https://danluu.com/startup-tradeoffs/&#34;&gt;public tech companies can pay very well&lt;/a&gt;, &lt;a href=&#34;https://danluu.com/monorepo/&#34;&gt;monorepos aren&#39;t stupid&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/why-benchmark/&#34;&gt;Measure something&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Discuss phenomena I think are interesting:

&lt;ul&gt;
&lt;li&gt;Examples: &lt;a href=&#34;https://danluu.com/discontinuities/&#34;&gt;funny discontinuities&lt;/a&gt;, &lt;a href=&#34;https://danluu.com/hardware-unforgiving/&#34;&gt;the difficulty of knowledge transfer&lt;/a&gt;, &lt;a href=&#34;https://danluu.com/wat/&#34;&gt;normalization of deviance&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When you combine one of those goals with the preference of discussing things &lt;a href=&#34;http://johnsalvatier.org/blog/2017/reality-has-a-surprising-amount-of-detail&#34;&gt;in detail&lt;/a&gt;, you get a style that&#39;s different from any of the writers mentioned above, even if you want to use humor as effectively as Steve Yegge, write for as broad an audience as Julia Evans, or write as authoritatively as Paul Graham.&lt;/p&gt;

&lt;p&gt;When I think about major components of my writing, the major thing that I view as driving how I write besides style &amp;amp; goals is process. As with style, I view this as something where a wide variety of things can work, where it&#39;s up to you to figure out what works for you.&lt;/p&gt;

&lt;p&gt;For myself, I had the following process goals when I started my blog:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Low up-front investment, with investment (possibly) increasing over time&lt;/li&gt;
&lt;li&gt;Improve writing technique/ability with each post without worrying too much about writing quality any specific post&lt;/li&gt;
&lt;li&gt;Only publish when I have something I feel is worth publishing&lt;/li&gt;
&lt;li&gt;Write a blog that I would want to subscribe to&lt;/li&gt;
&lt;li&gt;Write on my own platform&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The low-up front investment goal is because, when I surveyed blogs I&#39;d seen, one of the most common blog formats was a blog that contained a single post explaining that person was starting a blog, perhaps with another post explaining how their blog was set up, with no further posts. Another common blog format were blogs that had regular posts for a while, followed by a long dormant period with a post at the end explaining that they were going to start posting again, followed by no more posts (in some cases, there are a few such posts, with more time between each). Given the low rate of people continuing to blog after starting a blog, I figured I shouldn&#39;t bother investing in blog infra until I knew I was going to write for a while so, even though I already owned this domain name, I didn&#39;t bother figuring out how to point this domain at github pages and just set up a default install of some popular blogging software and I didn&#39;t even bother doing that until I had already written a post. In retrospect, Ben Kuhn has convinced me, in general, that I shouldn&#39;t take base rates so seriously, but I still view this one as a good move since I didn&#39;t know that I would enjoy blogging nor did I know what I would get out of blogging other than enjoyment, if anything&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:G&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:G&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;The &amp;quot;improve writing&amp;quot; goal is because I found my writing annoyingly awkward and wanted to fix that. I frequently wrote sentences or paragraphs that seemed clunky to me, like when you misspell a word and it looks wrong no matter how you try re-spelling it. Spellcheckers are now ubiquitous enough that you don&#39;t really run into the spelling problem anymore, but we don&#39;t yet have automated tools that will improve your writing (some attempts exist, but they tend to create bad writing). I didn&#39;t worry about any specific post since I figured I could easily spend years working on my writing and I didn&#39;t think that spending years re-editing a single post would be very satisfying.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://danluu.com/p95-skill/&#34;&gt;As we&#39;ve discussed before, getting feedback can greatly speed up skill acquisition&lt;/a&gt;, so I hired a professional editor whose writing I respect with the instruction &amp;quot;My writing is clunky and awkward and I&#39;d like to fix it. I don&#39;t really care about spelling and grammar issues. Can you edit my writing with that in mind?&amp;quot;. I got detailed feedback on a lot of my posts. I tried to fix the issues brought up in the feedback but, more importantly, tried to write my next post without it having the same or other previously mentioned issues. I can be a bit of a slow learner, so it sometimes took a few posts to iron out an issue but, over time, my writing improved a lot.&lt;/p&gt;

&lt;p&gt;The only publishing when I felt like publishing is because I generally prefer process goals to outcome goals, at least with respect to personal goals. I originally had a goal of spending a certain amount of time per month blogging, but I got rid of that when I realized that I&#39;d tend to spend enough time writing regardless of whether or not I made it an obligation. I think that outcome goals with respect to blogging do work for some people (e.g., &amp;quot;publish one post per week&amp;quot;), but if your goal is to improve writing quality, having outcome goals can be counterproductive (e.g., to hit a &amp;quot;publish one post per week goal&amp;quot; on limited time, someone might focus on getting something out the door and then not think about how to improve quality since, from the standpoint of the outcome goal, improving quality is a waste of time).&lt;/p&gt;

&lt;p&gt;Having a goal of writing something I&#39;d want to subscribe to is, of course, highly arbitrary. There are a bunch of things I don&#39;t like in other blogs, so I try to avoid them. Some examples:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Breaking up what could be a single post into a bunch of smaller posts&lt;/li&gt;
&lt;li&gt;Clickbait titles&lt;/li&gt;
&lt;li&gt;Repeatedly blogging about the same topic with nothing new to say

&lt;ul&gt;
&lt;li&gt;A sub-category of this is having some kind of belief and then blogging about it every time a piece of evidence shows up that confirms the belief while not mentioning evidence that shows up that disconfirms the belief&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Not having an RSS or atom feed&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Writing on my own platform is the most minor of these. A major reason for that comes out of what&#39;s happened to platforms. At the time I started my blog, a number of platforms had already come and gone. Most recently, Twitter had acquired Posterous and shut it down. For a while, Posterous was the trendiest platform around and Twitter&#39;s decision to kill it entirely broke links to many of the all-time top voted HN posts, among others. Blogspot, a previously trendy place to write, had also been acquired by Google and severely degraded the reader experience on many sites afterwards. Avoiding trendy platforms has worked out well. The two trendy platforms people were hopping on when I started blogging were &lt;a href=&#34;(https://news.ycombinator.com/item?id=4268832)&#34;&gt;Svbtle&lt;/a&gt; and Medium. &lt;a href=&#34;https://www.designernews.co/stories/44300-is-svbtle-dead&#34;&gt;Svbtle was basically abandoned shortly afterward I started my blog&lt;/a&gt; when it became clear that Medium was going to dominate Svbtle on audience size. And Medium never managed to find a good monetization strategy and severely degraded the user experience for readers in an attempt to generate enough revenue to justify its valuation after raising $160M. You can&#39;t trust someone else&#39;s platform to not disappear underneath you or radically change in the name of profit.&lt;/p&gt;

&lt;p&gt;A related thing I wanted to do was write in something that&#39;s my own space (as opposed to in internet comments). I used to write a lot of HN comments&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:H&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:H&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;, but the half-life of an HN comment is short. With very few exceptions, basically all of the views a comment is going to get will be in the first few days. With a blog, it&#39;s the other way around. A post might get burst of traffic initially but, as long as you keep writing, most traffic will come later (e.g., for my blog, I tend to get roughly twice as many hits as the baseline level when a post is on HN, and of course I don&#39;t have a post on HN most days). It isn&#39;t really much more work to write a &amp;quot;real blog post&amp;quot; instead of writing an HN comment, so I&#39;ve tended to favor writing blog posts instead of HN comments. Also, when I write here, most of the value created is split between myself and readers. If I were to write on someone else&#39;s platform, most of the value would be split between the platform and readers. If I were doing video, I might not really have a choice outside of YouTube or Twitch but, for text, I have a real choice. Looking at &lt;a href=&#34;http://exquora.thoughtstorms.info/&#34;&gt;how things worked out for people who made the other choice and decided to write comments for a platform&lt;/a&gt;, I think I made the right choice for the right seasons. I do see &lt;a href=&#34;https://twitter.com/foone/status/1066547904532242437&#34;&gt;the appeal of the reduced friction commenting on an existing platform offers&lt;/a&gt; but, even so, I&#39;d rather pay the cost of the extra friction and write something that&#39;s in my space instead of elsewhere.&lt;/p&gt;

&lt;p&gt;All of that together is basically it. That&#39;s how I write.&lt;/p&gt;

&lt;p&gt;Unlike other bloggers, I&#39;m not going to try to tell you &amp;quot;how to write usefully&amp;quot; or &amp;quot;how to write well&amp;quot; or anything like that. I agree with Steve Yegge when he says that &lt;a href=&#34;https://sites.google.com/site/steveyegge2/you-should-write-blogs&#34;&gt;you should consider writing because it&#39;s potentially high value and the value may show up in ways you don&#39;t expect&lt;/a&gt;, but how you write should really come from your goals and aptitudes.&lt;/p&gt;

&lt;h4 id=&#34;appendix-changes-in-approach-over-time&#34;&gt;Appendix: changes in approach over time&lt;/h4&gt;

&lt;p&gt;When I started the blog, I used to worry that a post wouldn&#39;t be interesting enough because it only contained a simple idea, so I&#39;d often wait until I could combine two or more ideas into a single post. In retrospect, I think many of my early posts would&#39;ve been better off as separate posts. For example, &lt;a href=&#34;https://danluu.com/bimodal-compensation/&#34;&gt;this post on compensation&lt;/a&gt; from 2016 contains the idea that compensation might be turning bimodal and that programmers are unbelievably well paid given the barriers to entry compared to other fields that are similarly remunerative, such has finance, law, and medicine. I don&#39;t think there was much value-add to combining the two ideas into a single post and I think a lot more people would&#39;ve read the bit about how unusually highly paid programmers are if it wasn&#39;t bundled into a post about compensation becoming bimodal.&lt;/p&gt;

&lt;p&gt;Another thing I used to do is avoid writing things that seem too obvious. &lt;a href=&#34;https://www.patreon.com/posts/58713950&#34;&gt;But, I&#39;ve come around to the idea that there&#39;s a lot of value in writing down obvious things&lt;/a&gt; and a number of my most influential posts have been on things I would&#39;ve previously considered too obvious to write down:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/look-stupid/&#34;&gt;https://danluu.com/look-stupid/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/people-matter/&#34;&gt;https://danluu.com/people-matter/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/culture/&#34;&gt;https://danluu.com/culture/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/learn-what/&#34;&gt;https://danluu.com/learn-what/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/productivity-velocity/&#34;&gt;https://danluu.com/productivity-velocity/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/in-house/&#34;&gt;https://danluu.com/in-house/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Excluding these recent posts, more people have told me that &lt;a href=&#34;https://danluu.com/look-stupid/&#34;&gt;https://danluu.com/look-stupid/&lt;/a&gt; has changed how they operate than all other posts combined (and the only reason it&#39;s even close is that a lot of people have told me that my discussions of compensation caused them to realize that they can find a job they enjoy more that also pays hundreds of thousands a year more than they were previously making, which is the set of posts that&#39;s drawn the most comments from people telling me that the post was pointless because everybody knows how much you can make in tech).&lt;/p&gt;

&lt;p&gt;A major, and relatively recent, style change I&#39;m trying out is using more examples. This was prompted by comments from Ben Kuhn, and I like it so far. Compared to most bloggers, &lt;a href=&#34;https://twitter.com/benskuhn/status/1431671165320376327&#34;&gt;I wasn&#39;t exactly light on examples in my early days&lt;/a&gt;, but one thing I&#39;ve noticed is that adding more examples than I would naturally tend to can really clarify things for readers; having &amp;quot;a lot&amp;quot; of examples reduces the rate at which people take away wildly different ideas than the ones I meant. A specific example of this would be, in a post discussing &lt;a href=&#34;https://danluu.com/p95-skill/&#34;&gt;what it takes to get to 95%-ile performance&lt;/a&gt;, I only provided a couple examples and &lt;a href=&#34;https://danluu.com/corrections/#p95&#34;&gt;many people filled in the blanks and thought that performance that&#39;s well above 99.9%-ile is 95%-ile, e.g., that being a chess GM&lt;/a&gt; is 95%-ile.&lt;/p&gt;

&lt;p&gt;Another example of someone who&#39;s made this change is Jamie Brandon. If you read his early posts, &lt;a href=&#34;https://www.scattered-thoughts.net/writing/imperative-thinking-and-the-making-of-sandwiches/&#34;&gt;such as this one&lt;/a&gt;, he often has a compelling idea with a nice turn of phrase, e.g., this bit about when he was working on Eve with Chris Granger:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;People regularly tell me that imperative programming is the natural form of programming because &#39;people think imperatively&#39;. I can see where they are coming from. Why, just the other day I found myself saying, &amp;quot;Hey Chris, I&#39;m hungry. I need you to walk into the kitchen, open the cupboard, take out a bag of bread, open the bag, remove a slice of bread, place it on a plate...&amp;quot; Unfortunately, I hadn&#39;t specified where to find the plate so at this point Chris threw a null pointer exception and died.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But, despite having parts that are really compelling, his earlier writing was often somewhat disconnected from the real world in a way that Jamie doesn&#39;t love when looking back on his old posts. On adding more details, Jamie says&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The point of focusing down on specific examples and keeping things as concrete as possible is a) makes me less likely to be wrong, because non-concrete ideas are very hard to falsify and I can trick myself easily b) makes it more likely that the reader absorbs the idea I&#39;m trying to convey rather than some superficially similar idea that also fits the vague text.&lt;/p&gt;

&lt;p&gt;Examples kind of pin ideas down so they can be examined properly.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Another big change, the only one I&#39;m going to discuss here that really qualifies as prose style, is that I try much harder to write things where there&#39;s continuity of something that&#39;s sometimes called &amp;quot;narrative grammar&amp;quot;. &lt;a href=&#34;https://web.archive.org/web/20180611151516/http://www.sterlingediting.com/narrative-grammar-an-exercise/&#34;&gt;This post by Nicola Griffith has some examples of this at the sentence level&lt;/a&gt;, but I also try to think about this in the larger structure of my writing. I don&#39;t think I&#39;m particularly good at this, but thinking about this more has made my writing easier to follow. This change, especially on larger scales, was really driven by working with a professional editor who&#39;s good at spotting structural issues that make writing more difficult to understand. But, at the same time, I don&#39;t worry too much if there&#39;s a reason that something is difficult to follow. A specific example of this is, if you read answers to questions on &lt;a href=&#34;https://ask.metafilter.com&#34;&gt;ask metafilter&lt;/a&gt; or reddit, any question that isn&#39;t structurally trivial will have a large fraction of answers that from people who failed to read the question and answer the wrong question, e.g., if someone asks for something that has two parts connected with an &lt;code&gt;and&lt;/code&gt;, many people will only read one half of the &lt;code&gt;and&lt;/code&gt; and give an answer that&#39;s clearly disqualified by the &lt;code&gt;and&lt;/code&gt; condition. If many people aren&#39;t going to read a short question closely enough to write up an answer that satisfies both halves of an &lt;code&gt;and&lt;/code&gt;, many people aren&#39;t going to follow the simplest things anyone might want to write. I don&#39;t think it&#39;s a good use of a writer&#39;s time to try to walk someone who can&#39;t be bothered with reading both sides of an &lt;code&gt;and&lt;/code&gt; through a structured post, but I do think there&#39;s value in trying to avoid &amp;quot;narrative grammar&amp;quot; issues that might make it harder for someone who does actually want to read.&lt;/p&gt;

&lt;h4 id=&#34;appendix-getting-feedback&#34;&gt;Appendix: getting feedback&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://danluu.com/p95-skill/&#34;&gt;As we&#39;ve previously discussed&lt;/a&gt;, feedback can greatly facilitate improvement. Unfortunately, the idea from that post, that 95%-ile performance is generally poor, also applies to feedback, making most feedback counterproductive.&lt;/p&gt;

&lt;p&gt;I&#39;ve spent a lot of time watching people get feedback in private channels and seeing how they change their writing in response to it and, at least in the channels that I&#39;ve looked at (programmers and not professional writers or editors commenting), most feedback is ignored. And when feedback is taken, because almost all feedback is bad and people generally aren&#39;t perfect or even very good at picking out good feedback, the feedback that&#39;s taken is usually bad.&lt;/p&gt;

&lt;p&gt;Fundamentally, most feedback has the issue mentioned in this post and is a form of &amp;quot;you should write it like I would&#39;ve written it&amp;quot;, which generally doesn&#39;t work unless the author of the feedback is very careful in how they give the feedback, which few people are. The feedback tends to be superficial advice that misses serious structural issues in writing. Furthermore, the feedback also tends to be &amp;quot;lowest common denominator&amp;quot; feedback that turns nice prose into Strunk-and-White-ified mediocre prose. I don&#39;t think that I have a particularly nice prose style, but I&#39;ve seen a number of people who have a naturally beautiful style ask for feedback from programmers, which has turned their writing into boring prose that anyone could&#39;ve written.&lt;/p&gt;

&lt;p&gt;The other side of this is that when people get what I think is good, substantive, feedback, the most common response is &amp;quot;nah, it&#39;s fine&amp;quot;. I think of this as the flip side of most feedback being &amp;quot;you should write it how I&#39;d write it&amp;quot;. Most people&#39;s response to feedback is &amp;quot;I want to write it how I want to write it&amp;quot;.&lt;/p&gt;

&lt;p&gt;Although this post has focused on how a wide variety of styles can work, it&#39;s also true that, given a style and a set of goals, writing can be better or worse. But, most people who are getting feedback &lt;a href=&#34;https://twitter.com/danluu/status/1428445465662603272&#34;&gt;don&#39;t know enough about writing to know what&#39;s better and what&#39;s worse&lt;/a&gt;, so they can&#39;t tell the difference between good feedback and bad feedback.&lt;/p&gt;

&lt;p&gt;One way around this is to get feedback from someone whose judgement you trust. As mentioned in the post, the way I did this was by hiring a professional editor whose writing (and editing) I respected.&lt;/p&gt;

&lt;p&gt;Another thing I do, one that&#39;s a core aspect of my personality and not really about writing, is that I take feedback relatively seriously and try to avoid having a &amp;quot;nah, it&#39;s fine&amp;quot; response to feedback. I wouldn&#39;t say that this is optimal since I&#39;ve sometimes spent far too much time on bad feedback, but a core part of how I think is that I&#39;m aware that most people are overconfident and frequently wrong because of their overconfidence, so I don&#39;t trust my own reasoning and spend a relatively large amount of time and effort thinking about feedback in an attempt to reduce my rate of overconfidence.&lt;/p&gt;

&lt;p&gt;At times, I&#39;ve spent a comically long amount of time mulling over what is, in retrospect, very bad and &amp;quot;obviously&amp;quot; incorrect feedback that I&#39;ve been wary of dismissing as incorrect. One thing I&#39;ve noticed is that, as people gain an audience, some people become more and more confident in themselves and eventually end up becoming highly overconfident. It&#39;s easy to see how this happens — as you gain prominence, you&#39;ll get more exposure and more &amp;quot;fans&amp;quot; who think you&#39;re always right and, on the flip side, you&#39;ll also get more &amp;quot;obviously&amp;quot; bad comments.&lt;/p&gt;

&lt;p&gt;Back when basically no one read my blog, most of the comments I got were quite good. As I&#39;ve gotten more and more readers, the percentage of good comments has dropped. From looking at how other people handle this, one common failure mode is that they&#39;ll see the massive number of obviously wrong comments that their posts draw and then incorrectly conclude that all of their critics are bozos and that they&#39;re basically never wrong. I don&#39;t really have an antidote to that other than &amp;quot;take criticism very seriously&amp;quot;. Since the failure mode here involves blind spots in judgement, I don&#39;t see a simple way to take a particular piece of criticism seriously that doesn&#39;t have the potential to result in incorrectly dismissing the criticism due to a blind spot.&lt;/p&gt;

&lt;p&gt;Fundamentally, my solution to this has been to avoid looking at most feedback while trying to take feedback from people I trust.&lt;/p&gt;

&lt;p&gt;When it comes to issues with the prose, one thing that we discussed above, hiring a professional editor whose writing and editing I respect and deferring to them on issues with my prose worked well.&lt;/p&gt;

&lt;p&gt;When it comes to logical soundness or just general interestingness, those are a more difficult to outsource to a single person and I have &lt;a href=&#34;https://twitter.com/Aella_Girl/status/1453936895088488449&#34;&gt;a set of people whose judgement I trust&lt;/a&gt; who look at most posts. If anyone whose judgement I trust thinks a post is interesting, I view that as a strong confirmation and I basically ignore comments that something is boring or uninteresting. For almost all of my posts that are among my top posts in terms of the number of people who told me the post was life changing for them, I got a number of comments from people whose judgement I otherwise think isn&#39;t terrible saying that the post seemed boring, pointless, too obvious to write, or just plain uninteresting. I used to take comments that something was uninteresting seriously but, in retrospect, that was a mistake that cost me a lot of time and didn&#39;t improve my writing. I think this isn&#39;t so different from people who say &amp;quot;write how I write&amp;quot;; instead, it&#39;s people who have a similar mental model, but with respect to interesting-ness instead, who can&#39;t imagine that other people would find something interesting that they don&#39;t. Of course, not everyone&#39;s mind works like that, but people who are good at modeling what other people find interesting generally don&#39;t leave feedback like &amp;quot;this is boring/pointless&amp;quot;, so feedback of that form is almost guaranteed to be worthless.&lt;/p&gt;

&lt;p&gt;When it comes to the soundness of an argument, I take the opposite approach that I do for interestingness, in that I take negative comments very seriously and I don&#39;t do much about positive comments. I have, sometimes, wasted a lot of time on particular posts because of that. My solution to that has been to try to ignore feedback from people who regularly give bad feedback. That&#39;s something I think of as dangerous to do since selectively choosing to ignore feedback is a good way to create an echo chamber, but really seriously taking the time to think through feedback when I don&#39;t see a logical flaw is time consuming enough that I don&#39;t think there&#39;s really another alternative given how I re-evaluate my own work when I get feedback.&lt;/p&gt;

&lt;p&gt;One thing I&#39;ve started doing recently that&#39;s made me feel a lot better about this is to look at what feedback people give to others. People who give me bad feedback generally also give other people feedback that&#39;s bad in pretty much exactly the same ways. Since I&#39;m not really concerned that I have some cognitive bias that might mislead me into thinking I&#39;m right and their feedback is wrong when it comes to their feedback on other people&#39;s writing, instead of spending hours trying to figure out if there&#39;s some hole in how I&#39;m explaining something that I&#39;m missing, I can spend minutes seeing that their feedback on someone else&#39;s writing is bogus feedback and then see that their feedback on my writing is bogus in exactly the same way.&lt;/p&gt;

&lt;h4 id=&#34;appendix-where-i-get-ideas&#34;&gt;Appendix: where I get ideas&lt;/h4&gt;

&lt;p&gt;I often get asked how I get ideas. I originally wasn&#39;t going to say anything about this because I don&#39;t have much to say, but Ben Kuhn strongly urged me to add this section &amp;quot;so that other people realize what an alien you are&amp;quot;.&lt;/p&gt;

&lt;p&gt;My feeling is that the world is so full of interesting stuff that ideas are everywhere. I have on the order of a hundred drafts lying around that I think are basically publishable that I haven&#39;t prioritized finishing up for one reason or another. If I think of ideas where I&#39;ve sketched out a post in my head but haven&#39;t written it down, the number must well into the thousands. If I were to quit my job and then sit down to write full-time until I died, I think I wouldn&#39;t run out of ideas even if I stuck to ones I&#39;ve already had. The world is big and wondrous and fractally interesting.&lt;/p&gt;

&lt;p&gt;For example, I recently took up surf skiing (a kind of kayaking) and I&#39;d say that, after a few weeks, I had maybe twenty or so blog post ideas that I think could be written up for a general audience in the sense that &lt;a href=&#34;https://danluu.com/branch-prediction/&#34;&gt;this post on branch prediction&lt;/a&gt; is written for a general audience, in that it doesn&#39;t assume any hardware background. I could write two posts on different technical aspects of canoe paddle evolution and design as well as two posts on cultural factors and how they impacted the update of different canoe paddle designs. Kayak paddle design has been, in recent history, a lot richer, and that could easily be another five or six posts. The technical aspects of hull design are richer still and could be an endless source of posts, although I only have four particular posts in mind at the moment, but the cultural and historical aspects also seem interesting to me and that&#39;s what rounds out the twenty things in my head with respect to that.&lt;/p&gt;

&lt;p&gt;I don&#39;t have twenty posts on kayaking and canoeing in my head because I&#39;m particularly interested in kayaking and canoeing. Everything seems interesting enough to write twenty posts about. A lot of my posts that exist are part of what might become a much longer series of posts if I ever get around to spending the time to write them up. For example, &lt;a href=&#34;https://danluu.com/bad-decisions/&#34;&gt;this post on decision making in baseball&lt;/a&gt; was, in my head, the first of a long-ish (10+) post series on decision making that I never got around to writing that I suspect I&#39;ll never write because there&#39;s too much other interesting stuff to write about and not enough time.&lt;/p&gt;

&lt;h4 id=&#34;appendix-other-writing-about-writing&#34;&gt;Appendix: other writing about writing&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Richard Lanham: &lt;a href=&#34;https://amzn.to/3DTiVU2&#34;&gt;Analyzing Prose&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;I think it&#39;s not easy to take anything directly actionable away from this book, but I found the way that it dissects the rhythm of prose to be really interesting&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Robert Alter: &lt;a href=&#34;https://amzn.to/3oOs3VT&#34;&gt;The Five Books of Moses&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;For the footnotes on why Robert Alter made certain subtle choices in his translation&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Francis-Noel Thomas &amp;amp; Mark Turner: &lt;a href=&#34;https://amzn.to/3ymHFDh&#34;&gt;Clear and Simple as the Truth&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;If you want to write in a clean, authoritative, style&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Gary Hoffman &amp;amp; Glynis Hoffman: &lt;a href=&#34;https://amzn.to/33qX6if&#34;&gt;Adios, Strunk &amp;amp; White: A Handbook for the new Academic Essay&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Tracy Kidder &amp;amp; Richard Todd: &lt;a href=&#34;https://amzn.to/3DRTCSp&#34;&gt;Good Prose: The Art of Nonfiction&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;This book was recommended to me by Kelly Eskridge for its in-depth look at how an editor and a writer interact and I found it useful to keep in mind when working with an editor; reading this book is probably an inefficient way to get a better understanding of what working with a good editor looks like, but it&#39;s probably worth reading if you&#39;re curious how the author of &lt;a href=&#34;https://amzn.to/3ETX7Jw&#34;&gt;The Soul of a New Machine&lt;/a&gt; writes; if you&#39;re not sure what an editor could do for you, this is a nice read&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Steve Yegge: &lt;a href=&#34;https://sites.google.com/site/steveyegge2/you-should-write-blogs&#34;&gt;You Should Write Blogs&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;In particular, for &amp;quot;Reason #3&amp;quot;, the Jacob Gabrielson / Zero Config story, although the whole thing is worth reading&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Lawrence Tratt: &lt;a href=&#34;https://tratt.net/laurie/blog/entries/what_ive_learnt_so_far_about_writing_research_papers.html&#34;&gt;What I’ve Learnt So Far About Writing Research Papers&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Well written, just like everyone else from Lawrence. Also, I think it&#39;s interesting in that Lawrence has a completely different process than mine in most major dimensions, but the resultant style is relatively similar if you compare across all programming bloggers (certainly more similar than any of the authors mentioned in the body of this post)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Julia Evans: &lt;a href=&#34;https://jvns.ca/blog/2020/12/05/how-i-write-useful-programming-comics/&#34;&gt;How I write useful programming comics&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Nice explanation of what makes Julia&#39;s zines tick; also completely different from my approach, but this time with a completely different result&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Yossi Kreinen: &lt;a href=&#34;https://yosefk.com/blog/blogging-is-hard.html&#34;&gt;Blogging is hard&lt;/a&gt; (the title is a contrast to his next post, &amp;quot;low level is easy&amp;quot;)

&lt;ul&gt;
&lt;li&gt;A rare example of a first post that&#39;s basically &amp;quot;I&#39;m going to write a blog&amp;quot; that&#39;s both interesting and has interesting future posts that follow; also Yossi&#39;s writing philosophy&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;appendix-things-that-increase-popularity-that-i-generally-don-t-do&#34;&gt;Appendix: things that increase popularity that I generally don&#39;t do&lt;/h4&gt;

&lt;p&gt;Here are some things that I think work based on observing what works for other people that I don&#39;t do, but if you want a broad audience, perhaps you can try some of them out:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Use clickbait titles

&lt;ul&gt;
&lt;li&gt;Swearing or saying that something &amp;quot;is cancer&amp;quot; or &amp;quot;is the Vietnam of X&amp;quot; or some other highly emotionally loaded phrase seems to be particularly effective&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Talk-up prestige/accomplishments/titles&lt;/li&gt;
&lt;li&gt;Use an authoritative tone and/or style&lt;/li&gt;
&lt;li&gt;Write things with an angry tone or that are designed to induce anger&lt;/li&gt;
&lt;li&gt;Write frequently&lt;/li&gt;
&lt;li&gt;Get endorsements from people&lt;/li&gt;
&lt;li&gt;Write about hot, current, topics

&lt;ul&gt;
&lt;li&gt;Provide takes on recent events&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Use deliberately outrageous / controversial framings on topics&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;appendix-some-snippets-of-writing&#34;&gt;Appendix: some snippets of writing&lt;/h4&gt;

&lt;p&gt;In case you&#39;re not familiar with the writers mentioned, here are some snippets that I think are representative of their writing styles:&lt;/p&gt;

&lt;p&gt;Joel Spolsky:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Why I really care is that Microsoft is vacuuming up way too many programmers. Between Microsoft, with their shady recruiters making unethical exploding offers to unsuspecting college students, and Google (you&#39;re on my radar) paying untenable salaries to kids with more ultimate frisbee experience than Python, whose main job will be to play foosball in the googleplex and walk around trying to get someone...anyone...to come see the demo code they&#39;ve just written with their &amp;quot;20% time,&amp;quot; doing some kind of, let me guess, cloud-based synchronization... between Microsoft and Google the starting salary for a smart CS grad is inching dangerously close to six figures and these smart kids, the cream of our universities, are working on hopeless and useless architecture astronomy because these companies are like cancers, driven to grow at all cost, even though they can&#39;t think of a single useful thing to build for us, but they need another 3000-4000 comp sci grads next week. And dammit foosball doesn&#39;t play &lt;i&gt;itself&lt;/i&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Paul Graham:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A couple years ago a venture capitalist friend told me about a new startup he was involved with. It sounded promising. But the next time I talked to him, he said they&#39;d decided to build their software on Windows NT, and had just hired a very experienced NT developer to be their chief technical officer. When I heard this, I thought, these guys are doomed. One, the CTO couldn&#39;t be a first rate hacker, because to become an eminent NT developer he would have had to use NT voluntarily, multiple times, and I couldn&#39;t imagine a great hacker doing that; and two, even if he was good, he&#39;d have a hard time hiring anyone good to work for him if the project had to be built on NT.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Steve Yegge:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;When I read this book for the first time, in October 2003, I felt this horrid cold feeling, the way you might feel if you just realized you&#39;ve been coming to work for 5 years with your pants down around your ankles. I asked around casually the next day: &amp;quot;Yeah, uh, you&#39;ve read that, um, Refactoring book, of course, right? Ha, ha, I only ask because I read it a very long time ago, not just now, of course.&amp;quot; Only 1 person of 20 I surveyed had read it. Thank goodness all of us had our pants down, not just me.&lt;/p&gt;

&lt;p&gt;This is a wonderful book about how to write good code, and there aren&#39;t many books like it. None, maybe. They don&#39;t typically teach you how to write good code in school, and you may never learn on the job. It may take years, but you may still be missing some key ideas. I certainly was.
...
If you&#39;re a relatively experienced engineer, you&#39;ll recognize 80% or more of the techniques in the book as things you&#39;ve already figured out and started doing out of habit. But it gives them all names and discusses their pros and cons objectively, which I found very useful. And it debunked two or three practices that I had cherished since my earliest days as a programmer. Don&#39;t comment your code? Local variables are the root of all evil? Is this guy a madman? Read it and decide for yourself!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Julia Evans:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Right now I’m on a million-hour train ride from New York to Montreal. So I’m looking at the output of strace because, uh, &lt;code&gt;strace&lt;/code&gt; is cool, and it is teaching me some things about how the command line tools I use all the time work.&lt;/p&gt;

&lt;p&gt;What &lt;code&gt;strace&lt;/code&gt; does is capture every single system call that gets called when executing a program. System calls are the interface between userspace programs and the kernel, so looking at the output from strace is a fun way to understand how Linux works, and what’s really involved in running a program.&lt;/p&gt;

&lt;p&gt;For example! &lt;code&gt;killall&lt;/code&gt;! I ran&lt;/p&gt;

&lt;p&gt;&lt;code&gt;strace killall ruby1.9.1 2&amp;gt; killall-log.&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;i&gt;Thanks to Yossi Kreinin, Ben Kuhn, Laurence Tratt, Heath Borders, Jamie Brandon, Julia Evans, Vegard Nossum, Julien Kirch, Bram Delver, and Pam Wolf for comments/corrections/discussion.&lt;/i&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:P&#34;&gt;&lt;p&gt;What&#39;s worked can mean very different things for different people, but for this section we&#39;re going to look at popular blogs because, when people I know have frustratedly stopped writing after writing a blog for a while, the most common reason has been that their blog had basically no readers.&lt;/p&gt;

&lt;p&gt;Of course, many people write without a goal of having readers and some people even try to avoid having more than a few readers (by &amp;quot;locking&amp;quot; posts in some way so that only &amp;quot;friends&amp;quot; have access) but, I don&#39;t think the idea that &amp;quot;what works&amp;quot; is very broad and that many different styles can work changes if the goal is to have just a few friends read a blog.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:P&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:O&#34;&gt;This is pretty arbitrary. In other social circles, Jeff Atwood, Raymond Chen, Scott Hanselman, etc., might be on the list, but this wouldn&#39;t change the point since all of these folks also have different styles from each other as well as the people on my list.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:O&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:7&#34;&gt;2017 is the endpoint since I reduced how much I pay attention to programming internet culture around then and don&#39;t have a good idea on what people I know were reading after 2017.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:7&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:C&#34;&gt;In sports, elite coaches that have really figured out how to cue people to do the right thing can greatly accelerate learning but, outside of sports, although there&#39;s no shortage of people who are willing to supply coaching, it&#39;s rare to find one who&#39;s really figured out what cues students can be given that will help them get to the right thing much more quickly than they would&#39;ve if they just naively measured what they were doing and applied a bit of introspection.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:C&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:G&#34;&gt;It turns out that blogging has been pretty great for me (e.g., my blog got me my current job, facilitated meeting a decent fraction of my friends, results in people sending me all sorts of interesting stories about goings-on in the industry, etc.), but I don&#39;t think that was a predictable outcome before starting the blog. My guess, based on base rates, was that the most likely outcome was failure.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:G&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:H&#34;&gt;Such as &lt;a href=&#34;https://news.ycombinator.com/item?id=6315483&#34;&gt;this comment on how cushy programming jobs are compared to other lucrative jobs&lt;/a&gt; (which turned into the back half of &lt;a href=&#34;https://danluu.com/bimodal-compensation/&#34;&gt;this post on programmer compensation&lt;/a&gt;, &lt;a href=&#34;https://news.ycombinator.com/item?id=4652367&#34;&gt;this comment on writing pay&lt;/a&gt;, and &lt;a href=&#34;https://news.ycombinator.com/item?id=4920429&#34;&gt;this comment on the evolution of board game design&lt;/a&gt;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:H&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Some latency measurement pitfalls</title>
      <link>https://danluu.com/latency-pitfalls/</link>
      <pubDate>Mon, 06 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://danluu.com/latency-pitfalls/</guid>
      <description>

&lt;p&gt;&lt;small&gt;&lt;i&gt;This is a pseudo-transcript (actual words modified to be more readable than a 100% faithful transcription) of a short lightning talk I did at Twitter a year or two ago, on pitfalls of how we use latency metrics (with the actual service names anonymized per a comms request). Since this presentation, significant progress has been made on this on the infra side, so the situation is much improved over what was presented, but I think this is still relevant since, from talking to folks at peer companies, many folks are facing similar issues.&lt;/i&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;We frequently use &lt;a href=&#34;https://research.google/pubs/pub40801/&#34;&gt;tail latency&lt;/a&gt; metrics here at Twitter. Most frequently, service owners want to get cluster-wide or Twitter-wide latency numbers for their services. Unfortunately, the numbers that service owners tend to use differ from what we&#39;d like to measure due some historical quirks in our latency measurement setup:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Opaque, uninstrumented, latency&lt;/li&gt;
&lt;li&gt;Lack of, cluster-wide, aggregation capability&lt;/li&gt;
&lt;li&gt;Minutely resolution&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;opaque-uninstrumented-latency&#34;&gt;Opaque, uninstrumented, latency&lt;/h4&gt;

&lt;p&gt;When we look at the dashboards for most services, the latency metrics that are displayed and are used for alerting are usually from the server the service itself is running on. Some services that have dashboards set up by senior SREs who&#39;ve been burned by invisible latency before will also have the service&#39;s client-observed latency from callers of the service. I&#39;d like to discuss three issues with this setup.&lt;/p&gt;

&lt;p&gt;For the purposes of this talk, we can view a client request as passing through the following pipeline after client &amp;quot;user&amp;quot; code passes the request to our RPC layer, Finagle(&lt;a href=&#34;https://twitter.github.io/finagle/&#34;&gt;https://twitter.github.io/finagle/&lt;/a&gt;), and before client user code receive the response (the way Finagle currently handles requests, we can&#39;t get timestamps for a particular request once the request is handled over to the network library we use, &lt;a href=&#34;(https://netty.io/)&#34;&gt;netty&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;client netty -&amp;gt; client Linux -&amp;gt; network -&amp;gt; server Linux -&amp;gt; server netty -&amp;gt; server &amp;quot;user code&amp;quot; -&amp;gt; server netty -&amp;gt; server Linux -&amp;gt; network -&amp;gt; client Linux -&amp;gt; client netty&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;As we previously saw in [an internal document quantifying the impact of &lt;a href=&#34;https://www.kernel.org/doc/html/latest/scheduler/sched-bwc.html&#34;&gt;CFS bandwidth control throttling&lt;/a&gt; and how our use of excessively large thread pools causes throttling]&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:W&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:W&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;, we frequently get a lot of queuing in and below netty, which has the knock-off effect of causing services to get throttled by the kernel, which often results in a lot of opaque latency, especially when under high load, when we most want dashboards to show correct latency numbers..&lt;/p&gt;

&lt;p&gt;When we sample latency at the server, we basically get latency from&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Server service &amp;quot;user&amp;quot; code&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When we sample latency at the client, we basically get&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Server service &amp;quot;user&amp;quot; code&lt;/li&gt;
&lt;li&gt;Server-side netty&lt;/li&gt;
&lt;li&gt;Server-side Linux latency&lt;/li&gt;
&lt;li&gt;Client-side Linux latency&lt;/li&gt;
&lt;li&gt;Client-side netty latency&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Two issues with this are that we don&#39;t, with metrics data, have a nice way to tell if latency is in the opaque parts of the stack are coming from the client or the server. As a service owner, if you set alerts based on client latency, you&#39;ll get alerted when client latency rises because there&#39;s too much queuing in netty or Linux on the client even when your service is running smoothly.&lt;/p&gt;

&lt;p&gt;Also, the client latency metrics that are reasonable to look at given what we expose give you latency for all servers a client talks to, which is a really different view from what we see on server metrics, which gives us per-server latency numbers and there isn&#39;t a good way to aggregate per-server client numbers across all clients, so it&#39;s difficult to tell, for example, if a particular instance of a server has high latency in netty.&lt;/p&gt;

&lt;p&gt;Below are a handful examples of cluster-wide measurements of latency measured at the client vs. the server. These were deliberately selected to show a cross-section of deltas between the client and the server.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://danluu.com/images/latency-pitfalls/service-1.png&#34; alt=&#34;Graph showing large difference between latency measured at the client vs. at the server&#34; width=&#34;1259&#34; height=&#34;778&#34;&gt;&lt;/p&gt;

&lt;p&gt;This is a &lt;a href=&#34;https://en.wikipedia.org/wiki/Cumulative_distribution_function&#34;&gt;CDF&lt;/a&gt;, presented with the standard orientation for a CDF, with the percentile is on the y-axis and the value on the x-axis, which makes down and to the right higher latency and up and to the left lower latency, and a flatter line meaning latency is increasing quickly and a steeper line meaning that latency is increasing more slowly.&lt;/p&gt;

&lt;p&gt;Because the chart is log scale on both axes, the difference between client and server latency is large even though the lines don&#39;t look all that far apart. For example, if we look at 99%-ile latency, we can see that it&#39;s ~16ms when measured at the server and ~240ms when measured at the client, a factor of 15 difference. Alternately, if we look at a fixed latency, like 240ms, and look up the percentile, we see that&#39;s 99%-ile latency on the client, but well above 99.9%-ile latency on the server.&lt;/p&gt;

&lt;p&gt;The graphs below have similar properties, although the delta between client and server will vary.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://danluu.com/images/latency-pitfalls/service-2.png&#34; alt=&#34;Graph showing moderate at the client vs. at the server until p99.5, with large difference above p99.5&#34; width=&#34;1259&#34; height=&#34;778&#34;&gt;
&lt;img src=&#34;https://danluu.com/images/latency-pitfalls/service-3.png&#34; alt=&#34;Graph showing small difference between latency measured at the client vs. at the server until p74, with increasing divergence after that&#34; width=&#34;1259&#34; height=&#34;778&#34;&gt;
&lt;img src=&#34;https://danluu.com/images/latency-pitfalls/service-4.png&#34; alt=&#34;Graph showing moderate difference between latency measured at the client vs. at the server until close to client timeout value, with large divergence near timeout value&#34; width=&#34;1259&#34; height=&#34;778&#34;&gt;
&lt;img src=&#34;https://danluu.com/images/latency-pitfalls/service-5.png&#34; alt=&#34;Graph showing small difference between latency measured at the client vs. at the server unil p999, with rapid increasing after that&#34; width=&#34;1259&#34; height=&#34;778&#34;&gt;&lt;/p&gt;

&lt;p&gt;We can see that latencies often differ significantly when measured at the client vs. when measured at the server and that, even in cases where the delta is small for lower percentiles, it sometimes gets large at higher percentiles, where more load can result in more queueing and therefore more latency in netty and the kernel.&lt;/p&gt;

&lt;p&gt;One thing to note is that, for any particular measured server latency value, we see a very wide range of client latency values. For example, here&#39;s a zoomed in scatterplot of client vs. server latency for &lt;code&gt;service-5&lt;/code&gt;. If we were to zoom out, we&#39;d see that for a request with a server-measured latency of 10ms, we can see client-measured latencies as high as 500ms. More generally, we see many requests where the server-measured latency is very similar to the client-measured latency, with a smattering of requests where the server-measured latency is a very inaccurate representation of the client-measured latency. In almost all of those cases, the client-measured latency is higher due to queuing in a part of the stack that&#39;s opaque to us and, in a (very) few cases, the client-measured latency is lower due to some issues in our instrumentation. In the plot below, due to how we track latencies, we only have 1ms granularity on latencies. The points on the plots below have been randomly jittered by +/- 0.4ms to give a better idea of the distribution at points on the plot that are very dense.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://danluu.com/images/latency-pitfalls/service-scatter.png&#34; alt=&#34;Per-request scatterplot of client vs. server latency, showing that any particular server latency value can be associated with a very wide range of client latency values&#34; width=&#34;1259&#34; height=&#34;778&#34;&gt;&lt;/p&gt;

&lt;p&gt;While it&#39;s possible to plumb instrumentation through netty and the kernel to track request latencies after Finagle has handed them off (the kernel even has hooks that would make this somewhat straightforward), that&#39;s probably more work than is worth it in the near future. If you want to get an idea for how your service is impacted by opaque latency, it&#39;s fairly easy to get a rough idea with &lt;a href=&#34;https://zipkin.io/&#34;&gt;Zipkin&lt;/a&gt; if you leverage &lt;a href=&#34;https://danluu.com/tracing-analytics/&#34;&gt;the work Rebecca Isaacs, Jonathan Simms, and Rahul Iyer have done&lt;/a&gt;, which is how I generated the plots above. The code for these is checked into [a path in our monorepo] and you can plug in your own service names if you just want to check out a different service.&lt;/p&gt;

&lt;h4 id=&#34;lack-of-cluster-wide-aggregation-capability&#34;&gt;Lack of cluster-wide aggregation capability&lt;/h4&gt;

&lt;p&gt;In the examples above, we were able to get cluster-wide latency percentiles because we used data from Zipkin, which attempts to sample requests uniformly at random. For a variety of reasons, service owners mostly rely on metrics data which, while more complete because it&#39;s unsampled, doesn&#39;t let us compute cluster-wide aggregates because we pre-compute fixed aggregations on a per-shard basis and there&#39;s no way to reconstruct the cluster-wide aggregate from the per-shard aggregates.&lt;/p&gt;

&lt;p&gt;From looking at dashboards of our services, the most common latency target is a per-shard average of shard-level 99%-ile latency (with some services that are deep in the request tree, like cache, using numbers further in the tail). Unfortunately, taking the average of per-shard tail latency defeats the purpose of monitoring tail latency. If &lt;a href=&#34;https://brooker.co.za/blog/2021/04/19/latency.html&#34;&gt;we think about why we want to use tail latency&lt;/a&gt; because, when we have high fanout and high depth request trees, a very small fraction of server responses slowing down can slow down many or most top-level requests, taking the average of tail latency fails to capture the value of using tail latency since the average of shard-level tail latencies fails to capture the property that a small fraction of server responses being slow can slow down many or most requests while &lt;a href=&#34;https://brooker.co.za/blog/2017/12/28/mean.html&#34;&gt;also missing out on the advantages of looking at cluster-wide averages&lt;/a&gt;, which can be reconstructed from per-shard averages.&lt;/p&gt;

&lt;p&gt;For example, when we have a few bad nodes returning , that has a small impact on the average per-shard tail latency even though cluster-wide tail latency will be highly elevated. As we saw in [a document quantifying the extent of machine-level issues across the fleet as well as the impact on data integrity and performance]&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:H&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:H&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;, we frequently have host-level issues that can drive tail latency on a node up by one or more orders of magnitude, which can sometimes drive median latency on the node up past the tail latency on other nodes. Since a few or even one such node can determine the tail latency for a cluster, taking the average across all nodes can be misleading, e.g., if we have a 100 node cluster where tail latency is up by 10x on one node, this might cause our average of cluster-wide latencies to increase by a factor of 0.99 + 0.01 * 10 = 1.09 when the actual increase in tail latency is much larger.&lt;/p&gt;

&lt;p&gt;Some service owners try to get a better approximation of cluster-wide tail latency by taking a percentile of the 99%-ile, often the 90%-ile or the 99%-ile, but this doesn&#39;t work either and there is, in general, no per-shard percentile or other aggregation of per-shard tail latencies that can reconstruct the cluster-level tail latency.&lt;/p&gt;

&lt;p&gt;Below are plots of the various attempts that people have on dashboards to get cluster-wide latency with instance-level metrics data vs. actual (sampled) cluster-wide latency on a service which makes the percentile of percentile attempts more accurate than for smaller services. We can see the correlation is very weak and has the problem we expect, where the average of the tail isn&#39;t influenced by outlier shards as much as it &amp;quot;should be&amp;quot; and the various commonly used percentiles either aren&#39;t influenced enough or are influenced too much, on average and are also weakly correlated with the actual latencies. Because we track metrics with minutely granularity, each point in the graphs below represents one minute, with the sampled cluster-wide p999 latency on the x-axis and the dashboard aggregated metric value on the y-axis. Because we have 1ms granularity on individual latency measurements from our tracing pipeline, points are jittered horizontally +/- 0.3ms to give a better idea of the distribution (no such jitter is applied vertically since we don&#39;t have this limitation in our metrics pipeline, so that data is higher precision).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://danluu.com/images/latency-pitfalls/cluster-1.png&#34; alt=&#34;Per-minute scatterplot of average of per-shard p999 vs. actual p999, showing that average of per-shard p999 is a very poor approximation&#34; width=&#34;1259&#34; height=&#34;778&#34;&gt;
&lt;img src=&#34;https://danluu.com/images/latency-pitfalls/cluster-2.png&#34; alt=&#34;Per-minute scatterplot of p99 of per-shard p999 vs. actual p999, showing that p99 of per-shard p999 is a poor approximation&#34; width=&#34;1259&#34; height=&#34;778&#34;&gt;
&lt;img src=&#34;https://danluu.com/images/latency-pitfalls/cluster-3.png&#34; alt=&#34;Per-minute scatterplot of p999 of per-shard p999 vs. actual p999, showing that p999 of per-shard p999 is a very poor approximation&#34; width=&#34;1259&#34; height=&#34;778&#34;&gt;&lt;/p&gt;

&lt;p&gt;The correlation between cluster-wide latency and aggregations of per-shard latency is weak enough that even if you pick the aggregation that results in the correct average behavior, the value will still be quite wrong for almost all samples (minutes). Given our infra, the only solutions that can really work here are extending our tracing pipeline for use on dashboards and with alerts or adding metric histograms to Finagle and plumbing that data up through everything and the into [dashboard software] so that we can get proper cluster-level aggregations&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:M&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:M&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;While it&#39;s popular to take the average of tail latencies because it&#39;s easy and people are familiar with it (e.g., the TL of observability at [redacted peer company name] has said that they shouldn&#39;t bother with anything other than averages because everyone just wants averages), taking the average or another aggregation of shard-level tail latencies has neither the properties people want nor the properties people expect.&lt;/p&gt;

&lt;h4 id=&#34;minutely-resolution&#34;&gt;Minutely resolution&lt;/h4&gt;

&lt;p&gt;Another, independent, issue that&#39;s a gap in our ability to observe what&#39;s going on with our infrastructure is that we only collect metrics at a minutely granularity. Rezolus does metrics collection on a secondly (and in some cases, even sub-secondly) granularity, but for reasons that are beyond the scope of this talk, it&#39;s generally only used for system-level metrics (with a few exceptions).&lt;/p&gt;

&lt;p&gt;We&#39;ve all seen incidents where some bursty, sub-minutely event, is the cause of a problem. Let&#39;s look at an example of one such incident. In this incident, a service had elevated latency and error rate. Looking at the standard metrics we export wasn&#39;t informative, but looking at sub-minutely metrics immediately reveals a clue:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://danluu.com/images/latency-pitfalls/minutely-1.png&#34; alt=&#34;Plot of per-request latency for sampled requests, showing large spike followed by severely reduced request rate&#34; width=&#34;1259&#34; height=&#34;778&#34;&gt;&lt;/p&gt;

&lt;p&gt;For this particular shard of a cache (and many others, not shown), there&#39;s a very large increase in latency at &lt;code&gt;time 0&lt;/code&gt;, followed by 30 seconds of very low request rate. The 30 seconds is because shards of &lt;code&gt;service-6&lt;/code&gt; were configured to mark servers they talk to as dead for 30 seconds if &lt;code&gt;service-6&lt;/code&gt; clients encounter too many failed requests. This decision is distributed, which is why the request rate to the impacted shard of &lt;code&gt;cache-1&lt;/code&gt; isn&#39;t zero; some shards of &lt;code&gt;service-6&lt;/code&gt; didn&#39;t send requests to that particular shard of &lt;code&gt;cache-1&lt;/code&gt; during during the period of elevated latency, so they didn&#39;t mark that shard of &lt;code&gt;cache-1&lt;/code&gt; as dead and continued to issue requests.&lt;/p&gt;

&lt;p&gt;A sub-minutely view of request latency made it very obvious what mechanism caused elevated error rates and latency in &lt;code&gt;service-6&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;One thing to note is that the lack of sub-minutely visibility wasn&#39;t the only issue here. Much of the elevated latency was in places that are invisible to the latency metric, resulting in monitoring &lt;code&gt;cache-1&lt;/code&gt; latencies insufficient to detect the issue. Below, the reported latency metrics for a single instance of &lt;code&gt;cache-1&lt;/code&gt; are the blue points and the measured (sampled) latency the client observed is the black line&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:O&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:O&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;. Reported p99 latency is 0.37ms, but actual p99 latency is ~580ms, an over three order of magnitude difference.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://danluu.com/images/latency-pitfalls/minutely-2.png&#34; alt=&#34;Plot of reported metric latency vs. latency from trace data, showing extremely large difference between metric latency and trace latency&#34; width=&#34;1259&#34; height=&#34;778&#34;&gt;&lt;/p&gt;

&lt;h4 id=&#34;summary&#34;&gt;Summary&lt;/h4&gt;

&lt;p&gt;Although our existing setup for reporting and alerting on latency works pretty decently, in that the site generally works and our reliability is actually quite good compared to peer companies in our size class, we do pay some significant costs as a result of our setup.&lt;/p&gt;

&lt;p&gt;One is that we often have incidents where it&#39;s difficult to see what&#39;s going on without using tools that are considered specialized that most people don&#39;t use, adding to the toil of being on call. Another is that, due to large margins of error in our estimates of cluster-wide latencies, we have to have to provision a very large amount of slack and keep latency SLOs that are much stricter than the actual latencies we want to achieve to avoid user-visible incidents. This increases operating costs as we&#39;ve seen in [a document comparing per-user operating costs to companies that serve similar kinds of and levels of traffic].&lt;/p&gt;

&lt;p&gt;&lt;i&gt;If you enjoyed this post you might like to read about &lt;b&gt;&lt;a href=&#34;https://danluu.com/perf-tracing/&#34;&gt;tracing on a single host vs. sampling profilers&lt;/a&gt;&lt;/b&gt;&lt;/i&gt;.&lt;/p&gt;

&lt;h4 id=&#34;appendix-open-vs-closed-loop-latency-measurements&#34;&gt;Appendix: open vs. closed loop latency measurements&lt;/h4&gt;

&lt;p&gt;Some of our synthetic benchmarking setups, such as setup-1, use &amp;quot;closed-loop&amp;quot; measurement, where they effectively send a single request, wait for it to come back, and then send another request. Some of these allow for a degree of parallelism, where N request can be in flight at once but that still has similar problems in terms of realism.&lt;/p&gt;

&lt;p&gt;For a toy example of the problem, let&#39;s say that we have a service that, in production, receives exactly 1 request every second and that the service has a normal response time of 1/2 second. Under normal behavior, if we issue requests at 1 per second, we&#39;ll observe that the mean, median, and all percentile request times are 1/2 second. As an exercise for the reader, compute the mean and 90%-ile latency if the service has no parallelism and one request takes 10 seconds in the middle of a 1 minute benchmark run for a closed vs. open loop benchmark setup where the benchmarking setup issues requests at 1 per second for the open loop case, and 1 per second but waits for the previous request to finish in the closed loop case.&lt;/p&gt;

&lt;p&gt;For more info on this, see &lt;a href=&#34;https://psy-lob-saw.blogspot.com/2015/03/fixing-ycsb-coordinated-omission.html&#34;&gt;Nitsan Wakart&#39;s write-up on fixing this issue in the YCSB benchmark&lt;/a&gt; or &lt;a href=&#34;https://www.youtube.com/watch?v=9MKY4KypBzg&#34;&gt;Gil Tene&#39;s presentation on this issue&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&#34;appendix-use-of-unweighted-averages&#34;&gt;Appendix: use of unweighted averages&lt;/h4&gt;

&lt;p&gt;An common issue with averages on dashboards that I&#39;ve looked at that&#39;s independent of the issues that come up when we take the average of tail latencies is that an unweighted average frequently underestimates the actual latency.&lt;/p&gt;

&lt;p&gt;Two places I commonly see an unweighted average are when someone gets an overall latency by taking an unweighted average across datacenters and when someone gets a cluster-wide latency by taking an average across shards. Both of these have the same issue, that shards that have lower load tend to have lower latency. This is especially pronounced when we fail away from a datacenter. Services that incorrectly use an unweighted average across datacenters will often show decreased latency even though actually served requests have increased latency.&lt;/p&gt;

&lt;p&gt;&lt;i&gt;Thanks to Ben Kuhn for comments/corrections/discussion.&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;&lt;link rel=&#34;prefetch&#34; href=&#34;https://danluu.com/&#34;&gt;
&lt;link rel=&#34;prefetch&#34; href=&#34;https://danluu.com/perf-tracing/&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:W&#34;&gt;This is another item that&#39;s somewhat out of date, since this document motivated work from Flavio Brasil and Vladimir Kostyukov to do work on Finagle that reduces the impact of this problem and then, later, work from my then-intern, Xi Yang, on a patch to the kernel scheduler that basically eliminates the problem by preventing cgroups from exceeding their CPU allocation (as opposed to the standard mechanism, which allows cgroups to exceed their allocation and then effectively puts the cgroup to sleep until its amortized cpu allocation is no longer excessive, which is very bad for tail latency).
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:W&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:H&#34;&gt;This is yet another item that&#39;s out of date since the kernel, HWENG, and the newly created fleet health team have expended significant effort to drive down the fraction of unhealthy machines.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:H&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:M&#34;&gt;This is also significantly out of date today. Finagle does now support exporting shard-level histogram data and this can be queried via one-off queries by hitting the exported metrics endpoint.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:M&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:O&#34;&gt;As we previously noted, opaque latency could come from either the server or the client, but in this case, we have strong evidence that the latency is coming from the &lt;code&gt;cache-1&lt;/code&gt; server and not the &lt;code&gt;service-6&lt;/code&gt; client because opaque latency from the &lt;code&gt;service-6&lt;/code&gt; client should be visible on all requests from &lt;code&gt;service-6&lt;/code&gt; but we only observe elevated opaque latency on requests from &lt;code&gt;service-6&lt;/code&gt; to &lt;code&gt;cache-1&lt;/code&gt; and not to the other servers it &amp;quot;talks to&amp;quot;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:O&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Major errors on this blog (and their corrections)</title>
      <link>https://danluu.com/corrections/</link>
      <pubDate>Mon, 22 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://danluu.com/corrections/</guid>
      <description>&lt;p&gt;Here&#39;s a list of errors on this blog that I think were fairly serious. While what I think of as serious is, of course, subjective, I don&#39;t think there&#39;s any reasonable way to avoid that because, e.g., I make a huge number of typos, so many that the majority of acknowledgements on many posts are for people who e-mailed or DM&#39;ed me typo fixes.&lt;/p&gt;

&lt;p&gt;A list that included everything, including typos would both be uninteresting for other people to read as well as high overhead for me, which is why I&#39;ve drawn the line somewhere. An example of an error I don&#39;t think of as serious is, &lt;a href=&#34;https://danluu.com/learning-to-program/&#34;&gt;in this post on how I learned to program&lt;/a&gt;, I originally had the dates wrong on when the competition programmers from my high school made money (it was a couple years after I thought it was). In that case, and many others, I don&#39;t think that the date being wrong changes anything significant about the post.&lt;/p&gt;

&lt;p&gt;Although I&#39;m publishing the original version of this in 2021, I expect this list to grow over time. I hope that I&#39;ve become more careful and that the list will grow more slowly in the future than it has in the past, but that remains to be seen. I view it as a good sign that a large fraction of the list is from my first three months of blogging, in 2013, but that&#39;s no reason to get complacent!&lt;/p&gt;

&lt;p&gt;I&#39;ve added a classification below that&#39;s how I think of the errors, but that classification is also arbitrary and the categories aren&#39;t even mutually exclusive. If I ever collect enough of these that it&#39;s difficult to hold them all in my head at once, I might create a tag system and use that to classify them instead, but I hope to not accumulate so many major errors that I feel like I need a tag system for readers to easily peruse them.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Insufficient thought

&lt;ul&gt;
&lt;li&gt;&lt;i&gt;2013&lt;/i&gt;: &lt;a href=&#34;https://danluu.com/randomize-hn/&#34;&gt;Using random algorithms to decrease the probability that good stories get &amp;quot;unlucky&amp;quot; on HN&lt;/a&gt;: this idea was tried and didn&#39;t work well as well as putting humans in the loop who decide which stories should be rescued from oblivion.

&lt;ul&gt;
&lt;li&gt;Since this was a proposal and not a claim, this technically wasn&#39;t an error since I didn&#39;t claim that this would definitely work, but my feeling is that I should&#39;ve also considered solutions that put humans in the loop. I didn&#39;t because Digg famously got a lot of backlash for having humans influence their front page but, in retrospect, we can see that it&#39;s possible to do so in a way that doesn&#39;t generate backlash that effective kills the site and I think this could&#39;ve been predicted with enough thought&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Naivete

&lt;ul&gt;
&lt;li&gt;&lt;i&gt;2013&lt;/i&gt;: &lt;a href=&#34;https://danluu.com/hardware-unforgiving/&#34;&gt;The institution knowledge and culture that create excellence can take a long time to build up&lt;/a&gt;: At this time, I hadn&#39;t worked in software and that thought that this wasn&#39;t as difficult for software because so many software companies are successful with new/young teams. But, in retrospect, the difference isn&#39;t that those companies don&#39;t produce bad (unreliable, buggy, slow, etc.) software, it&#39;s that product/market fit and network effects are important enough that it frequently doesn&#39;t matter that software is bad&lt;/li&gt;
&lt;li&gt;&lt;i&gt;2015&lt;/i&gt;: &lt;a href=&#34;https://danluu.com/dunning-kruger/&#34;&gt;In this post on how people don&#39;t read citations&lt;/a&gt;, I found it mysterious that type system advocates would cite non-existent strong evidence, which seems unlike the other examples, where people pass on a clever, contrarian, result without ever having read it. The thing I thought was mysterious was that, unlike the other examples, there isn&#39;t an incorrect piece of evidence being passed around; the assertion that there is evidence is disconnected from any evidence, even misinterpreted evidence. In retrospect, I was being naive in thinking that there was a link to evidence that people wouldn&#39;t just fabricate the idea that there is evidence supporting their belief and then pass that around.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Insufficient verification of information

&lt;ul&gt;
&lt;li&gt;&lt;i&gt;2016&lt;/i&gt;: &lt;a href=&#34;https://danluu.com/sounds-easy/&#34;&gt;Building a search engine isn&#39;t trivial&lt;/a&gt;: although I think the overall point is true, one of the pieces of evidence I relied on came out of using numbers that someone who worked on a search engine told me about. But when I measured actual numbers, I found that the numbers I was told were off by multiple orders of magnitude&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Blunder

&lt;ul&gt;
&lt;li&gt;&lt;i&gt;2015&lt;/i&gt;: &lt;a href=&#34;https://danluu.com/butler-lampson-1999/&#34;&gt;Checking out Butler Lampson&#39;s review of what worked in CS, 16 years later&lt;/a&gt;: it was wrong to say that capabilities were a &amp;quot;no&amp;quot; in 2015 given their effectiveness on mobile and that seems so obviously wrong at the time that I would call this a blunder rather than something where I gave it a decent amount of thought but should&#39;ve thought through it more deeply&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Pointlessly difficult to understand explanation

&lt;ul&gt;
&lt;li&gt;&lt;i&gt;2013&lt;/i&gt;: &lt;a href=&#34;https://danluu.com/3c-conflict/&#34;&gt;How data alignment impacts memory latency&lt;/a&gt;: the main plots in this post use a ratio of latencies, which adds a level of indirection that many people found confusing&lt;/li&gt;
&lt;li&gt;&lt;a id=&#34;p95&#34;&gt;&lt;i&gt;2017&lt;/i&gt;&lt;/a&gt;: &lt;a href=&#34;https://danluu.com/p95-skill/&#34;&gt;It is easy to achieve 95%-ile performance&lt;/a&gt;: the most common objection people had to this post was something like &amp;quot;False. You need to be very talented and/or it is hard to [play in the NBA / become a chess GM / achieve a 2200 chess rating]&amp;quot;. &lt;a href=&#34;https://twitter.com/JamesClear/status/1292574538912456707&#34;&gt;James Clear made an even weaker claim on Twitter&lt;/a&gt; and also got similar responses. There isn&#39;t really space to do this on Twitter, but in my blog post, I should&#39;ve included more concrete examples of what various levels of performance look like for people who have a difficult time estimating what performance looks like at various percentiles. To pick one of the less outlandish claims, &lt;a href=&#34;https://lobste.rs/s/mwykjj/95_ile_isn_t_good#c_pudige&#34;&gt;here&#39;s a claim that a 2200 rating is 95%-ile for someone who&#39;s ever played chess online&lt;/a&gt;, which &lt;a href=&#34;https://lobste.rs/s/mwykjj/95_ile_isn_t_good#c_iyoegc&#34;&gt;appears to be off by perhaps four orders of magnitude, plus or minus one&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Errors in retrospect

&lt;ul&gt;
&lt;li&gt;&lt;i&gt;2015&lt;/i&gt;: &lt;a href=&#34;https://danluu.com/blog-ads/&#34;&gt;Blog monetization&lt;/a&gt;: I grossly underestimated how much &lt;a href=&#34;https://www.patreon.com/danluu&#34;&gt;I could make on Patreon&lt;/a&gt; by looking at how much Casey Muratori, Eric Raymond, and eevee were making on Patreon at the time. I thought that all three of them would out-earn me based for a variety of reasons and that was incorrect. A major reason that was incorrect was that boring, long-form, writing monetizes much better than I exepected, which means that I monetarily undervalued that compared to what other tech folks are doing.

&lt;ul&gt;
&lt;li&gt;A couple weeks ago, I added a link to Patreon at the top of posts (instead of just having one hidding at the bottom) and mentioned having a Patreon on Twitter. Since then, my earnings have increased by about as much as Eric Raymond makes in total and the amount seems to be increasing at a decent rate, which is a result I wouldn&#39;t have expected before the rise of substack. But anyone who realized how well individual writers can monetize their writing could&#39;ve created substack and no one did until Chris Best, Hamish McKenzie, and Jairaj Sethi created substack, so I&#39;d say that this one was somewhat non-obvious. Also, &lt;a href=&#34;https://www.patreon.com/posts/60185075&#34;&gt;it&#39;s unclear if the monetization is going to scale up or will plateau&lt;/a&gt;; if it plateaus, then my guess would only be off by a small constant factor.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thanks to Anja Boskovic and Ville Sundberg for comments/corrections/discussion.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Individuals matter</title>
      <link>https://danluu.com/people-matter/</link>
      <pubDate>Mon, 15 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://danluu.com/people-matter/</guid>
      <description>

&lt;p&gt;One of the most common mistakes I see people make when looking at data is incorrectly using an overly simplified model. A specific variant of this that has derailed the majority of work roadmaps I&#39;ve looked at is treating people as interchangeable, as if it doesn&#39;t matter who is doing what, as if individuals don&#39;t matter.&lt;/p&gt;

&lt;p&gt;Individuals matter.&lt;/p&gt;

&lt;p&gt;A pattern I&#39;ve repeatedly seen during the roadmap creation and review process is that people will plan out the next few quarters of work and then assign some number of people to it, one person for one quarter to a project, two people for three quarters to another, etc. Nominally, this process enables teams to understand what other teams are doing and plan appropriately. I&#39;ve never worked in an organization where this actually worked, where this actually enabled teams to effectively execute with dependencies on other teams.&lt;/p&gt;

&lt;p&gt;What I&#39;ve seen happen instead is, when work starts on the projects, people will ask who&#39;s working the project and then will make a guess at whether or not the project will be completed on time or in an effective way or even be completed at all based on who ends up working on the project. &amp;quot;Oh, Joe is taking feature X? He never ships anything reasonable. Looks like we can&#39;t depend on it because that&#39;s never going to work. Let&#39;s do Y instead of Z since that won&#39;t require X to actually work&amp;quot;. The roadmap creation and review process maintains the polite fiction that people are interchangeable, but everyone knows this isn&#39;t true and teams that are effective and want to ship on time can&#39;t play along when the rubber hits the road even if they play along with the managers, directors, and VPs, who create roadmaps as if people can be generically abstracted over.&lt;/p&gt;

&lt;p&gt;Another place the non-fungibility of people causes predictable problems is with how managers operate teams. Managers who want to create effective teams&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:P&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:P&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; end up fighting the system in order to do so. Non-engineering orgs mostly treat people as fungible, and the finance org at a number of companies I&#39;ve worked for forces the engineering org to treat people as fungible by requiring the org to budget in terms of headcount. The company, of course, spends money and not &amp;quot;heads&amp;quot;, but internal bookkeeping is done in terms of &amp;quot;heads&amp;quot;, so $X of budget will be, for some team, translated into something like &amp;quot;three staff-level heads&amp;quot;. There&#39;s no way to convert that into &amp;quot;two more effective and better-paid staff level heads&amp;quot;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:E&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:E&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. If you hire two staff engineers and not a third, the &amp;quot;head&amp;quot; and the associated budget will eventually get moved somewhere else.&lt;/p&gt;

&lt;p&gt;One thing I&#39;ve repeatedly seen is that a hiring manager will &lt;a href=&#34;https://twitter.com/danluu/status/1452701799417143296&#34;&gt;want to hire someone who they think will be highly effective or even just someone who has specialized skills and then not be able to hire because the company has translated budget into &amp;quot;heads&amp;quot; at a rate that doesn&#39;t allow for hiring some kind of heads&lt;/a&gt;. There will be a &amp;quot;comp team&amp;quot; or other group in HR that will object because the comp team has no concept of &amp;quot;an effective engineer&amp;quot; or &amp;quot;a specialty that&#39;s hard to hire for&amp;quot;; for a person, role, level, and location defines them and someone who&#39;s paid too much for their role and level is therefore a bad hire. If anyone reasonable had power over the process that they were willing to use, this wouldn&#39;t happen but, by design, the bureaucracy is set up so that few people have power&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:B&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:B&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;A similar thing happens with retention. A great engineer I know who was regularly creating $x0M/yr&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:Q&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:Q&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; of additional profit for the company per year wanted to move home to Portugal, so the company cut the person&#39;s cash comp by a factor of four. The company also offered to only cut his cash comp by a factor of two if he moved to Spain instead of Portugal. He left for a company that doesn&#39;t have location-based pay. This was escalated up to the director level, but that wasn&#39;t sufficient to override HR, so they left. HR didn&#39;t care that the person made the company more money than HR saves by doing location adjustments for all international employees combined because HR at the company had no notion of the value of an employee, only the cost, title, level, and location&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:L&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:L&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Relatedly, a &amp;quot;move&amp;quot; I&#39;ve seen twice, once from a distance and once from up close, is when HR decides &lt;a href=&#34;https://twitter.com/danluu/status/1277591470162104321&#34;&gt;attrition is too low&lt;/a&gt;. In one case, the head of HR thought that the company&#39;s ~5% attrition was &amp;quot;unhealthy&amp;quot; because it was too low and in another, HR thought that the company&#39;s attrition sitting at a bit under 10% was too low. In both cases, the company made some moves that resulted in attrition moving up to what HR thought was a &amp;quot;healthy&amp;quot; level. In the case I saw from a distance, folks I know at the company agree that the majority of the company&#39;s best engineers left over the next year, many after only a few months. In the case I saw up close, I made a list of the most effective engineers I was aware of (like the person mentioned above who increased the company&#39;s revenue by 0.7% on his paternity leave) and, when the company successfully pushed attrition to over 10% overall, the most effective engineers left at over double that rate (which understates the impact of this because they tended to be long-tenured and senior engineers, where the normal expected attrition would be less than half the average company attrition).&lt;/p&gt;

&lt;p&gt;Some people seem to view companies like a game of SimCity, where if you want more money, you can turn a knob, increase taxes, and get more money, uniformly impacting the city. But companies are not a game of SimCity. If you want more attrition and turn a knob that cranks that up, you don&#39;t get additional attrition that&#39;s sampled uniformly at random. People, as a whole, cannot be treated as an abstraction where the actions company leadership takes impacts everyone in the same way. The people who are most effective will be disproportionately likely to leave if you turn a knob that leads to increased attrition.&lt;/p&gt;

&lt;p&gt;So far, we&#39;ve talked about how treating individual people as fungible doesn&#39;t work for corporations but, of course, it also doesn&#39;t work in general. For example, a complaint from a friend of mine who&#39;s done a fair amount of &amp;quot;on the ground&amp;quot; development work in Africa is that a lot of people who are looking to donate want, clear, simple criteria to guide their donations (e.g., an RCT showed that the intervention was highly effective). But many effective interventions cannot have their impact demonstrated ex ante in any simple way because, among other reasons, the composition of the team implementing the intervention is important, resulting in a randomized trial or other experiment not being applicable to team implementing the intervention other than the teams from the trial in the context they were operating in during the trial.&lt;/p&gt;

&lt;p&gt;An example of this would be an intervention they worked on that, among other things, helped wipe out guinea worm in a country. Ex post, we can say that was a highly effective intervention since it was a team of three people operating on a budget of $12/(person-day)&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:T&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:T&#34;&gt;6&lt;/a&gt;&lt;/sup&gt; for a relatively short time period, making it a high ROI intervention, but there was no way to make a quantitative case for the intervention ex ante, nor does it seem plausible that there could&#39;ve been a set of randomized trials or experiments that would&#39;ve justified the intervention.&lt;/p&gt;

&lt;p&gt;Their intervention wasn&#39;t wiping out guinea worm, that was just a side effect. The intervention was, basically, travelling around the country and embedding in regional government offices in order to understand their problems and then advise/facilitate better decision making. In the course of talking to people and suggesting improvements/changes, they realized that guinea worm could with better distribution of clean water (guinea worm can come from drinking unfiltered water; giving people clean water can solve that problem) and that aid money flowing into the country specifically for water-related projects, like building wells, was already sufficient if the it was distributed to places in the country that had high rates of guinea worm due to contaminated water instead of to the places aid money was flowing to (which were locations that had a lot of aid money flowing to them for a variety of reasons, such as being near a local &amp;quot;office&amp;quot; that was doing a lot of charity work). The specific thing this team did to help wipe out guinea worm was to give powerpoint presentations to government officials on how the government could advise organizations receiving aid money on how those organizations could more efficiently place wells. At the margin, wiping out guinea worm in a country would probably be sufficient for the intervention to be high ROI, but that&#39;s a very small fraction of the &amp;quot;return&amp;quot; from this three person team. I only mention it because it&#39;s a self-contained easily-quantifiable change. Most of the value of &amp;quot;leveling up&amp;quot; decision making in regional government offices is very difficult to quantify (and, to the extent that it can be quantified, will still have very large error bars).&lt;/p&gt;

&lt;p&gt;Many interventions that seem the same ex ante, probably even most, produce little to no impact. My friend has a lot of comments on organizations that send a lot of people around to do similar sounding work but that produce little value, such as the Peace Corps.&lt;/p&gt;

&lt;p&gt;A major difference between my friend&#39;s team and most teams is that my friend&#39;s team was composed of people who had a track record of being highly effective across a variety of contexts. In an earlier job, my friend started a job at a large-ish ($5B/yr revenue) government-run utility company and was immediately assigned a problem that, unbeknownst to her, had been an open problem for years that was considered to be unsolvable. No one was willing to touch the problem, so they hired her because they wanted a scapegoat to blame and fire when the problem blew up. Instead, she solved the problem she was assigned to as well as a number of other problems that were considered unsolvable. A team of three such people will be able to get a lot of mileage out of potentially high ROI interventions that most teams would not succeed at, such as going to a foreign country and improving governmental decision making in regional offices across the country enough that the government is able to solve serious open problems that had been plaguing the country for decades.&lt;/p&gt;

&lt;p&gt;Many of the highest ROI interventions are similarly skill intensive and not amenable to simple back-of-the-envelope calculations, but most discussions I see on the topic, both in person and online, rely heavily on simplistic but irrelevant back-of-the-envelope calculations. This is not just a problem limited to cocktail-party conversations. My friend&#39;s intervention was almost killed by the organization she worked for because the organization was infested with what she thinks of &amp;quot;overly simplistic &lt;a href=&#34;https://en.wikipedia.org/wiki/Effective_altruism&#34;&gt;EA&lt;/a&gt; thinking&amp;quot;, which caused leadership in the organization to try to redirect resources to projects where the computation of expected return was simpler because those projects were thought to be higher impact even though they were, ex post, lower impact. Of course, we shouldn&#39;t judge interventions on how they performed ex post since that will overly favor high variance interventions, but I think that someone thinking it through, who was willing to exercise their judgement instead of outsourcing their judgement to a simple metric, could and should say that the intervention in question was a good choice ex ante.&lt;/p&gt;

&lt;p&gt;This issue of projects which are more &lt;a href=&#34;https://amzn.to/3qGiucN&#34;&gt;legible&lt;/a&gt; getting more funding is an issue across organizations as well as within them. For example, my friend says that, back when GiveWell was mainly or only recommending charities that had simply quantifiable return, she basically couldn&#39;t get her friends who worked in other fields to put resources towards efforts that weren&#39;t endorsed by GiveWell. People who didn&#39;t know about her aid background would say things like &amp;quot;haven&#39;t you heard of GiveWell?&amp;quot; when she suggested putting resources towards any particular cause, project, or organization.&lt;/p&gt;

&lt;p&gt;I talked to a friend of mine who worked at GiveWell during that time period about this and, according to him, the reason GiveWell initially focused on charities that had easily quantifiable value wasn&#39;t that they thought those were the highest impact charities. Instead, it was because, as a young organization, they needed to be credible and it&#39;s easier to make a credible case for charities whose value is easily quantifiable. He would not, and he thinks GiveWell would not, endorse donors funnelling all resources into charities endorsed by GiveWell and neglecting other ways to improve the world. But many people want the world to be simple and apply the algorithm &amp;quot;charity on GiveWell list = good; not on GiveWell list = bad&amp;quot; because it makes the world simple for them.&lt;/p&gt;

&lt;p&gt;Unfortunately for those people, as well as for the world, the world is not simple.&lt;/p&gt;

&lt;p&gt;Coming back to the tech company examples, Laurence Tratt notes something that I&#39;ve also observed:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;One thing I&#39;ve found very interesting in large organisations is when they realise that they need to do something different (i.e. they&#39;re slowly failing and want to turn the ship around). The obvious thing is to let a small team take risks on the basis that they might win big. Instead they tend to form endless committees which just perpetuate the drift that caused the committees to be formed in the first place! I think this is because they really struggle to see people as anything other than fungible, even if they really want to: it&#39;s almost beyond their ability to break out of their organisational mould, even when it spells long-term doom.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;One lens we can use to look at what&#39;s going on is &lt;a href=&#34;https://www.ribbonfarm.com/2010/07/26/a-big-little-idea-called-legibility/&#34;&gt;legibility&lt;/a&gt;. When you have a complex system, whether that&#39;s a company with thousands of engineers or a world with many billions of dollars going to aid work, the system is too complex for any decision maker to really understand, whether that&#39;s an exec at a company or a potential donor trying to understand where their money should go. One way to address this problem is by reducing the perceived complexity of the problem via imagining that individuals are fungible, making the system more legible. That produces relatively inefficient outcomes but, unlike &lt;a href=&#34;https://twitter.com/benskuhn/status/1458948982059593730&#34;&gt;trying to understand the issues at hand&lt;/a&gt;, it&#39;s highly scalable, and if there&#39;s one thing that tech companies like, it&#39;s doing things that scale, and treating a complex system like it&#39;s SimCity or Civilization is highly scalable. When returns are relatively evenly distributed, losing out on potential outlier returns in the name of legibility is a good trade-off. But when ROI is a heavy-tailed distribution, when the right person can, on their paternity leave, increase company revenue of a giant tech company by 0.7% and then much more when they work on that full-time, then severely tamping down on the right side of the curve to improve legibility is very costly and can cost you the majority of your potential returns.&lt;/p&gt;

&lt;p&gt;Thanks to Laurence Tratt, Pam Wolf, Ben Kuhn, Peter Bhat Harkins, John Hergenroeder, Andrey Mishchenko, Joseph Kaptur, and Sophia Wisdom for comments/corrections/discussion.&lt;/p&gt;

&lt;h3 id=&#34;appendix-re-orgs&#34;&gt;Appendix: re-orgs&lt;/h3&gt;

&lt;p&gt;A friend of mine recently told me a story about a trendy tech company where they tried to move six people to another project, one that the people didn&#39;t want to work on that they thought didn&#39;t really make sense. The result was that two senior devs quit, the EM retired, one PM was fired (long story), and three people left the team. The team for both the old project and the new project had to be re-created from scratch.&lt;/p&gt;

&lt;p&gt;It could be much worse. In that case, at least there were some people who didn&#39;t leave the company. I once asked someone why feature X, which had been publicly promised, hadn&#39;t been implemented yet and also the entire sub-product was broken. The answer was that, after about a year of work, when shipping the feature was thought to be weeks away, leadership decided that the feature, which was previously considered a top priority, was no longer a priority and should be abandoned. The team argued that the feature was very close to being done and they just wanted enough runway to finish the feature. When that was denied, the entire team quit and the sub-product has slowly decayed since then. After many years, there was one attempted reboot of the team but, for reasons beyond the scope of this story, it was done with a new manager managing new grads and didn&#39;t really re-create what the old team was capable of.&lt;/p&gt;

&lt;p&gt;As we&#39;ve previously seen, &lt;a href=&#34;https://danluu.com/hardware-unforgiving/&#34;&gt;an effective team is difficult to create, due to the institutional knowledge that exists on a team&lt;/a&gt;, as well as &lt;a href=&#34;https://danluu.com/culture/&#34;&gt;the team&#39;s culture&lt;/a&gt;, but destroying a team is very easy.&lt;/p&gt;

&lt;p&gt;I find it interesting that so many people in senior management roles persist in thinking that they can re-direct people as easily as opening up the city view in Civilization and assigning workers to switch from one task to another when the senior ICs I talk to have high accuracy in predicting when these kinds of moves won&#39;t work out.&lt;/p&gt;

&lt;h3 id=&#34;appendix-related-posts&#34;&gt;Appendix: related posts&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://yosefk.com/blog/compensation-rationality-and-the-projectperson-fit.html&#34;&gt;Yossi Kreinin on compensation and project/person fit&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/hardware-unforgiving/&#34;&gt;Me on the difficulty of obtaining institutional knowledge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://amzn.to/3qGiucN&#34;&gt;James C. Scott on legibility&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:P&#34;&gt;&lt;p&gt;On the flip side, there are managers who want to maximize the return to their career. At every company I&#39;ve worked at that wasn&#39;t a startup, doing that involves moving up the ladder, which is easiest to do by collecting as many people as possible. At one company I&#39;ve worked for, the explicitly stated promo criteria are basically &amp;quot;how many people report up to this person&amp;quot;.&lt;/p&gt;

&lt;p&gt;Tying promotions and compensation to the number of people managed could make sense if you think of people as mostly fungible, but is otherwise an obviously silly idea.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:P&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:E&#34;&gt;This isn&#39;t quite this simple when you take into account retention budgets (money set aside from a pool that doesn&#39;t come out of the org&#39;s normal budget, often used to match offers from people who are leaving), etc., but adding this nuance doesn&#39;t really change the fundamental point.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:E&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:B&#34;&gt;&lt;p&gt;There are advantages to a system where people don&#39;t have power, such as mitigating abuses of power, various biases, nepotism, etc. One can argue that reducing variance in outcomes by making people powerless is the preferred result, but in winner-take-most markets, which many tech markets are, forcing everyone lowest-common-denominator effectiveness is a recipe for being an also ran.&lt;/p&gt;

&lt;p&gt;A specific, small-scale, example of this is the massive advantage &lt;a href=&#34;https://danluu.com/corp-eng-blogs/&#34;&gt;companies that don&#39;t have a bureaucratic comms/PR approval process for technical blog posts have&lt;/a&gt;. The theory behind having the onerous process that most companies have is that the company is protected from downside risk of a bad blog post, but examples of bad engineering blog posts  that would&#39;ve been mitigated by having an onerous process are few and far between, whereas the companies that have good processes for writing publicly get a lot of value that&#39;s easy to see.&lt;/p&gt;

&lt;p&gt;A larger scale example of this is that the large, now &amp;gt;= $500B companies, all made aggressive moves that wouldn&#39;t have been possible at their bureaucracy laden competitors, which allowed them to wipe the floor with their competitors. Of course, many other companies that made serious bets instead of playing it safe failed more quickly than companies trying to play it safe, but those companies at least had a chance, unlike the companies that played it safe.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:B&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:Q&#34;&gt;&lt;p&gt;I&#39;m generally skeptical of claims like this. At multiple companies that I&#39;ve worked for, if you tally up the claimed revenue or user growth wins and compare them to actual revenue or user growth, you can see that there&#39;s some funny business going on since the total claimed wins are much larger than the observed total.&lt;/p&gt;

&lt;p&gt;Just because &lt;a href=&#34;https://danluu.com/why-benchmark/&#34;&gt;I&#39;m generally curious about measurements&lt;/a&gt;, I sometimes did my own analysis of people&#39;s claimed wins and I almost always came up with an estimate that was much lower than the original estimate. Of course, I generally didn&#39;t publish these results internally since that would, in general, be a good way to make a lot of enemies without causing any change. In one extreme case, I found that the experimental methodology one entire org used was broken, causing them to get spurious wins in their A/B tests. I quietly informed them and they did nothing about it, which was the only reasonable move for them since having experiments that systematically showed improvement when none existed was a cheap and effective way for the org to gain more power by having its people get promoted and having more headcount allocated to it. And if anyone with power over the bureaucracy cared about accuracy of results, such a large discrepancy between claimed wins and actual results couldn&#39;t exist in the first place.&lt;/p&gt;

&lt;p&gt;Anyway, despite my general skepticism of claimed wins in general, I found this person&#39;s claimed wins highly credible after checking them myself. A project of theirs, done on their paternity leave (done while on leave because their manager and, really, the organization as well as the company, didn&#39;t support the kind of work they were doing) increased the company&#39;s revenue by 0.7%, robust and actually increasing in value through a long-term holdback, and they were able to produce wins of that magnitude after leadership was embarrassed into allowing them to do valuable work.&lt;/p&gt;

&lt;p&gt;P.S. If you&#39;d like to play along at home, another fun game you can play after figuring out which teams and orgs hit their roadmap goals. For bonus points, plot the percentage of roadmap goals a team hits vs. their headcount growth as well as how predictive hitting last quarter&#39;s goals are for hitting next quarter&#39;s goals across teams.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:Q&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:L&#34;&gt;&lt;p&gt;I&#39;ve seen quite a few people leave their employers due to location adjustments during the pandemic. In one case, HR insisted the person was actually very well compensated because, even though it might appear as if the person isn&#39;t highly paid because they were paid significantly less than many people who were one level below them, according to HR&#39;s formula, which included a location-based pay adjustment, the person was one of the highest paid people for their level at the entire company in terms of normalized pay. Putting aside abstract considerations about fairness, &lt;a href=&#34;https://yosefk.com/blog/compensation-rationality-and-the-projectperson-fit.html&#34;&gt;for an employee&lt;/a&gt;, HR telling them that they&#39;re highly paid given their location is like HR having a formula that pays based on height telling an employee that they&#39;re well paid for their height. That may be true according to whatever formula HR has but, practically speaking, that means nothing to the employee, who can go work somewhere that has a smaller height-based pay adjustment.&lt;/p&gt;

&lt;p&gt;Companies were able to get away with severe location-based pay adjustments with no cost to themselves before the pandemic. But, since the pandemic, a lot of companies have ramped up remote hiring and some of those companies have relatively small location-based pay adjustments, which has allowed them to disproportionately hire away who they choose from companies that still maintain severe location-based pay adjustments.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:L&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:T&#34;&gt;Technically, their budget ended up being higher than this because one team member contracted typhoid and paid for some medical expenses from their personal budget and not from the organization&#39;s budget, but $12/(person-day), the organizational funding, is a pretty good approximation.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:T&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Culture matters</title>
      <link>https://danluu.com/culture/</link>
      <pubDate>Mon, 08 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://danluu.com/culture/</guid>
      <description>

&lt;p&gt;Three major tools that companies have to influence behavior are incentives, process, and culture. People often mean different things when talking about these, so I&#39;ll provide an example of each so we&#39;re on the same page (if you think that I should be using a different word for the concept, feel free to mentally substitute that word).&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Getting people to show up to meetings on time&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Incentive: dock pay for people who are late&lt;/li&gt;
&lt;li&gt;Process: don&#39;t allow anyone who&#39;s late into the meeting&lt;/li&gt;
&lt;li&gt;Culture: people feel strongly about showing up on time&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Getting people to build complex systems&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Incentive: require complexity in promo criteria&lt;/li&gt;
&lt;li&gt;Process: make process for creating or executing on a work item so heavyweight that people stop doing simple work&lt;/li&gt;
&lt;li&gt;Culture: people enjoy building complex systems and/or building complex systems results in respect from peers and/or prestige&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Avoiding manufacturing defects&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Incentive: pay people per good item created and/or dock pay for bad items&lt;/li&gt;
&lt;li&gt;Process: have QA check items before shipment and discard bad items&lt;/li&gt;
&lt;li&gt;Culture: people value excellence and try very hard to avoid defects&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you read &amp;quot;old school&amp;quot; thought leaders, many of them advocate for a culture-only approach, e.g., &lt;a href=&#34;https://mobile.twitter.com/danluu/status/885214004649615360&#34;&gt;Ken Thompson saying, to reduce bug rate, that tools (which, for the purposes of this post, we&#39;ll call process) aren&#39;t the answer, having people care to and therefore decide to avoid writing bugs is the answer&lt;/a&gt; or Bob Martin saying &amp;quot;&lt;a href=&#34;https://www.hillelwayne.com/post/uncle-bob/&#34;&gt;The solution to the software apocalypse is not more tools. The solution is better programming discipline&lt;/a&gt;.&amp;quot;&lt;/p&gt;

&lt;p&gt;The emotional reaction those kinds of over-the-top statements evoke combined with the ease of rebutting them has led to a backlash against cultural solutions, leading people to say things like &amp;quot;you should never say that people need more discipline and you should instead look at the incentives of the underlying system&amp;quot;, in the same way that the 10x programmer meme and the associated comments have caused a backlash that&#39;s led to people to say things like &lt;a href=&#34;https://danluu.com/productivity-velocity/&#34;&gt;velocity doesn&#39;t matter at all&lt;/a&gt; or there&#39;s absolutely no difference in velocity between programmers (&lt;a href=&#34;https://scattered-thoughts.net/writing/moving-faster/&#34;&gt;as Jamie Brandon has noted, a lot of velocity comes down to caring about and working on velocity&lt;/a&gt;, so this is also part of the backlash against culture).&lt;/p&gt;

&lt;p&gt;But if we look at quantifiable output, we can see that, even if processes and incentives are the first-line tools a company should reach for, culture also has a large impact. For example, if we look at manufacturing defect rate, some countries persistently have lower defect rates than others on a timescale of decades&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:C&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:C&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;, generally robust across companies, even when companies are operating factories in multiple countries and importing the same process and incentives to each factory to the extent that&#39;s possible, due to cultural differences that impact how people work.&lt;/p&gt;

&lt;p&gt;Coming back to programming, Jamie&#39;s post on &amp;quot;moving faster&amp;quot; notes:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The main thing that helped is actually wanting to be faster.&lt;/p&gt;

&lt;p&gt;Early on I definitely cared more about writing &#39;elegant&#39; code or using fashionable tools than I did about actually solving problems. Maybe not as an explicit belief, but those priorities were clear from my actions.&lt;/p&gt;

&lt;p&gt;I probably also wasn&#39;t aware how much faster it was possible to be. I spent my early career working with people who were as slow and inexperienced as I was.&lt;/p&gt;

&lt;p&gt;Over time I started to notice that some people are producing projects that are far beyond what I could do in a single lifetime. I wanted to figure out how to do that, which meant giving up my existing beliefs and trying to discover what actually works.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I was lucky to have the opposite experience starting out since my first full-time job was at Centaur, a company that, at the time, had very high velocity/productivity. I&#39;d say that I&#39;ve only ever worked on one team with a similar level of productivity, and that&#39;s my current team, but my current team is fairly unusual for a team at a tech company (e.g., the median level on my team is &amp;quot;senior staff&amp;quot;)&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:S&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:S&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. A side effect of having started my career at such a high velocity company is that I generally find the pace of development slow at big companies and I see no reason to move slowly just because that&#39;s considered normal. I often hear similar comments from people I talk to at big companies who&#39;ve previously worked at non-dysfunctional but not even particularly fast startups. A regular survey at one of the trendiest companies around asks &amp;quot;Do you feel like your dev speed is faster or slower than your previous job?&amp;quot; and the responses are bimodal, depending on whether the respondent came from a small company or a big one (with dev speed at TrendCo being slower than at startups and faster than at larger companies).&lt;/p&gt;

&lt;p&gt;There&#39;s a story that, &lt;a href=&#34;https://amzn.to/3EZXykS&#34;&gt;IIRC, was told by Brian Enos&lt;/a&gt;, where he was practicing timed drills with the goal of practicing until he could complete a specific task at or under his usual time. He was having a hard time hitting his normal time and was annoyed at himself because he was slower than usual and kept at it until he hit his target, at which point he realized he misremembered the target and was accidentally targeting a new personal best time that was better than he thought was possible. While it&#39;s too simple to say that we can achieve anything if we put our minds to it, &lt;a href=&#34;https://twitter.com/nickcammarata/status/1362261305357393920&#34;&gt;almost none of us are operating at anywhere near our capacity and what we think we can achieve is often a major limiting factor&lt;/a&gt;. Of course, at the limit, there&#39;s a tradeoff between velocity and quality and you can&#39;t get velocity &amp;quot;for free&amp;quot;, but, when it comes to programming, &lt;a href=&#34;https://danluu.com/p95-skill/&#34;&gt;we&#39;re so far from the Pareto frontier that there are free wins&lt;/a&gt; if you just &lt;a href=&#34;https://twitter.com/danluu/status/1442945072144678914&#34;&gt;realize that they&#39;re available&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;One way in which culture influences this is that people often absorb their ideas of what&#39;s possible from the culture they&#39;re in. For a non-velocity example, one thing I noticed after attending &lt;a href=&#34;https://www.recurse.com/scout/click?t=b504af89e87b77920c9b60b2a1f6d5e8&#34;&gt;RC&lt;/a&gt; was that a lot of speakers at the well-respected non-academic non-enterprise tech conferences, like Deconstruct and Strange Loop, also attended RC. Most people hadn&#39;t given talks before attending RC and, when I asked people, a lot of people had wanted to give talks but didn&#39;t realize how straightforward the process for becoming a speaker at &amp;quot;big&amp;quot; conferences is (have an idea, write it down, and then submit what you wrote down as a proposal). It turns out that giving talks at conferences is easy to do and a major blocker for many folks is just knowing that it&#39;s possible. In an environment where lots of people give talks and, where people who hesitantly ask how they can get started are told that it&#39;s straightforward, a lot of people will end up giving talks. The same thing is true of blogging, which is why a disproportionately large fraction of widely read programming bloggers started blogging seriously after attending RC. For many people, the barrier to starting a blog is some combination of realizing it&#39;s feasible to start a blog and that, from a technical standpoint, it&#39;s very easy to start a blog if you just pick any semi-reasonable toolchain and go through the setup process. And then, because people give talks and write blog posts, they get better at giving talks and writing blog posts so, on average, RC alums are probably better speakers and writers than random programmers even though there&#39;s little to no skill transfer or instruction at RC.&lt;/p&gt;

&lt;p&gt;Another kind of thing where culture can really drive skills are skills that are highly attitude dependent. An example of this is debugging. As Julia Evans has noted, &lt;a href=&#34;https://twitter.com/b0rk/status/1249715842708844544&#34;&gt;having a good attitude is a major component of debugging effectiveness&lt;/a&gt;. This is something Centaur was very good at instilling in people, to the point that nearly everyone in my org at Centaur would be considered a very strong debugger by tech company standards.&lt;/p&gt;

&lt;p&gt;At big tech companies, it&#39;s common to see people give up on bugs after trying a few random things that didn&#39;t work. In one extreme example, someone I know at a mid-10-figure tech company said that it never makes sense to debug a bug that takes more than a couple hours to debug because engineer time is too valuable to waste on bugs that take longer than that to debug, an attitude this person picked up from the first team they worked on. Someone who picks up that kind of attitude about debugging is unlikely to become a good debugger until they change their attitude, and many people, including this person, carry the attitudes and habits they pick up at their first job around for quite a long time&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:N&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:N&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;By tech standards, Centaur is an extreme example in the other direction. If you&#39;re designing a CPU, it&#39;s not considered ok to walk away from a bug that you don&#39;t understand. Even if the symptom of the bug isn&#39;t serious, it&#39;s possible that the underlying cause is actually serious and you won&#39;t observe the more serious symptom until you&#39;ve shipped a chip, so you have to go after even seemingly trivial bugs. Also, it&#39;s pretty common for there to be no good or even deterministic reproduction of a bug. The repro is often something like &amp;quot;run these programs with these settings on the system and then the system will hang and/or corrupt data after some number of hours or days&amp;quot;. When debugging a bug like that, there will be numerous wrong turns and dead ends, some of which can eat up weeks or months. As a new employee watching people work on those kinds of bugs, what I observed was that people would come in day after day and track down bugs like that, not getting frustrated and not giving up. When that&#39;s the culture and everyone around you has that attitude, it&#39;s natural to pick up the same attitude. Also, a lot of practical debugging skill is applying tactical skills picked up from having debugged a lot of problems, which naturally falls out of spending a decent amount of time debugging problems with a positive attitude, especially with exposure to hard debugging problems.&lt;/p&gt;

&lt;p&gt;Of course, most bugs at tech companies don&#39;t warrant months of work, but there&#39;s a big difference between intentionally leaving some bugs undebugged because some bugs aren&#39;t worth fixing and having poor debugging skills from never having ever debugged a serious bug and then not being able to debug any bug that isn&#39;t completely trivial.&lt;/p&gt;

&lt;p&gt;Cultural attitudes can drive a lot more than individual skills like debugging. Centaur had, per capita, by far the lowest serious production bug rate of any company I&#39;ve worked for, at well under one per year with ~100 engineers. By comparison, I&#39;ve never worked on a team 1/10th that size that didn&#39;t have at least 10x the rate of serious production issues. Like most startups, Centaur was very light on process and it was also much lighter on incentives than the big tech companies I&#39;ve worked for.&lt;/p&gt;

&lt;p&gt;One component of this was that there was a culture of owning problems, regardless of what team you were on. If you saw a problem, you&#39;d fix it, or, if there was a very obvious owner, you&#39;d tell them about the problem and they&#39;d fix it. There weren&#39;t roadmaps, standups, kanban, or anything else to get people to work on important problems. People did it without needed to be reminded or prompted.&lt;/p&gt;

&lt;p&gt;That&#39;s the opposite of what I&#39;ve seen at two of the three big tech companies I&#39;ve worked for, where the median person avoids touching problems outside of their team&#39;s mandate like the plague, and someone who isn&#39;t politically savvy who brings up a problem to another team will get a default answer of &amp;quot;sorry, this isn&#39;t on our roadmap for the quarter, perhaps we can put this on the roadmap in [two quarters from now]&amp;quot;, with the same response repeated to anyone naive enough to bring up the same issue two quarters later. At every tech company I&#39;ve worked for, huge, extremely costly, problems slip through the cracks all the time because no one wants to pick them up. I never observed that happening at Centaur.&lt;/p&gt;

&lt;p&gt;A side effect of big company tech culture is that someone who wants to actually do the right thing can easily do very high (positive) impact work by just going around and fixing problems that any intern could solve, if they&#39;re willing to ignore organizational processes and incentives. You can&#39;t shake a stick without &lt;a href=&#34;https://twitter.com/danluu/status/802971209176477696&#34;&gt;hitting a problem that&#39;s worth more to the company than my expected lifetime earnings&lt;/a&gt; and it&#39;s easy to knock off multiple such problems per year. &lt;a href=&#34;https://danluu.com/algorithms-interviews/#appendix-misaligned-incentive-hedgehog-defense-part-3&#34;&gt;Of course, the same forces that cause so many trivial problems to not get solved mean that people who solve those problems don&#39;t get rewarded for their work&lt;/a&gt;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:B&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:B&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Conversely, in eight years at Centaur, I only found one trivial problem whose fix was worth more than I&#39;ll earn in my life because, in general, problems would get solved before they got to that point. I&#39;ve seen various big company attempts to fix this problem using incentives (e.g., monetary rewards for solving important problems) and process (e.g., making a giant list of all projects/problems and having a single person order them, along with a bureaucratic system where everyone has to constantly provide updates on their progress via JIRA so that PMs can keep sending progress updates to the person who&#39;s providing a total order over the work of thousands of engineers&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:R&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:R&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;), but none of those attempts have worked even half as well as having a culture of ownership (to be fair to incentives, I&#39;ve heard that FB uses monetary rewards to good effect, but &lt;a href=&#34;https://twitter.com/danluu/status/1447268693075841024&#34;&gt;I&#39;ve failed FB&#39;s interview three times&lt;/a&gt;, so I haven&#39;t been able to observe how that works myself).&lt;/p&gt;

&lt;p&gt;Another component that resulted in a relatively low severe bug rate was that, across the company at Centaur, people cared about quality in a way that I&#39;ve never seen at a team level let alone at an org level at a big tech company. When you have a collection of people who care about quality and feel that no issue is off limits, you&#39;ll get quality. And when you onboard people, as long as you don&#39;t do it so quickly that the culture is overwhelmed by the new hires, they&#39;ll also tend to pick up the same habits and values, especially when you hire new grads. While it&#39;s not exactly common, there are plenty of small firms out there with a culture of excellence that generally persists without heavyweight processes or big incentives, but this doesn&#39;t work at big tech companies since they&#39;ve all gone through a hypergrowth period where it&#39;s impossible to maintain such extreme (by mainstream standards) cultural values.&lt;/p&gt;

&lt;p&gt;So far, we&#39;ve mainly discussed companies transmitting culture to people, but something that I think is no less important is how people then carry that culture with them when they leave. I&#39;ve been &lt;a href=&#34;https://twitter.com/danluu/status/1444034823329177602&#34;&gt;reasonably successful since changing careers from hardware to software&lt;/a&gt; and I think that, among the factors that are under my control, one of the biggest ones is that I picked up effective cultural values from the first place I worked full-time and continue to operate as in the same way, which is highly effective. I&#39;ve also seen this in other people who, career-wise, &amp;quot;grew up&amp;quot; in a culture of excellence and then changed to a different field where there&#39;s even less direct skill transfer, e.g., from skiing to civil engineering. Relatedly, if you read books from people who discuss the reasons why they were very effective in their field, e.g., &lt;a href=&#34;https://amzn.to/3EZXykS&#34;&gt;Practical Shooting by Brian Enos&lt;/a&gt;, &lt;a href=&#34;https://www.sirlin.net/ptw&#34;&gt;Playing to Win by Dan Sirlin&lt;/a&gt;, etc., the books tend to contain the same core ideas (serious observation and improvement of skills, the importance of avoiding emotional self-sabotage, the importance of intuition, etc.).&lt;/p&gt;

&lt;p&gt;Anyway, I think that cultural transmission of values and skills is an underrated part of choosing a job (some things I would consider overrated are &lt;a href=&#34;https://www.patreon.com/posts/25835707&#34;&gt;prestige&lt;/a&gt; and &lt;a href=&#34;https://twitter.com/danluu/status/1275191896097189888&#34;&gt;general reputation&lt;/a&gt; and that people should be thoughtful about what cultures they spend time in because not many people are able to avoid at least somewhat absorbing the cultural values around them&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:L&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:L&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Although this post is oriented around tech, there&#39;s nothing specific to tech about this. A classic example is how idealistic students will go to law school with the intention of doing &amp;quot;save the world&amp;quot; type work and then absorb the &lt;a href=&#34;https://www.patreon.com/posts/25835707&#34;&gt;prestige-transmitted cultural values&lt;/a&gt; of students around then go into the most prestigious job they can get which, when it&#39;s not a clerkship, will be a &amp;quot;BIGLAW&amp;quot; job that&#39;s the opposite of &amp;quot;save the world&amp;quot; work. To first approximation, everyone thinks &amp;quot;that will never happen to me&amp;quot;, but from having watched many people join organizations where they &lt;a href=&#34;https://danluu.com/wat/&#34;&gt;initially find the values and culture very wrong&lt;/a&gt;, almost no one is able to stay without, to some extent, absorbing the values around them; &lt;a href=&#34;https://danluu.com/look-stupid/&#34;&gt;very few people are ok with everyone around them looking at them like they&#39;re an idiot for having the wrong values&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;appendix-bay-area-culture&#34;&gt;Appendix: Bay area culture&lt;/h3&gt;

&lt;p&gt;One thing I admire about the bay area is how infectious people&#39;s attitudes are with respect to trying to change the world. Everywhere I&#39;ve lived, people gripe about problems (the mortgage industry sucks, selling a house is high friction, etc.). Outside of the bay area, it&#39;s just griping, but in the bay, when I talk to someone who was griping about something a year ago, there&#39;s a decent chance they&#39;ve started a startup to try to address one of the problems they&#39;re complaining about. I don&#39;t think that people in the bay area are fundamentally different from people elsewhere, it&#39;s more that when you&#39;re surrounded by people who are willing to walk away from their jobs to try to disrupt an entrenched industry, it seems pretty reasonable to do the same thing (which also leads to network effects that make it easier from a &amp;quot;technical&amp;quot; standpoint, e.g., easier fundraising). &lt;a href=&#34;https://slatestarcodex.com/2017/05/11/silicon-valley-a-reality-check/&#34;&gt;There&#39;s a kind of earnestness in these sorts of complaints and attempts to fix them that&#39;s easy to mock&lt;/a&gt;, but &lt;a href=&#34;https://danluu.com/look-stupid/&#34;&gt;that earnestness is something I really admire&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Of course, &lt;a href=&#34;https://twitter.com/pushcx/status/1442860058660913166&#34;&gt;not all of bay area culture is positive&lt;/a&gt;. The bay has, among other things, &lt;a href=&#34;https://devonzuegel.com/post/why-is-flaking-so-widespread-in-san-francisco&#34;&gt;a famously flaky culture&lt;/a&gt; to an extent I found shocking when I moved there. Relatively early on in my time there, I met some old friends for dinner and texted them telling them I was going to be about 15 minutes late. They were shocked when I showed up because they thought that saying that I was going to be late actually meant that I wasn&#39;t going to show up (another norm that surprised me that&#39;s an even more extreme version was that, for many people, not confirming plans shortly before their commencement means that the person has cancelled, i.e., plans are cancelled by default).&lt;/p&gt;

&lt;p&gt;A related norm that I&#39;ve heard people complain about is how management and leadership will say yes to everything in a &amp;quot;people pleasing&amp;quot; move to avoid conflict, which actually increases conflict as people who heard &amp;quot;yes&amp;quot; as a &amp;quot;yes&amp;quot; and not as &amp;quot;I&#39;m saying yes to avoid saying no but don&#39;t actually mean yes&amp;quot; are later surprised that &amp;quot;yes&amp;quot; meant &amp;quot;no&amp;quot;.&lt;/p&gt;

&lt;h3 id=&#34;appendix-centaur-s-hiring-process&#34;&gt;Appendix: Centaur&#39;s hiring process&lt;/h3&gt;

&lt;p&gt;One comment people sometimes have when I talk about Centaur is that they must&#39;ve had some kind of incredibly rigorous hiring process that resulted in hiring elite engineers, but the hiring process was much less selective than any &amp;quot;brand name&amp;quot; big tech company I&#39;ve worked for (Google, MS, and Twitter) and not obviously more selective than boring, old school, companies I&#39;ve worked for (IBM and Micron). The &amp;quot;one weird trick&amp;quot; was onboarding, not hiring.&lt;/p&gt;

&lt;p&gt;For new grad hiring (and, proportionally, we hired a lot of new grads), recruiting was more difficult than at any other company I&#39;d worked for. Senior hiring wasn&#39;t difficult because Centaur had a good reputation locally, in Austin, but among new grads, no one had heard of us and no one wanted to work for us. When I recruited at career fairs, I had to stand out in front of our booth and flag down people who were walking by to get anyone to talk to us. This meant that we couldn&#39;t be picky about who we interviewed. We really ramped up hiring of new grads around the time that Jeff Atwood popularized the idea that there are a bunch of fake programmers out there applying for jobs and that you&#39;d end up with programmers who can&#39;t program if you don&#39;t screen people out with basic coding questions in his very influential post, &lt;a href=&#34;https://blog.codinghorror.com/why-cant-programmers-program/&#34; rel=&#34;nofollow&#34;&gt;Why Can&#39;t Programmers.. Program?&lt;/a&gt; (the bolding below is his):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;I am disturbed and appalled that any so-called programmer would apply for a job without being able to write the simplest of programs&lt;/strong&gt;. That&#39;s a slap in the face to anyone who writes software for a living.
...
It&#39;s a shame you have to do so much pre-screening to &lt;strong&gt;have the luxury of interviewing programmers who can actually program&lt;/strong&gt;. It&#39;d be funny if it wasn&#39;t so damn depressing&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Since we were a relatively coding oriented hardware shop (verification engineers primarily wrote software and design engineers wrote a lot of tooling), we tried asking a simple coding question where people were required to code up a function to output Fibonacci numbers given a description of how to compute them (the naive solution was fine; a linear time or faster solution wasn&#39;t necessary). We dropped that question because no one got it without being walked through the entire thing in detail, which meant that the question had zero discriminatory power for us.&lt;/p&gt;

&lt;p&gt;Despite not really asking a coding question, people did things like write hairy concurrent code (internal processor microcode, which often used barriers as the concurrency control mechanism) and create tools at a higher velocity and lower bug rate than I&#39;ve seen anywhere else I&#39;ve worked.&lt;/p&gt;

&lt;p&gt;We were much better off avoiding hiring the way everyone else was because that meant we tried to and did hire people that other companies weren&#39;t competing over. That wouldn&#39;t make sense if other companies were using techniques that were highly effective but other companies were doing things like asking people to code FizzBuzz and then whiteboard some algorithms. While &lt;a href=&#34;https://danluu.com/algorithms-interviews/&#34;&gt;one might expect that doing algorithms interviews would result in hiring people who can solve the exact problems people ask about in interviews, but this turns out not to be the case&lt;/a&gt;. &lt;a href=&#34;https://twitter.com/danluu/status/1425514112642080773&#34;&gt;The other thing we did was have much less of a prestige filter than most companies&lt;/a&gt;, which also let us hire great engineers that other companies wouldn&#39;t even consider.&lt;/p&gt;

&lt;p&gt;We did have some people who didn&#39;t work out, but it was never because they were &amp;quot;so-called programmers&amp;quot; who couldn&#39;t &amp;quot;write the simplest of programs&amp;quot;. I do know of two cases of &amp;quot;fake programmers being hired who literally couldn&#39;t program, but both were at prestigious companies that have among the most rigorous coding interviews done at tech companies. In one case, it was discovered pretty quickly that the person couldn&#39;t code and people went back to review security footage from the interview and realized that the person who interviewed wasn&#39;t the person who showed up to do the job. In the other, the person was able to sneak under the radar at Google for multiple years before someone realized that the person never actually wrote any code and tasks only got completed when they got someone else to do the task. The person who realized eventually scheduled a pair programming session, where they discovered that the person wasn&#39;t able to write a loop, didn&#39;t know the difference between &lt;code&gt;=&lt;/code&gt; and &lt;code&gt;==&lt;/code&gt;, etc., despite being a &amp;quot;senior SWE&amp;quot; (L5/T5) at Google for years.&lt;/p&gt;

&lt;p&gt;I&#39;m not going to say that having coding questions will never save you from hiring a fake programmer, but the rate of fake programmers appears to be very low enough that a small company can go a decade without hiring a fake programmer without asking a coding question and larger companies that are targeted by scammers still can&#39;t really avoid them even after asking coding questions.&lt;/p&gt;

&lt;h3 id=&#34;appendix-importing-culture&#34;&gt;Appendix: importing culture&lt;/h3&gt;

&lt;p&gt;Although this post is about how company culture impacts employees, of course employees impact company culture as well. Something that seems underrated in hiring, especially of senior leadership and senior ICs, is how they&#39;ll impact culture. Something I&#39;ve repeatedly seen, both up close, and from a distance, is the hiring of a new senior person who manages to import their culture, which isn&#39;t compatible with the existing company&#39;s culture, causing serious problems and, frequently, high attrition, as things settle down.&lt;/p&gt;

&lt;p&gt;Now that I&#39;ve been around for a while, I&#39;ve been in the room for discussions on a number of very senior hires and I&#39;ve never seen anyone else bring up whether or not someone will import incompatible cultural values other than really blatant issues, like the person being a jerk or making racist or sexist comments in the interview.&lt;/p&gt;

&lt;p&gt;Thanks to Peter Bhat Harkins, Laurence Tratt, Julian Squires, Anja Boskovic, Tao L., Justin Blank, Ben Kuhn, V. Buckenham, Mark Papadakis, and Jamie Brandon for comments/corrections/discussion.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:C&#34;&gt;What countries actually have low defect rate manufacturing is often quite different from the general public reputation. To see this, you really need to look at the data, which is often NDA&#39;d and generally only spread in &amp;quot;bar room&amp;quot; discussions.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:C&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:S&#34;&gt;: Centaur had what I sometimes called &amp;quot;the world&#39;s stupidest business model&amp;quot;, competing with Intel on x86 chips starting in 1995, so it needed an extremely high level of productivity to survive. Through the bad years, AMD survived by selling off pieces of itself to fund continued x86 development and every other competitor (Rise, Cyrix, TI, IBM, UMC, NEC, and Transmeta) got wiped out. If you compare Centaur to the longest surviving competitor that went under, Transmeta, Centaur just plain shipped more quickly, which is a major reason that Centaur was able to survive until 2021 (when it was pseudo-acqui-hired by Intel) and Transmeta went in 2009 under after burning through ~$1B of funding (including payouts from lawsuits). Transmeta was founded in 1995 and shipped its first chip in 2000, which was considered a normal tempo for the creation of a new CPU/microarchitecture at the time; Centaur shipped its first chip in 1997 and continued shipping at a high cadence until 2010 or so (how things got slower and slower until the company stalled out and got acqui-hired is a topic for another post).
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:S&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:N&#34;&gt;This person initially thought the processes and values on their first team were absurd before &lt;a href=&#34;https://danluu.com/wat/&#34;&gt;the cognitive dissonance got to them and they became a staunch advocate of the company&#39;s culture, which is typical for folks joining a company that has obviously terrible practices&lt;/a&gt;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:N&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:B&#34;&gt;This illustrates one way in which incentives and culture are non-independent. What I&#39;ve seen in places where this kind of work isn&#39;t rewarded is that, due to the culture, making these sorts of high-impact changes frequently requires burnout inducing slogs, at the end of which there is no reward, which causes higher attrition among people who have a tendency to own problems and do high-impact work. What I&#39;ve observed in environments like this is that the environment differentially retains people who don&#39;t want to own problems, which then makes make more difficult and more burnout inducing for new people who join who attempt to fix serious problems.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:B&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:R&#34;&gt;I&#39;m adding this note because, when I&#39;ve described this to people, many people thought that this must be satire. It is not satire.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:R&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:L&#34;&gt;&lt;p&gt;As with many other qualities, there can be high variance within a company as well as across companies. For example, there&#39;s a team I sometimes encountered at a company I&#39;ve worked for that has a very different idea of customer service than most of the company and people who join that team and don&#39;t quickly bounce usually absorb their values.&lt;/p&gt;

&lt;p&gt;Much of the company has a pleasant attitude towards internal customers, but this team has a &amp;quot;the customer is always wrong&amp;quot; attitude. A funny side effect of this is that, when I dealt with the team, I got the best support when a junior engineer who hadn&#39;t absorbed the team&#39;s culture was on call, and sometimes a senior engineer would say something was impossible or infeasible only to have a junior engineer follow up and trivially solve the problem.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:L&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Willingness to look stupid</title>
      <link>https://danluu.com/look-stupid/</link>
      <pubDate>Thu, 21 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://danluu.com/look-stupid/</guid>
      <description>

&lt;p&gt;People frequently&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:F&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:F&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; think that I&#39;m very stupid. I don&#39;t find this surprising, since I don&#39;t mind if other people think I&#39;m stupid, which means that I don&#39;t adjust my behavior to avoid seeming stupid, which results in people thinking that I&#39;m stupid. Although there are some downsides to people thinking that I&#39;m stupid, e.g., failing interviews where the interviewer very clearly thought I was stupid, I think that, overall, the upsides of being willing to look stupid have greatly outweighed the downsides.&lt;/p&gt;

&lt;p&gt;I don&#39;t know why this one example sticks in my head but, for me, the most memorable example of other people thinking that I&#39;m stupid was from college. I&#39;ve had numerous instances where more people thought I was stupid and also where people thought the depths of my stupidity was greater, but this one was really memorable for me.&lt;/p&gt;

&lt;p&gt;Back in college, there was one group of folks that, for whatever reason, stood out to me as people who really didn&#39;t understand the class material. When they talked, they said things that didn&#39;t make any sense, they were struggling in the classes and barely passing, etc. I don&#39;t remember any direct interactions but, one day, a friend of mine who also knew them remarked to me, &amp;quot;did you know [that group] thinks you&#39;re really dumb?&amp;quot;. I found that interesting and asked why. It turned out the reason was that I asked really stupid sounding questions.&lt;/p&gt;

&lt;p&gt;In particular, it&#39;s often the case that there&#39;s a seemingly obvious but actually incorrect reason something is true, a slightly less obvious reason the thing seems untrue, and then a subtle and complex reason that the thing is actually true&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:T&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:T&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. I would regularly figure out that the seemingly obvious reason was wrong and then ask a question to try to understand the subtler reason, which sounded stupid to someone who thought the seemingly obvious reason was correct or thought that the refutation to the obvious but incorrect reason meant that the thing was untrue.&lt;/p&gt;

&lt;p&gt;The benefit from asking a stupid sounding question is small in most particular instances, but the compounding benefit over time is quite large and I&#39;ve observed that people who are willing to ask dumb questions and think &amp;quot;stupid thoughts&amp;quot; end up understanding things much more deeply over time. Conversely, when I look at people who have a very deep understanding of topics, many of them frequently ask naive sounding questions and continue to apply one of the techniques that got them a deep understanding in the first place.&lt;/p&gt;

&lt;p&gt;I think I first became sure of something that I think of as a symptom of the underlying phenomenon via playing competitive video games when I was in high school. There were few enough people playing video games online back then that you&#39;d basically recognize everyone who played the same game and could see how much everyone improved over time. Just like &lt;a href=&#34;https://danluu.com/p95-skill/&#34;&gt;I saw when I tried out video games again a couple years ago&lt;/a&gt;, most people would blame external factors (lag, luck, a glitch, teammates, unfairness, etc.) when they &amp;quot;died&amp;quot; in the game. The most striking thing about that was that people who did that almost never became good and never became great. I got pretty good at the game&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:B&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:B&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; and my &amp;quot;one weird trick&amp;quot; was to think about what went wrong every time something went wrong and then try to improve. But most people seemed more interested in making an excuse to avoid looking stupid (or maybe feeling stupid) in the moment than actually improving, which, of course, resulted in them having many more moments where they looked stupid in the game.&lt;/p&gt;

&lt;p&gt;In general, I&#39;ve found willingness to look stupid to be very effective. Here are some more examples:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Going into an Apple store and asking for (and buying) the computer that comes in the smallest box, which I had a good reason to want at the time

&lt;ul&gt;
&lt;li&gt;The person who helped me, despite being very polite, also clearly thought I was a bozo and kept explaining things like &amp;quot;the size of the box and the size of the computer aren&#39;t the same&amp;quot;. Of course I knew that, but I didn&#39;t want to say something like &amp;quot;I design CPUs. I understand the difference between the size of the box the computer comes and in the size of the computer and I know it&#39;s very unusual to care about the size of the box, but I really want the one that comes in the smallest box&amp;quot;. Just saying the last bit without establishing any kind of authority didn&#39;t convince the person&lt;/li&gt;
&lt;li&gt;I eventually asked them to humor me and just bring out the boxes for the various laptop models so I could see the boxes, which they did, despite clearly thinking that my decision making process made no sense (&lt;a href=&#34;https://twitter.com/altluu/status/1452704171447123969&#34;&gt;I also tried explaining why I wanted the smallest box but that didn&#39;t work&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Covid: I took this seriously relatively early on and bought a half mask respirator on 2020-01-26 and was using N95s I&#39;d already had on hand for the week before (IMO, the case that covid was airborne and that air filtration would help was very strong based on the existing literature on SARS contact tracing, filtration of viruses from air filters, and viral load)

&lt;ul&gt;
&lt;li&gt;It wasn&#39;t until many months later that people didn&#39;t generally look at me like I was an idiot, and even as late 2020-08, I would sometimes run into people who would verbally make fun me&lt;/li&gt;
&lt;li&gt;On the flip side, the person I was living with at the time didn&#39;t want to wear the mask I got her since she found it too embarrassing to wear a mask when no one else was and became one of the early bay area covid cases, which gave her a case of long covid that floored her for months&lt;/li&gt;
&lt;li&gt;A semi-related one is that, when Canada started doing vaccines, I wanted to get Moderna even though the general consensus online and in my social circles was that Pfizer was preferred

&lt;ul&gt;
&lt;li&gt;One reason for this was it wasn&#39;t clear if the government was going to allow mixing vaccines and the delivery schedule implied that there would be a very large shortage of Pfizer for 2nd doses as well as a large supply of Moderna&lt;/li&gt;
&lt;li&gt;Another thought that had crossed my mind was that Moderna is basically &amp;quot;more stuff&amp;quot; than Pfizer and might convey better immunity in some cases, in the same way that some populations get high-dose flu shots to get better immunity&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Work: I generally don&#39;t worry about proposals or actions looking stupid

&lt;ul&gt;
&lt;li&gt;I can still remember the first time I explicitly ran into this. This was very early on my career, when I was working on chip verification. Shortly before tape-out, the head of verification wanted to use our compute resources to re-run a set of tests that had virtually no chance of finding any bugs (they&#39;d been run thousands of times before) instead of running the usual mix of tests, which would include a lot of new generated tests that had a much better chance of finding a bug (this was both logically and empirically true). I argued that we should run the tests that reduced the odds of shipping with a show stopping bug (which would cost us millions of dollars and delay shipping by three months), but the head of the group said that we would look stupid and incompetent if there was a bug that could&#39;ve been caught by one of our old &amp;quot;golden&amp;quot; tests that snuck in since the last time we&#39;d run those tests

&lt;ul&gt;
&lt;li&gt;At the time, I was shocked that somebody would deliberately do the wrong thing in order to reduce the odds of potentially looking stupid (and, really, only looking stupid to people who wouldn&#39;t understand the logic of running the best available mix of tests; since there weren&#39;t non-technical people anywhere in the management chain, anyone competent should understand the reasoning) but now that I&#39;ve worked at various companies in multiple industries, I see that most people would choose to do the wrong thing to avoid potentially looking stupid to people who are incompetent. I see the logic, but I think that it&#39;s self-sabotaging to behave that way and that the gains to my career for standing up for what I believe are the right thing have been so large that, even if the next ten times I do so, I get unlucky and it doesn&#39;t work out, that still won&#39;t erase the gains I&#39;ve made from having done the right thing many times in the past&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Air filtration: I did a bit of looking into the impact of air quality on health and bought air filters for my apartment in 2012

&lt;ul&gt;
&lt;li&gt;Friends have been chiding about this for years and strangers, dates, and acquaintances, will sometimes tell me, with varying levels of bluntness, that I&#39;m being paranoid and stupid&lt;/li&gt;
&lt;li&gt;I added more air filtration capacity when I moved to a wildfire risk area &lt;a href=&#34;https://mobile.twitter.com/altluu/status/1409762306452459520&#34;&gt;after looking into wildfire risk&lt;/a&gt; which increased the rate and bluntness of people telling me that I&#39;m weird for having air filters

&lt;ul&gt;
&lt;li&gt;I&#39;ve been basically totally unimpacted by wildfire despite living through a fairly severe wildfire season twice&lt;/li&gt;
&lt;li&gt;Other folks I know experienced some degree of discomfort, with a couple people developing persistent issues after the smoke exposure (in one case, persistent asthma, which they didn&#39;t have before or at least hadn&#39;t noticed before)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Learning things that are hard for me: this is a &amp;quot;feeling stupid&amp;quot; thing and not a &amp;quot;looking stupid&amp;quot; thing, but when I struggle with something, I feel really dumb, as in, I have a feeling/emotion that I would verbally describe as &amp;quot;feeling dumb&amp;quot;

&lt;ul&gt;
&lt;li&gt;When I was pretty young, I think before I was a teenager, I noticed that this happened when I learned things that were hard for me and tried to think of this feeling as &amp;quot;the feeling of learning something&amp;quot; instead of &amp;quot;feeling dumb&amp;quot;, which half worked (I now associate that feeling with the former as well as the latter)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Asking questions: covered above, but I frequently ask questions when there&#39;s something I don&#39;t understand or know, from basic stuff, &amp;quot;what does [some word] mean?&amp;quot; to more subtle stuff.

&lt;ul&gt;
&lt;li&gt;On the flip side, one of the most common failure modes I see with junior engineers is when someone will be too afraid to look stupid to ask questions and then learn very slowly as a result; in some cases, this is so severe it results in them being put on a PIP and then getting fired

&lt;ul&gt;
&lt;li&gt;I&#39;m sure there are other reasons this can happen, like not wanting to bother people, but in the cases where I&#39;ve been close enough to the situation to ask, it was always embarrassment and fear of looking stupid&lt;/li&gt;
&lt;li&gt;I try to be careful to avoid this failure mode when onboarding interns and junior folks and have generally been sucessful, but it&#39;s taken me up to six weeks to convince people that it&#39;s ok for them to ask questions and, until that happens, I have to constantly ask them how things are going to make sure they&#39;re not stuck. That works fine if someone is my intern, but I can observe that many intern and new hire mentors do not do this and that often results in a bad outcome for all parties

&lt;ul&gt;
&lt;li&gt;In almost every case, the person had at least interned at other companies, but they hadn&#39;t learned that it was ok to ask questions. P.S. if you&#39;re a junior engineer at a place where it&#39;s not ok to ask questions, you should look for another job if circumstances permit&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Not making excuses for failures: covered above for video games, but applies a lot more generally&lt;/li&gt;
&lt;li&gt;When learning, deliberately playing around in the area between success and failure (this applies to things like video games and sports as well as abstract intellectual pursuits)

&lt;ul&gt;
&lt;li&gt;An example would be, when learning to climb, repeatedly trying the same easy move over and over again in various ways to understand what works better and what works worse. I&#39;ve had strangers make fun of me and literally point at me and make snide comments to their friends while I&#39;m doing things like this&lt;/li&gt;
&lt;li&gt;When learning to drive, I wanted to set up some cones and drive so that I barely hit them, to understand where the edge of the car is. My father thought this idea was very stupid and I should just not hit things like curbs or cones&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Car insurance: the last time I bought car insurance, I had to confirm three times that I only wanted coverage for damage I do to others with no coverage for damage to my own vehicle if I&#39;m at fault. The insurance agent was unable to refrain from looking at me like I&#39;m an idiot and was more incredulous each time they asked if I was really sure&lt;/li&gt;
&lt;li&gt;The styling and content on this website: I regularly get design folks and typographers telling me how stupid the design is, frequently in ways that become condescending very quickly if I engage with them

&lt;ul&gt;
&lt;li&gt;But, when I tested out switching to the current design from the generally highly lauded Octopress design, this one got much better engagement when a user landed on the site and also appeared to get passed around a lot more as well&lt;/li&gt;
&lt;li&gt;When I&#39;ve compared my traffic numbers to major corporate blogs, my blog completely dominates most &amp;lt; $100B companies (e.g., it gets an order of magnitude more traffic than my employer&#39;s blog and my employer is a $50B company)&lt;/li&gt;
&lt;li&gt;When I started my blog (and this is still true today), writing advice for programming blogs &lt;a href=&#34;https://twitter.com/danluu/status/1437539076324790274&#34;&gt;was to keep it short, maybe 500 to 1000 words&lt;/a&gt;. Most of my blog posts are 5000 to 10000 words&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Taking my current job, which almost everyone thought was a stupid idea

&lt;ul&gt;
&lt;li&gt;Closely related: quitting my job at Centaur to attend &lt;a href=&#34;https://www.recurse.com/scout/click?t=b504af89e87b77920c9b60b2a1f6d5e8&#34;&gt;RC&lt;/a&gt; and then eventually changing fields into software (I don&#39;t think this would be considered as stupid now, but it was thought to be a very stupid thing to do in 2013)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Learning a sport or video game: I try things out to understand what happens when you do them, which often results in other people thinking that I&#39;m a complete idiot when the thing looks stupid, but being willing to look stupid helps me improve relatively quickly&lt;/li&gt;
&lt;li&gt;Medical care: I&#39;ve found that a lot of doctors are very confident in their opinion and get condescending pretty fast if you disagree

&lt;ul&gt;
&lt;li&gt;And yet, in the most extreme case, I would have died if I listened to my doctor; in the next most extreme case, I would have gone blind&lt;/li&gt;
&lt;li&gt;When getting blood draws, I explain to people that I&#39;m deceptively difficult to draw from and tell them what&#39;s worked in the past

&lt;ul&gt;
&lt;li&gt;About half the time, the nurse or phlebotomist takes my comments seriously, generally resulting in a straightforward and painless or nearly painless blood draw&lt;/li&gt;
&lt;li&gt;About half the time, the nurse or phlebotomist looks at me like I&#39;m an idiot and makes angry and/or condescending comments towards me; so far, everyone who&#39;s done this has failed to draw blood and/or given me a hematoma&lt;/li&gt;
&lt;li&gt;I&#39;ve had people tell me that I&#39;m probably stating my preferences an offensive way and that I should be more polite; I&#39;ve then invited them along with me to observe and no one has ever had a suggestion on how I could state things different to elicit a larger fraction of positive responses; in general, people are shocked and upset when they see how nurses and phlebotomists respond&lt;/li&gt;
&lt;li&gt;In retrospect, I should probably just get up and leave when someone has the &amp;quot;bad&amp;quot; response, which will probably increase the person&#39;s feeling that I&#39;m stupid&lt;/li&gt;
&lt;li&gt;One issue I have (and not the main one that makes it hard to &amp;quot;get a stick&amp;quot;) is that, during a blood draw, the blood will slow down and then usually stop. Some nurses like to wiggle the needle around to see if that starts things up again, which sometimes works (maybe 50/50) and will generally leave me with a giant bruise or a hematoma or both. After this happened a few times, I asked if getting my blood flowing (e.g., by moving around a lot before a blood draw) could make a difference and every nurse or phlebotomist I talked to said that was silly and that it wouldn&#39;t make any difference. I tried it anyway and that solved this problem, although I still have the problem of being hard to stick properly&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Interviews: I&#39;m generally not (perhaps not ever?) adversarial in interviews, but I try to say things that I think are true and try to avoid saying things that I think are false and this frequently &lt;a href=&#34;https://twitter.com/danluu/status/1447268693075841024&#34;&gt;causes interviews to think that I&#39;m stupid&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Generally trying to improve at things as well as being earnest

&lt;ul&gt;
&lt;li&gt;Even before &amp;quot;tryhard&amp;quot; was an insult, a lot of people in my extended social circles thought that being a tryhard was idiotic and that one shouldn&#39;t try and should instead play it cool (this was before I worked as an engineer; as an engineer, I think that effort is more highly respected than among my classmates from school as well as internet folks I knew back when I was in school)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Generally admitting when I&#39;m bad or untalented at stuff, e.g., &lt;a href=&#34;https://danluu.com/learning-to-program/&#34;&gt;mentioning that I struggled to learn to program in this post&lt;/a&gt;; an interviewer at Jane Street really dug into what I&#39;d written in that post and tore me a new one for that post (it was the most hostile interview I&#39;ve ever experienced by a very large margin), which is the kind of thing that sometimes happens when you&#39;re earnest and put yourself out there, but I still view the upsides as being greater than the downsides&lt;/li&gt;
&lt;li&gt;Recruiting: I have an unorthodox recruiting pitch which candidly leads with the downsides, often causing people to say that I&#39;m a terrible recruiter (or sarcastically say that I&#39;m a great recruiter); I haven&#39;t publicly written up the pitch (yet?) because it&#39;s negative enough that I&#39;m concerned that I&#39;d be fired for putting it on the internet

&lt;ul&gt;
&lt;li&gt;I have never failed to close a full-time candidate (I once failed to close an intern candidate) and have brought in a lot of people who never would&#39;ve considered working for us otherwise. My recruiting pitch sounds comically stupid, but it&#39;s much more effective than the standard recruiting spiel most people give&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Posting things on the internet: self explanatory&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Although most of the examples above are &amp;quot;real life&amp;quot; examples, being willing to look stupid is also highly effective at work. Besides the obvious reason that it allows you to learn faster and become more effective, it also makes it much easier to find high ROI ideas. If you go after trendy or reasonable sounding ideas, to do something really extraordinary, you have to have better ideas/execution than everyone else working on the same problem. But if you&#39;re thinking about ideas that most people consider too stupid to consider, you&#39;ll often run into ideas that are both very high ROI as well as simple and easy that anyone could&#39;ve done had they not dismissed the idea out of hand. It may still technically be true that you need to have better execution than anyone else who&#39;s trying the same thing, but if no one else trying the same thing, that&#39;s easy to do!&lt;/p&gt;

&lt;p&gt;I don&#39;t actually have to be nearly as smart or work nearly as hard as most people to get good results. If I try to solve some a problem by doing what everyone else is doing and go looking for problems where everyone else is looking, if I want to do something valuable, I&#39;ll have to do better than a lot of people, maybe even better than everybody else if the problem is really hard. If the problem is considered trendy, a lot of very smart and hardworking people will be treading the same ground and doing better than that is very difficult. But I have a dumb thought, one that&#39;s too stupid sounding for anyone else to try, I don&#39;t necessarily have to be particularly smart or talented or hardworking to come up with valuable solutions. Often, the dumb solution is something any idiot could&#39;ve come up with and the reason the problem hasn&#39;t been solved is because no one was willing to think the dumb thought until an idiot like me looked at the problem.&lt;/p&gt;

&lt;p&gt;Overall, I view the upsides of being willing to look stupid as much larger than the downsides. When it comes to things that aren&#39;t socially judged, like winning a game, understanding something, or being able to build things due to having a good understanding, it&#39;s all upside. There can be downside for things that are &amp;quot;about&amp;quot; social judgement, like interviews and dates but, even there, I think a lot of things that might seem like downsides are actually upsides.&lt;/p&gt;

&lt;p&gt;For example, if a date thinks I&#39;m stupid because I ask them what a word means, so much so that they show it in their facial expression and/or tone of voice, I think it&#39;s pretty unlikely that we&#39;re compatible, so I view finding that out sooner rather than later as upside and not downside.&lt;/p&gt;

&lt;p&gt;Interviews are the case where I think there&#39;s the most downside since, at large companies, the interviewer likely has no connection to the job or your co-workers, so them having a pattern of interaction that I would view as a downside has no direct bearing on the work environment I&#39;d have if I were offered the job and took it. There&#39;s probably some correlation but I can probably get much more signal on that elsewhere. But I think that being willing to say things that I know have a good chance of causing people to think I&#39;m stupid is a deeply ingrained enough habit that it&#39;s not worth changing just for interviews and I can&#39;t think of another context where the cost is nearly as high as it is in interviews. In principle, I could probably change how I filter what I say only in interviews, but I think that would be a very large amount of work and not really worth the cost. An easier thing to do would be to change how I think so that I reflexively avoid thinking and saying &amp;quot;stupid&amp;quot; thoughts, which a lot of folks seem to do, but that seems even more costly.&lt;/p&gt;

&lt;h3 id=&#34;appendix-do-you-try-to-avoid-looking-stupid&#34;&gt;Appendix: do you try to avoid looking stupid?&lt;/h3&gt;

&lt;p&gt;On reading a draft of this, Ben Kuhn remarked,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;[this post] caused me to realize that I&#39;m actually very bad at this, at least compared to you but perhaps also just bad in general.&lt;/p&gt;

&lt;p&gt;I asked myself &amp;quot;why can&#39;t Dan just avoid saying things that make him look stupid specifically in interviews,&amp;quot; then I started thinking about what the mental processes involved must look like in order for that to be impossible, and realized they must be extremely different from mine. Then tried to think about the last time I did something that made someone think I was stupid and realized I didn&#39;t have a readily available example)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;One problem I expect this post to have is that most people will read this and decide that they&#39;re very willing to look stupid. This reminds me of how most people, when asked, think that they&#39;re creative, innovative, and take big risks. I think that feels true since people often operate at the edge of their comfort zone, but there&#39;s a difference between feeling like you&#39;re taking big risks and taking big risks, e.g., when asked, someone I know who is among the most conservative people I know thinks that they take a lot of big risks and names things like sometimes jaywalking as risk that they take.&lt;/p&gt;

&lt;p&gt;This might sound ridiculous, &lt;a href=&#34;https://danluu.com/everything-is-broken/&#34;&gt;as ridiculous as saying that I run into hundreds to thousands of software bugs per week&lt;/a&gt;, but I think I run into someone who thinks that I&#39;m an idiot in a way that&#39;s obvious to me around once a week. The car insurance example is from a few days ago, and if I wanted to think of other recent examples, there&#39;s a long string of them.&lt;/p&gt;

&lt;p&gt;If you don&#39;t regularly have people thinking that you&#39;re stupid, I think it&#39;s likely that at least one of the following is true&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;You have extremely filtered interactions with people and basically only interact with people of your choosing and you have filtered out any people who have the reactions describe in this post

&lt;ul&gt;
&lt;li&gt;If you count internet comments, then you do not post things to the internet or do not read internet comments&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;You are avoiding looking stupid&lt;/li&gt;
&lt;li&gt;You are not noticing when people think you&#39;re stupid&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I think the last one of those is unlikely because, while I sometimes have interactions like the school one described, where the people were too nice to tell me that they think I&#39;m stupid and I only found out via a third party, just as often, the person very clearly wants me to know that they think I&#39;m stupid. The way it happens reminds me of being a pedestrian in NYC, where, when a car tries to cut you off when you have right of way and fails (e.g., when you&#39;re crossing a crosswalk and have the walk signal and the driver guns it to try to get in front of you to turn right), the driver will often scream at you and gesture angrily until you acknowledge them and, if you ignore them, will try very hard to get your attention. In the same way that it seems very important to some people who are angry that you know they&#39;re angry, many people seem to think it&#39;s very important that you know that they think that you&#39;re stupid and will keep increasing the intensity of their responses until you acknowledge that they think you&#39;re stupid.&lt;/p&gt;

&lt;p&gt;One thing that might be worth noting is that I don&#39;t go out of my way to sound stupid or otherwise be non-conformist. If anything, it&#39;s the opposite. I generally try to conform in areas that aren&#39;t important to me when it&#39;s easy to conform, e.g., I dressed more casually in the office on the west coast than on the east coast since it&#39;s not important to me to convey some particular image based on how I dress and I&#39;d rather spend my &amp;quot;weirdness points&amp;quot; on pushing radical ideas than on dressing unusually. After I changed how I dressed, one of the few people in the office who dressed really sharply in a way that would&#39;ve been normal in the east coast office jokingly said to me, &amp;quot;so, the west coast got to you, huh?&amp;quot; and a few other people remarked that I looked a lot less stuffy/formal.&lt;/p&gt;

&lt;p&gt;Another thing to note is that &amp;quot;avoiding looking stupid&amp;quot; seems to usually go beyond just filtering out comments or actions that might come off as stupid. Most people I talk to (and Ben is an exception here) have a real aversion evaluating stupid thoughts and (I&#39;m guessing) also to having stupid thoughts. When I have an idea that sounds stupid, it&#39;s generally (and again, Ben is an exception here) extremely difficult to get someone to really consider the idea. Instead, most people reflexively reject the idea without really engaging with it at all and (I&#39;m guessing) the same thing happens inside their heads when a potentially stupid sounding thought might occur to them. I think the danger here is not having a concious process that lets you decide to broadcast or not broadcast stupid sounding thoughts (that seems great if it&#39;s low overhead), and instead it&#39;s having some non-concious process automatically reject thinking about stupid sounding things.&lt;/p&gt;

&lt;p&gt;Of course, stupid-sounding thoughts are frequently wrong, so, if you&#39;re not going to rely on social proof to filter out bad ideas, you&#39;ll have to hone your intuition or find trusted friends/colleagues who are able to catch your stupid-sounding ideas that are actually stupid. That&#39;s beyond the scope of this post. but I&#39;ll note that &lt;a href=&#34;https://danluu.com/p95-skill/&#34;&gt;because almost no one attempts to hone their intuition for this kind of thing, it&#39;s very easy to get relatively good at it by just trying to do it at all&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;appendix-stories-from-other-people&#34;&gt;Appendix: stories from other people&lt;/h3&gt;

&lt;p&gt;A disproportionate fraction of people whose work I really respect operate in a similar way to me with respect to looking stupid and also have a lot of stories about looking stupid.&lt;/p&gt;

&lt;p&gt;One example from Laurence Tratt is from when he was job searching:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I remember being rejected from a job at my current employer because a senior person who knew me told other people that I was &amp;quot;too stupid&amp;quot;. For a long time, I found this bemusing (I thought I must be missing out on some deep insights), but eventually I found it highly amusing, to the point I enjoy playing with it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Another example: the other day, when I was talking to Gary Bernhardt, he told me a story about a time when he was chatting with someone who specialized in microservices on Kubernetes for startups and Gary said that he thought that most small (by transaction volume) startups could get away with being on a managed platform like Heroku or Google App Engine. The more Gary explained about his opinion, the more sure the person was that Gary was stupid.&lt;/p&gt;

&lt;h3 id=&#34;appendix-context&#34;&gt;Appendix: context&lt;/h3&gt;

&lt;p&gt;There are a lot of contexts that I&#39;m not exposed to where it may be much more effective to train yourself to avoid looking stupid or incompetent, e.g., &lt;a href=&#34;https://twitter.com/apartovi/status/1449856639331340289&#34;&gt;see this story by Ali Partovi about how his honesty led to Paul Graham&#39;s company being acquired by Yahoo instead of his own, which eventually led to Paul Graham founding YC and becoming one of the most well-known and influential people in the valley&lt;/a&gt;. If you&#39;re in a context where it&#39;s more important to look competent than to be competent then this post doesn&#39;t apply to you. Personally, I&#39;ve tried to avoid such contexts, although they&#39;re probably more lucrative than the contexts I operate in.&lt;/p&gt;

&lt;p&gt;Thanks to Ben Kuhn, Laurence Tratt, Jeshua Smith, Niels Olson, Justin Blank, Tao L., Colby Russell, Anja Boskovic, David Coletta, @conservatif, and Ahmad Jarara for comments/corrections/discussion.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:F&#34;&gt;This happens in a way that I notice something like once a week and it seems like it must happen much more frequently in ways that I don&#39;t notice.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:F&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:T&#34;&gt;&lt;p&gt;A semi-recent example of this from my life is when I wanted to understand why wider tires have better grip. A naive reason one might think this is true is that wider tire = larger contact patch = more friction, and a lot of people seem to believe the naive reason. A reason the naive reason is wrong is because, as long as the tire is inflated semi-reasonably, given a fixed vehicle weight and tire pressure, the total size of the tire&#39;s contact patch won&#39;t change when tire width is changed. Another naive reason that the original naive reason is wrong is that, at a &amp;quot;spherical cow&amp;quot; level of detail, the level of grip is unrelated to the contact patch size.&lt;/p&gt;

&lt;p&gt;Most people I talked who don&#39;t race cars (e.g., autocross, drag racing, etc.) and &lt;a href=&#34;https://twitter.com/danluu/status/1304093800474636288&#34;&gt;the top search results online used the refutation to the naive reason plus an incorrect application of high school physics to incorrectly conclude that varying tire width has no effect on grip&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;But there is an effect and the reason is subtler than more width = larger contact patch.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:T&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:B&#34;&gt;I was arguably #1 in the world one season, when I put up a statistically dominant performance and my team won every game I played even though I disproportionately played in games against other top teams (and we weren&#39;t undefeated and other top players on the team played in games we lost).
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:B&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>What to learn</title>
      <link>https://danluu.com/learn-what/</link>
      <pubDate>Mon, 18 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://danluu.com/learn-what/</guid>
      <description>

&lt;p&gt;It&#39;s common to see people advocate for learning skills that they have or using processes that they use. For example, Steve Yegge has a set of blog posts where he recommends reading compiler books and learning about compilers. His reasoning is basically that, if you understand compilers, you&#39;ll see compiler problems everywhere and will recognize all of the cases where people are solving a compiler problem without using compiler knowledge. Instead of hacking together some half-baked solution that will never work, you can apply a bit of computer science knowledge to solve the problem in a better way with less effort. That&#39;s not untrue, but it&#39;s also not a reason to study compilers in particular because you can say that about many different areas of computer science and math. Queuing theory, computer architecture, mathematical optimization, operations research, etc.&lt;/p&gt;

&lt;p&gt;One response to that kind of objection is to say that &lt;a href=&#34;https://twitter.com/danluu/status/899141882760110081&#34;&gt;one should study everything&lt;/a&gt;. While being an extremely broad generalist can work, it&#39;s gotten much harder to &amp;quot;know a bit of everything&amp;quot; and be effective because there&#39;s more of everything over time (in terms of both breadth and depth). And even if that weren&#39;t the case, I think saying “should” is too strong; whether or not someone enjoys having that kind of breadth is a matter of taste. Another approach that can also work, one that&#39;s more to my taste, is to, &lt;a href=&#34;https://alumni.media.mit.edu/~cahn/life/gian-carlo-rota-10-lessons.html&#34;&gt;as Gian Carlo Rota put it&lt;/a&gt;, learn a few tricks:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A long time ago an older and well known number theorist made some disparaging remarks about Paul Erdos&#39; work. You admire contributions to mathematics as much as I do, and I felt annoyed when the older mathematician flatly and definitively stated that all of Erdos&#39; work could be reduced to a few tricks which Erdos repeatedly relied on in his proofs. What the number theorist did not realize is that other mathematicians, even the very best, also rely on a few tricks which they use over and over. Take Hilbert. The second volume of Hilbert&#39;s collected papers contains Hilbert&#39;s papers in invariant theory. I have made a point of reading some of these papers with care. It is sad to note that some of Hilbert&#39;s beautiful results have been completely forgotten. But on reading the proofs of Hilbert&#39;s striking and deep theorems in invariant theory, it was surprising to verify that Hilbert&#39;s proofs relied on the same few tricks. Even Hilbert had only a few tricks!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If you look at how people succeed in various fields, you&#39;ll see that this is a common approach. For example, &lt;a href=&#34;https://judoinfo.com/weers1/&#34;&gt;this analysis of world-class judo players found that most rely on a small handful of throws&lt;/a&gt;, concluding&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:J&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:J&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Judo is a game of specialization. You have to use the skills that work best for you. You have to stick to what works and practice your skills until they become automatic responses.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If you watch an anime or a TV series &amp;quot;about&amp;quot; fighting, people often improve by increasing the number of techniques they know because that&#39;s an easy thing to depict but, in real life, getting better at techniques you already know is often more effective than having a portfolio of hundreds of &amp;quot;moves&amp;quot;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://staffeng.com/stories/joy-ebertz&#34; rel=&#34;nofollow&#34;&gt;Relatedly, Joy Ebertz says&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;One piece of advice I got at some point was to amplify my strengths. All of us have strengths and weaknesses and we spend a lot of time talking about ‘areas of improvement.’ It can be easy to feel like the best way to advance is to eliminate all of those. However, it can require a lot of work and energy to barely move the needle if it’s truly an area we’re weak in. Obviously, you still want to make sure you don’t have any truly bad areas, but assuming you’ve gotten that, instead focus on amplifying your strengths. How can you turn something you’re good at into your superpower?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I&#39;ve personally found this to be true in a variety of disciplines. While it&#39;s really difficult to measure programmer effectiveness in anything resembling an objective manner, this isn&#39;t true of some things I&#39;ve done, like competitive video games (a very long time ago at this point, back before there was &amp;quot;real&amp;quot; money in competitive gaming), the thing that took me from being a pretty decent player to a &lt;a href=&#34;https://danluu.com/look-stupid/#fn:B&#34;&gt;very good player&lt;/a&gt; was abandoning practicing things I wasn&#39;t particularly good at and focusing on increasing the edge I had over everybody else at the few things I was unusually good at.&lt;/p&gt;

&lt;p&gt;This can work for games and sports because you can get better maneuvering yourself into positions that take advantage of your strengths as well as avoiding situations that expose your weaknesses. I think this is actually more effective at work than it is in sports or gaming since, unlike in competitive endeavors, you don&#39;t have an opponent who will try to expose your weaknesses and force you into positions where your strengths are irrelevant. If I study queuing theory instead of compilers, a rival co-worker isn&#39;t going to stop me from working on projects where queuing theory knowledge is helpful and leave me facing a field full of projects that require compiler knowledge.&lt;/p&gt;

&lt;p&gt;One thing that&#39;s worth noting is that skills don&#39;t have to be things people would consider fields of study or discrete techniques. For the past three years, the main skill I&#39;ve been applying and improving is something you might call &amp;quot;looking at data&amp;quot;; the term is in quotes because I don&#39;t know of a good term for it. I don&#39;t think it&#39;s what most people would think of as &amp;quot;statistics&amp;quot;, in that I don&#39;t often need to do anything as sophisticated as logistic regression, let alone actually sophisticated. Perhaps one could argue that this is something data scientists do, but if I look at what I do vs. what data scientists we hire do as well as what we screen for in data scientist interviews, we don&#39;t appear to want to hire data scientists with the skill I&#39;ve been working on nor do they do what I&#39;m doing (this is a long enough topic that I might turn it into its own post at some point).&lt;/p&gt;

&lt;p&gt;Unlike Matt Might or Steve Yegge, I&#39;m not going to say that you should take a particular approach, but I&#39;ll say that working on a few things and not being particularly well rounded has worked for me in multiple disparate fields and it appears to work for a lot of other folks as well.&lt;/p&gt;

&lt;p&gt;If you want to take this approach, this still leaves the question of what skills to learn. This is one of the most common questions I get asked and I think my answer is probably not really what people are looking for and not very satisfying since it&#39;s both &lt;a href=&#34;https://twitter.com/danluu/status/1428445465662603272&#34;&gt;obvious and difficult to put into practice&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For me, two ingredients for figuring out what to spend time learning are having a relative aptitude for something (relative to other things I might do, not relative to other people) and also having a good environment in which to learn. To say that someone should look for those things is so vague that&#39;s it&#39;s nearly useless, but it&#39;s still better than the usual advice, which boils down to &amp;quot;learn what I learned&amp;quot;, which results in advice like &amp;quot;Career pro tip: if you want to get good, REALLY good, at designing complex and stateful distributed systems at scale in real-world environments, learn functional programming. It is an almost perfectly identical skillset.&amp;quot; or the even more extreme claims from some language communities, like Chuck Moore&#39;s claim that Forth is &lt;a href=&#34;https://danluu.com/boring-languages/&#34;&gt;at least 100x as productive as boring languages&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I took generic internet advice early in my career, including language advice (this was when much of this kind of advice was relatively young and it was not yet possible to easily observe that, despite many people taking advice like this, people who took this kind of advice were not particularly effective and people who are particularly effective were not likely to have taken this kind of advice). I learned &lt;a href=&#34;https://twitter.com/sc13ts/status/1448003352655060997&#34;&gt;Haskell, Lisp, Forth&lt;/a&gt;, &lt;a href=&#34;https://malisper.me/there-is-more-to-programming-than-programming-languages/&#34;&gt;etc&lt;/a&gt;. At one point in my career, I was on a two person team that implemented what might still be, a decade later, the highest performance Forth processor in existence (it was a 2GHz IPC-oriented processor) and I programmed it as well (there were good reasons for this to be a stack processor, so Forth seemed like as good a choice as any). &lt;a href=&#34;https://yosefk.com/blog/my-history-with-forth-stack-machines.html&#34;&gt;Like Yossi Kreinin, I think I can say that I spent more effort than most people have becoming proficient in Forth, and like him, not only did I not find it find it to be a 100x productivity tool, it wasn&#39;t clear that it would, in general, even be 1x on productivity&lt;/a&gt;. To be fair, a number of other tools did better than 1x on productivity but, overall, I think following internet advice was very low ROI and the things that I learned that were high ROI weren&#39;t things people were recommending.&lt;/p&gt;

&lt;p&gt;In retrospect, when people said things like &amp;quot;Forth is very productive&amp;quot;, what I suspect they really meant was &amp;quot;Forth makes me very productive and I have not considered how well this generalizes to people with different aptitudes or who are operating in different contexts&amp;quot;. I find it totally plausible that Forth (or Lisp or Haskell or any other tool or technique) does work very well for some particular people, but I think that people tend to overestimate how much something working for them means that it works for other people, &lt;a href=&#34;https://twitter.com/danluu/status/1355661542155378688&#34;&gt;making advice generally useless because it doesn&#39;t distinguish between advice that&#39;s aptitude or circumstance specific and generalizable advice, which is in stark contrast to fields where people actually discuss the pros and cons of particular techniques&lt;/a&gt;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:F&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:F&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;While a coach can give you advice that&#39;s tailored to you 1 on 1 or in small groups, that&#39;s difficult to do on the internet, which is why the best I can do here is the uselessly vague &amp;quot;pick up skills that are suitable for you&amp;quot;. Just for example, two skills that clicked for me are &amp;quot;having an adversarial mindset&amp;quot; and &amp;quot;looking at data&amp;quot;. A perhaps less useless piece of advice is that, if you&#39;re having a hard time identifying what those might be, you can ask people who know you very well, e.g., my manager and Ben Kuhn independently named coming up with solutions that span many levels of abstraction as a skill of mine that I frequently apply (and I didn&#39;t realize I was doing that until they pointed it out).&lt;/p&gt;

&lt;p&gt;Another way to find these is to look for things you can&#39;t help but do that most other people don&#39;t seem to do, which is true for me of both &amp;quot;looking at data&amp;quot; and &amp;quot;having an adversarial mindset&amp;quot;. Just for example, on having an adversarial mindset, when a company I was working for was beta testing a new custom bug tracker, I filed some of the first bugs on it and put unusual things into the fields to see if it would break. Some people really didn&#39;t understand why anyone would do such a thing and were baffled, disgusted, or horrified, but a few people (including the authors, who I knew wouldn&#39;t mind), really got it and were happy to see the system pushed past its limits. Poking at the limits of a system to see where it falls apart doesn&#39;t feel like work to me; it&#39;s something that I&#39;d have to stop myself from doing if I wanted to not do it, which made spending a decade getting better at testing and verification techniques felt like something hard not to do and not work. Looking deeply into data is one I&#39;ve spent more than a decade on at this point and it&#39;s another one that, to me, emotionally feels almost wrong to not improve at.&lt;/p&gt;

&lt;p&gt;That these things are suited to me is basically due to my personality, and not something inherent about human beings. Other people are going to have different things that really feel easy/right for them, which is great, since if everyone was into looking at data and no one was into building things, that would be very problematic (although, IMO, looking at data is, on average, underrated).&lt;/p&gt;

&lt;p&gt;The other major ingredient in what I&#39;ve tried to learn is finding environments that are conducive to learning things that line up with my skills that make sense for me. Although suggesting that other people do the same sounds like advice that&#39;s so obvious that it&#39;s useless, based on how I&#39;ve seen people select what team and company to work on, I think that almost nobody does this and, as a result, discussing this may not be completely useless.&lt;/p&gt;

&lt;p&gt;An example of not doing this which typifies what I usually see is a case I just happened to find out about because I chatted with a manager about why their team had lost their new full-time intern conversion employee. I asked them about it since it was unusual for that manager to lose anyone since they&#39;re very good at retaining people and have low turnover on their teams. It turned out that their intern had wanted to work on infra, but had joined this manager&#39;s product team because they didn&#39;t know that they could ask to be on a team that matched their preferences. After the manager found out, the manager wanted the intern to be happy and facilitated a transfer to an infra team. In this case, this was a double whammy since the new hire doubly didn&#39;t consider working in an environment conducive for learning the skills they wanted. They made no attempt to work in the area they were interested in and then they joined a company that has a dysfunctional infra org that generally has poor design and operational practices, making the company a relatively difficult place to learn about infra on top of not even trying to land on an infra team. While that&#39;s an unusually bad example, in the median case that I&#39;ve seen, people don&#39;t make decisions that result in particularly good outcomes with respect to learning even though good opportunities to learn are one of the top things people say that they want.&lt;/p&gt;

&lt;p&gt;For example, Steve Yegge has noted:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The most frequently-asked question from college candidates is: &amp;quot;what kind of training and/or mentoring do you offer?&amp;quot;
...
One UW interviewee just told me about Ford Motor Company&#39;s mentoring program, which Ford had apparently used as part of the sales pitch they do for interviewees. [I&#39;ve elided the details, as they weren&#39;t really relevant. -stevey 3/1/2006] The student had absorbed it all in amazing detail. That doesn&#39;t really surprise me, because it&#39;s one of the things candidates care about most.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For myself, I was lucky that my first job, Centaur, was a great place to develop having an adversarial mindset with respect to testing and verification. When I compare what the verification team there accomplished, it&#39;s comparable to peer projects at other companies that employed much larger teams to do very similar things with similar or worse effectiveness, implying that the team was highly productive, which made that a really good place to learn.&lt;/p&gt;

&lt;p&gt;Moreover, I don&#39;t think I could&#39;ve learned as quickly on my own or by trying to follow advice from books or the internet. I think that &lt;a href=&#34;https://danluu.com/hardware-unforgiving/&#34;&gt;people who are really good at something have too many bits of information in their head about how to do it for that information to really be compressible into a book, let alone a blog post&lt;/a&gt;. In sports, good coaches are able to convey that kind of information over time, but I don&#39;t know of anything similar for programming, so I think the best thing available for learning rate is to find an environment that&#39;s full of experts&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:M&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:M&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;For &amp;quot;looking at data&amp;quot;, while I got a lot better at it from working on that skill in environments where people weren&#39;t really taking data seriously, the rate of improvement during the past few years, where I&#39;m in an environment where I can toss ideas back and forth with people who are very good at understanding the limitations of what data can tell you as well as good at informing data analysis with deep domain knowledge, has been much higher. I&#39;d say that I improved more at this in each individual year at my current job than I did in the decade prior to my current job.&lt;/p&gt;

&lt;p&gt;One thing to perhaps note is that the environment, how you spend your day-to-day, is inherently local. My current employer is probably the least data driven of the three large tech companies I&#39;ve worked for, but my vicinity is a great place to get better at looking at data because I spend a relatively large fraction of my time working with people who are great with data, like Rebecca Isaacs, and a relatively small fraction of the time working with people who don&#39;t take data seriously.&lt;/p&gt;

&lt;p&gt;This post has discussed some strategies with an eye towards why they can be valuable, but I have to admit that my motivation for learning from experts wasn’t to create value. It&#39;s more that I find learning to be fun and there are some areas where I&#39;m motivated enough to apply the skills regardless of the environment, and learning from experts is such a great opportunity to have fun that it&#39;s hard to resist. Doing this for a couple of decades has turned out to be useful, but that&#39;s not something I knew would happen for quite a while (and I had no idea that this would effectively transfer to a new industry until I changed from hardware to software).&lt;/p&gt;

&lt;p&gt;A lot of career advice I see is oriented towards career or success or growth. That kind of advice often tells people to have a long-term goal or strategy in mind. It will often have some argument that&#39;s along the lines of &amp;quot;a random walk will only move you sqrt(n) in some direction whereas a directed walk will move you n in some direction&amp;quot;. I don&#39;t think that&#39;s wrong, but I think that, for many people, that advice implicitly underestimates the difficulty of finding an area that&#39;s suited to you&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:S&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:S&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;, which I&#39;ve basically &lt;a href=&#34;https://twitter.com/jeanqasaur/status/1074528356324892672&#34;&gt;done by trial and error&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;appendix-parts-of-the-problem-this-post-doesn-t-discuss-in-detail&#34;&gt;Appendix: parts of the problem this post doesn&#39;t discuss in detail&lt;/h3&gt;

&lt;p&gt;One major topic not discussed is how to balance what &amp;quot;level&amp;quot; of skill to work on, which could be something high level, like &amp;quot;looking at data&amp;quot;, to something lower level, like &amp;quot;Bayesian multilevel models&amp;quot;, to something even lower level, like &amp;quot;typing speed&amp;quot;. That&#39;s a large enough topic that it deserves its own post that I&#39;d expect to be longer than this one but, for now, &lt;a href=&#34;https://danluu.com/productivity-velocity/#appendix-one-way-to-think-about-what-to-improve&#34;&gt;here&#39;s a comment from Gary Bernhardt about something related that I believe also applies to this topic&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Another major topic that&#39;s not discussed here is picking skills that are relatively likely to be applicable. It&#39;s a little too naive to just say that someone should think about learning skills they have an aptitude for without thinking about applicability.&lt;/p&gt;

&lt;p&gt;But while it&#39;s pretty easy to pick out skills where it&#39;s very difficult to either have an impact on the world or make a decent amount of money or achieve whatever goal you might want to achieve, like &amp;quot;basketball&amp;quot; or &amp;quot;boxing&amp;quot;, it&#39;s harder to pick between plausible skills, like computer architecture vs. PL.&lt;/p&gt;

&lt;p&gt;But I think semi-reasonable sounding skills are likely enough to be high return if they&#39;re a good fit for someone that trial and error among semi-reasonable sounding skills is fine, although it probably helps &lt;a href=&#34;https://danluu.com/productivity-velocity/&#34;&gt;to be able to try things out quickly&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;appendix-related-posts&#34;&gt;Appendix: related posts&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Ben Kuhn on, in some sense, &lt;a href=&#34;https://www.benkuhn.net/conviction/&#34;&gt;what it&#39;s like to really learn something&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Holden Karnofsky on &lt;a href=&#34;https://80000hours.org/podcast/episodes/holden-karnofsky-building-aptitudes-kicking-ass/&#34;&gt;having an aptitude-first approach to careers instead of a career-path-first approach&lt;/a&gt;, which is sort of analogous to thinking about cross cutting skills like &amp;quot;looking at data&amp;quot; or &amp;quot;having an adversarial mindset&amp;quot; and not just thinking about skills like &amp;quot;compilers&amp;quot; or &amp;quot;queuing theory&amp;quot;&lt;/li&gt;
&lt;li&gt;Peter Drucker on &lt;a href=&#34;https://www.csub.edu/~ecarter2/CSUB.MKTG%20490%20F10/DRUCKER%20HBR%20Managing%20Oneself.pdf&#34;&gt;how to understand one&#39;s strengths and weaknesses and do work that compatible with ones own inclinations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Alexy Guzey on &lt;a href=&#34;https://guzey.com/advice/&#34;&gt;the effectiveness of advice&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Edward Kmett with &lt;a href=&#34;https://www.youtube.com/watch?v=Z8KcCU-p8QA&#34;&gt;another perspective on how to think about learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Patrick Collison &lt;a href=&#34;https://patrickcollison.com/advice&#34;&gt;on how to maximize useful learning and find what you&#39;ll enjoy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;small&gt;Thanks to Ben Kuhn, Alexey Guzey, Marek Majkowski, Nick Bergson-Shilcock, @bekindtopeople2, Aaron Levin, Milosz Danczak, Anja Boskovic, John Doty, Justin Blank, Mark Hansen, &amp;quot;wl&amp;quot;, and Jamie Brandon for comments/corrections/discussion.&lt;/small&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:J&#34;&gt;This is an old analysis. If you were to do one today, you&#39;d see a different mix of throws, but it&#39;s still the case that you see specialists having a lot of success, e.g., Riner with osoto gari
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:J&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:F&#34;&gt;To be fair to blanket, context free, advice, to learn a particular topic, functional programming really clicked for me and I could imagine that, if that style of thinking wasn&#39;t already natural for me (as a result of coming from a hardware background), the advice that one should learn functional programming because it will change how you think about problems might&#39;ve been useful for me, but on the other hand, that means that the advice could&#39;ve just as easily been to learn hardware engineering.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:F&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:M&#34;&gt;&lt;p&gt;I don&#39;t have a large enough sample nor have I polled enough people to have high confidence that this works as a general algorithm but, for finding groups of world-class experts, what&#39;s worked for me is finding excellent managers. The two teams I worked on with the highest density of world-class experts have been teams under really great management. I have a higher bar for excellent management than most people and, from having talked to many people about this, almost no one I&#39;ve talked to has worked for or even knows a manager as good as one I would consider to be excellent (and, general, both the person I&#39;m talking to agrees with me on this, indicating that it&#39;s not the case that they have a manager who&#39;s excellent in dimensions I don&#39;t care about and vice versa); from discussions about this, I would guess that a manager I think of as excellent is at least 99.9%-ile. How to find such a manager is a long discussion that I might turn into another post.&lt;/p&gt;

&lt;p&gt;Anyway, despite having a pretty small sample on this, I think the mechanism for this is plausible, in that the excellent managers I know have very high retention as well as a huge queue of people who want to work for them, making it relatively easy for them to hire and retain people with world-class expertise since &lt;a href=&#34;https://danluu.com/hiring-lemons/&#34;&gt;the rest of the landscape is so bleak&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A more typical strategy, one that I don&#39;t think generally works and also didn&#39;t work great for me when I tried it is to work on the most interesting sounding and/or hardest problems around. While I did work with some really great people while trying to &lt;a href=&#34;https://www.benkuhn.net/hard/&#34;&gt;work on interesting / hard problems&lt;/a&gt;, including one of the best engineers I&#39;ve ever worked with, I don&#39;t think that worked nearly as well as looking for good management w.r.t. working with people I really want to learn from. I believe the general problem with this algorithm is the same problem with going to work in video games because video games are cool and/or interesting. The fact that so many people want to work on exciting sounding problems leads to dysfunctional environments that can persist indefinitely.&lt;/p&gt;

&lt;p&gt;In one case, I was on a team that had 100% turnover in nine months and it would&#39;ve been six if it hadn&#39;t taken so long for one person to find a team to transfer to. In the median case, my cohort (people who joined around when I joined, ish) had about 50% YoY turnover and I think that people had pretty good reasons for leaving. Not only is this kind of turnover a sign that the environment is often a pretty unhappy one, these kinds of environments often differentially cause people who I&#39;d want to work with and/or learn from to leave. For example, on the team I was on where the TL didn&#39;t believe in using version control, automated testing, or pipelined designs, I worked with Ikhwan Lee, who was great. Of course, Ikhwan left pretty quickly while the TL stayed and is still there six years later.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:M&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:S&#34;&gt;Something I&#39;ve seen many times among my acquaintances is that people will pick a direction before they have any idea whether or not it&#39;s suitable for them. Often, after quite some time (more than a decade in some cases), they&#39;ll realize that they&#39;re actually deeply unhappy with the direction they&#39;ve gone, sometimes because it doesn&#39;t match their temperament, and sometimes because it&#39;s something they&#39;re actually bad at. In any case, wandering around randomly and finding yourself sqrt(n) down a path you&#39;re happy with doesn&#39;t seem so bad compared to having made it n down a path you&#39;re unhappy with.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:S&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Some reasons to work on productivity and velocity</title>
      <link>https://danluu.com/productivity-velocity/</link>
      <pubDate>Fri, 15 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://danluu.com/productivity-velocity/</guid>
      <description>

&lt;p&gt;A common topic of discussion among my close friends is where the bottlenecks are in our productivity and how we can execute more quickly. This is very different from what I see in my extended social circles, where people commonly say that &lt;a href=&#34;https://twitter.com/danluu/status/1440106603093495810&#34;&gt;velocity doesn&#39;t matter&lt;/a&gt;. In online discussions about this, I frequently see people go a step further and assign moral valence to this, saying that it is actually bad to try to increase velocity or be more productive or work hard (see appendix for more examples).&lt;/p&gt;

&lt;p&gt;The top reasons I see people say that productivity doesn&#39;t matter (or is actually bad) fall into one of three buckets:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Working on the right thing is more important than working quickly&lt;/li&gt;
&lt;li&gt;Speed at X doesn&#39;t matter because you don&#39;t spend much time doing X&lt;/li&gt;
&lt;li&gt;Thinking about productivity is bad and you should &amp;quot;live life&amp;quot;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I certainly agree that working on the right thing is important, but increasing velocity doesn&#39;t stop you from working on the right thing. If anything, each of these is a force multiplier for the other. Having strong execution skills becomes more impactful if you&#39;re good at picking the right problem and vice versa.&lt;/p&gt;

&lt;p&gt;It&#39;s true that the gains from picking the right problem can be greater than the gains from having better tactical execution because the gains from picking the right problem can be unbounded, but it&#39;s also much easier to improve tactical execution and doing so also helps with picking the right problem because having faster execution lets you experiment more quickly, which helps you find the right problem.&lt;/p&gt;

&lt;p&gt;A concrete example of this is a project I worked on to quantify the machine health of the fleet. The project discovered a number of serious issues (a decent fraction of hosts were actively corrupting data or had a performance problem that would increase tail latency by &amp;gt; 2 orders of magnitude, or both). This was considered serious enough that a new team was created to deal with the problem.&lt;/p&gt;

&lt;p&gt;In retrospect, my first attempts at quantifying the problem were doomed and couldn&#39;t have really worked (or not in a reasonable amount of time, anyway). I spent a few weeks cranking through ideas that couldn&#39;t work and a critical part of getting to the idea that did work after &amp;quot;only&amp;quot; a few weeks was being able to quickly try out and discard ideas that didn&#39;t work. In part of a previous post, I described how long a tiny part of that process took and multiple people objected to that being impossibly fast in internet comments.&lt;/p&gt;

&lt;p&gt;I find this a bit funny since I&#39;m not a naturally quick programmer. &lt;a href=&#34;https://danluu.com/learning-to-program/&#34;&gt;Learning to program was a real struggle for me&lt;/a&gt; and I was pretty slow at it for a long time (and I still am in aspects that I haven&#39;t practiced). My &amp;quot;one weird trick&amp;quot; is that I&#39;ve explicitly worked on speeding up things that I do frequently and most people have not. I view the situation as somewhat analogous to sports before people really trained. For a long time, many athletes didn&#39;t seriously train, and then once people started trying to train, the training was often misguided by modern standards. For example, if you read commentary on baseball from the 70s, you&#39;ll see people saying that baseball players shouldn&#39;t weight train because it will make them &amp;quot;muscle bound&amp;quot; (many people thought that weight lifting would lead to &amp;quot;too much&amp;quot; bulk, causing people to be slower, have less explosive power, and be less agile). But today, players get a huge advantage from using performance-enhancing drugs that increase their muscle-bound-ness, which implies that players could not get too &amp;quot;muscle bound&amp;quot; from weight training alone. An analogous comment to one discussed above would be saying that athletes shouldn&#39;t worry about power/strength and should increase their skill, but power increases returns to skill and vice versa.&lt;/p&gt;

&lt;p&gt;Coming back to programming, if you explicitly practice and train and almost no one else does, you&#39;ll be able to do things relatively quickly compared to most people even if, like me, you don&#39;t have much talent for programming and getting started at all was a real struggle. Of course, there&#39;s always going to be someone more talented out there who&#39;s executing faster after having spent less time improving. But, luckily for me, &lt;a href=&#34;https://danluu.com/p95-skill/&#34;&gt;relatively few people seriously attempt to improve&lt;/a&gt;, so I&#39;m able to do ok.&lt;/p&gt;

&lt;p&gt;Anyway, despite operating at a rate that some internet commenters thought was impossible, it took me weeks of dead ends to find something that worked. If I was doing things at a speed that people thought was normal, I suspect it would&#39;ve taken long enough to find a feasible solution that I would&#39;ve dropped the problem after spending maybe one or two quarters on it. The number of plausible-ish seeming dead ends was probably not unrelated to why the problem was still an open problem despite being a critical issue for years. Of course, someone who&#39;s better at having ideas than me could&#39;ve solved the problem without the dead ends, but as we discussed earlier, it&#39;s fairly easy to find low hanging fruit on &amp;quot;execution speed&amp;quot; and not so easy to find low hanging fruit on &amp;quot;having better ideas&amp;quot;. However, it&#39;s possible to, to a limited extent, simulate someone who has better ideas than me by being able to quickly try out and discard ideas (I also work on having better ideas, but I think it makes sense to go after the easier high ROI wins that are available as well). Being able to try out ideas quickly also improves the rate at which I can improve at having better ideas since a key part of that is building intuition by getting feedback on what works.&lt;/p&gt;

&lt;p&gt;The next major objection is that speed at a particular task doesn&#39;t matter because time spent on that task is limited. At a high level, I don&#39;t agree with this objection because, while this may hold true for any particular kind of task, the solution to that is to try to improve each kind of task and not to reject the idea of improvement outright. A sub-objection people have is something like &amp;quot;but I spend 20 hours in unproductive meetings every week, so it doesn&#39;t matter what I do with my other time&amp;quot;. I think this is doubly wrong, in that if you then only have 20 hours of potentially productive time, whatever productivity multiplier you have on that time still holds for your general productivity. Also, it&#39;s generally possible to drop out of meetings that are a lost cause and increase the productivity of meetings that aren&#39;t a lost cause&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:M&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:M&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;More generally, when people say that optimizing X doesn&#39;t help because they don&#39;t spend time on X and are not bottlenecked on X, that doesn&#39;t match my experience as I find I spend plenty of time bottlenecked on X for commonly dismissed Xs. I think that part of this is because getting faster at X can actually increase time spent on X due to a sort of virtuous cycle feedback loop of where it makes sense to spend time. Another part of this is illustrated in this comment by Fabian Giesen:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It is commonly accepted, verging on a cliche, that you have no idea where your program spends time until you actually profile it, but the corollary that you also don&#39;t know where &lt;em&gt;you&lt;/em&gt; spend your time until you&#39;ve measured it is not nearly as accepted.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;When I&#39;ve looked how people spend time vs. how people think they spend time, it&#39;s wildly inaccurate and I think there&#39;s a fundamental reason that, unless they measure, people&#39;s estimates of how they spend their time tends to be way off, which is nicely summed in by another Fabian Giesen quote, which happens to be about solving rubik&#39;s cubes but applies to other cognitive tasks:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Paraphrasing a well-known cuber, &amp;quot;your own pauses never seem bad while you&#39;re solving, because your brain is busy and you know what you&#39;re thinking about, but once you have a video it tends to become blindingly obvious what you need to improve&amp;quot;. Which is pretty much the usual &amp;quot;don&#39;t assume, profile&amp;quot; advice for programs, but applied to a situation where you&#39;re concentrated and busy for the entire time, whereas the default assumption in programming circles seems to be that as long as you&#39;re actually doing work and not distracted or slacking off, you can&#39;t possibly be losing a lot of time&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Unlike most people who discuss this topic online, I&#39;ve actually looked at where my time goes and a lot of it goes to things that are canonical examples of things that you shouldn&#39;t waste time improving because people don&#39;t spend much time doing them.&lt;/p&gt;

&lt;p&gt;An example of one of these, the most commonly cited bad-thing-to-optmize example that I&#39;ve seen, is typing speed (when discussing this, people usually say that typing speed doesn&#39;t matter because more time is spent thinking than typing). But, when I look at where my time goes, a lot of it is spent typing.&lt;/p&gt;

&lt;p&gt;A specific example is that I&#39;ve written a number of influential docs at my current job and when people ask how long some doc took to write, they&#39;re generally surprised that the doc only took a day to write. As with the machine health example, a thing that velocity helps with is figuring out which docs will be influential. If I look at the docs I&#39;ve written, I&#39;d say that maybe 15% were really high impact (caused a new team to be created, changed the direction of existing teams, resulted in significant changes to the company&#39;s bottom line, etc.). Part of it is that I don&#39;t always know which ideas will resonate with other people, but part of it is also that I often propose ideas that are long shots because the ideas sound too stupid to be taken seriously (e.g., one of my proposed solutions to a capacity crunch was to, for each rack, turn off 10% of it, thereby increasing effective provisioned capacity, which is about as stupid sounding an idea as one could come up with). If I was much slower at writing docs, it wouldn&#39;t make sense to propose real long shot ideas. As things are today, if I think an idea has a 5% chance of success, in expectation, I need to spend ~20 days writing docs to have one of those land.&lt;/p&gt;

&lt;p&gt;I spend roughly half my writing time typing. If I typed at what some people say median typing speed is (40 WPM) instead of the rate some random typing test clocked me at (110 WPM), this would be a 0.5 + 0.5 * 110/40 = 1.875x slowdown, putting me at nearly 40 days of writing before a longshot doc lands, which would make that a sketchier proposition. If I hadn&#39;t optimized the non-typing part of my writing workflow as well, I think I would be, on net, maybe 10x slower&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:T&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:T&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;, which would put me at more like ~200 days per high impact longshot doc, which is enough that I think that I probably wouldn&#39;t write longshot docs&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:S&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:S&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;More generally, Fabian Giesen has noted that this kind of non-linear impact of velocity is common:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;There are &amp;quot;phase changes&amp;quot; as you cross certain thresholds (details depend on the problem to some extent) where your entire way of working changes.
...
​​There&#39;s a lot of things I could in theory do at any speed but in practice cannot, because as iteration time increases it first becomes so frustrating that I can&#39;t do it for long and eventually it takes so long that it literally drops out of my short-term memory, so I need to keep notes or otherwise organize it or I can&#39;t do it at all.&lt;/p&gt;

&lt;p&gt;Certainly if I can do an experiment in an interactive UI by dragging on a slider and see the result in a fraction of a second, at that point it&#39;s very &amp;quot;no filter&amp;quot;, if you want to try something you just do it.&lt;/p&gt;

&lt;p&gt;Once you&#39;re at iteration times in the low seconds (say a compile-link cycle with a statically compiled lang) you don&#39;t just try stuff anymore, you also spend time thinking about whether it&#39;s gonna tell you anything because it takes long enough that you&#39;d rather not waste a run.&lt;/p&gt;

&lt;p&gt;Once you get into several-minute or multi-hour iteration times there&#39;s a lot of planning to not waste runs, and context switching because you do other stuff while you wait, and note-taking/bookkeeping; also at this level mistakes are both more expensive (because a wasted run wastes more time) and more common (because your attention is so divided).&lt;/p&gt;

&lt;p&gt;As you scale that up even more you might now take significant resources for a noticeable amount of time and need to get that approved and budgeted, which takes its own meetings etc.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;A specific example of something moving from one class of item to another in my work was &lt;a href=&#34;https://danluu.com/metrics-analytics/&#34;&gt;this project on metrics analytics&lt;/a&gt;. There were a number of proposals on how to solve this problem. There was broad agreement that the problem was important with no dissenters, but the proposals were all the kinds of things you&#39;d allocate a team to work on through multiple roadmap cycles. Getting a project that expensive off the ground requires a large amount of organizational buy-in, enough that many important problems don&#39;t get solved, including this one. But it turned out, if scoped properly and executed reasonably, the project was actually something a programmer could create an MVP of in a day, which takes no organizational buy-in to get off the ground. Instead of needing to get multiple directors and a VP to agree that the problem is among the org&#39;s most important problems, you just need a person who thinks the problem is worth solving.&lt;/p&gt;

&lt;p&gt;Going back to Xs where people say velocity doesn&#39;t matter because they don&#39;t spend a lot time on X, another one I see frequently is coding, and it is also not my personal experience that coding speed doesn&#39;t matter. For the machine health example discussed above, after I figured out something that would work, I spent one month working on basically nothing but that, coding, testing, and debugging. I think I had about 6 hours of meetings during that month, but other than that plus time spent eating, etc., I would go in to work, code all day, and then go home. I think it&#39;s much more difficult to compare coding speed across people because it&#39;s rare to see people do the same or very similar non-trivial tasks, so I won&#39;t try to compare to anyone else, but if I look at my productivity before I worked on improving it as compared to where I&#39;m at now, the project probably would have been infeasible without the speedups I&#39;ve found by looking at my velocity.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Amdahl%27s_law&#34;&gt;Amdahl&#39;s law&lt;/a&gt; based arguments can make sense when looking for speedups in a fixed benchmark, like a sub-task of SPECint, but when you have a system where getting better at a task increases returns to doing that task and can increase time spent on the task, it doesn&#39;t make sense to say that you shouldn&#39;t work on something because you spend a lot of time doing it. I spend time on things that are high ROI, but those things are generally only high ROI because I&#39;ve spent time improving my velocity, which reduces the &amp;quot;I&amp;quot; in ROI.&lt;/p&gt;

&lt;p&gt;The last major argument I see against working on velocity assigns negative moral weight to the idea of thinking about productivity and working on velocity at all. This kind of comment often assigns positive moral weight to various kinds of leisure, such as spending time with friends and family. I find this argument to be backwards. If someone thinks it&#39;s important to spend time with friends and family, an easy way to do that is to be more productive at work and spend less time working.&lt;/p&gt;

&lt;p&gt;Personally, I deliberately avoid working long hours and I suspect I don&#39;t work more than the median person at my company, which is a company where I think work-life balance is pretty good overall. A lot of my productivity gains have gone to leisure and not work. Furthermore, deliberately working on velocity has &lt;a href=&#34;https://twitter.com/danluu/status/1444034823329177602&#34;&gt;allowed me to get promoted relatively quickly&lt;/a&gt;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:P&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:P&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;, which means that I make more money than I would&#39;ve made if I didn&#39;t get promoted, which gives me more freedom to spend time on things that I value.&lt;/p&gt;

&lt;p&gt;For people that aren&#39;t arguing that you shouldn&#39;t think about productivity because it&#39;s better to focus on leisure and instead argue that you simply shouldn&#39;t think about productivity at all because it&#39;s unnatural and one should live a natural life, that ultimately comes down to personal preference, but for me, I value the things I do outside of work too much to not explicitly work on productivity at work.&lt;/p&gt;

&lt;p&gt;As with &lt;a href=&#34;https://danluu.com/why-benchmark/&#34;&gt;this post on reasons to measure&lt;/a&gt;, while this post is about practical reasons to improve productivity, the main reason I&#39;m personally motivated to work on my own productivity isn&#39;t practical. The main reason is that I enjoy the process of getting better at things, whether that&#39;s some nerdy board game, a sport I have zero talent at that will never have any practical value to me, or work. For me, a secondary reason is that, given that  my lifespan is finite, I want to allocate my time to things that I value, and increasing productivity allows me to do more of that, but that&#39;s not a thought i had until I was about 20, at which point I&#39;d already been trying to improve at most things I spent significant time on for many years.&lt;/p&gt;

&lt;p&gt;Another common reason for working on productivity is that mastery and/or generally being good at something seems satisfying for a lot of people. That&#39;s not one that resonates with me personally, but when I&#39;ve asked other people about why they work on improving their skills, that seems to be a common motivation.&lt;/p&gt;

&lt;p&gt;A related idea, one that Holden Karnofsky has been talking about for a while, is that if you ever want to make a difference in the world in some way, it&#39;s useful to work on your skills even in jobs where it&#39;s not obvious that being better at the job is useful, because the developed skills will give you more leverage on the world when you switch to something that&#39;s more aligned with you want to achieve.&lt;/p&gt;

&lt;h3 id=&#34;appendix-one-way-to-think-about-what-to-improve&#34;&gt;Appendix: one way to think about what to improve&lt;/h3&gt;

&lt;p&gt;Here&#39;s a framing I like from Gary Bernhardt (not set off in a quote block since this entire section, other than this sentence, is his).&lt;/p&gt;

&lt;p&gt;People tend to fixate on a single granularity of analysis when talking about efficiency. E.g., &amp;quot;thinking is the most important part so don&#39;t worry about typing speed&amp;quot;. If we step back, the response to that is &amp;quot;efficiency exists at every point on the continuum from year-by-year strategy all the way down to millisecond-by-millisecond keystrokes&amp;quot;. I think it&#39;s safe to assume that gains at the larger scale will have the biggest impact. But as we go to finer granularity, it&#39;s not obvious where the ROI drops off. Some examples, moving from coarse to fine:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The macro point that you started with is: programming isn&#39;t just thinking; it&#39;s thinking plus tactical activities like editing code. Editing faster means more time for thinking.&lt;/li&gt;
&lt;li&gt;But editing code costs more than just the time spent typing! Programming is highly dependent on short-term memory. Every pause to edit is a distraction where you can forget the details that you&#39;re juggling. Slower editing effectively weakens your short-term memory, which reduces effectiveness.&lt;/li&gt;
&lt;li&gt;But editing code isn&#39;t just hitting keys! It&#39;s hitting keys plus the editor commands that those keys invoke. A more efficient editor can dramatically increase effective code editing speed, even if you type at the same WPM as before.&lt;/li&gt;
&lt;li&gt;But each editor command doesn&#39;t exist in a vacuum! There are often many ways to make the same edit. A Vim beginner might type &amp;quot;hhhhxxxxxxxx&amp;quot; when &amp;quot;bdw&amp;quot; is more efficient. An advanced Vim user might use &amp;quot;bdw&amp;quot;, not realizing that it&#39;s slower than &amp;quot;diw&amp;quot; despite having the same number of keystrokes. (In QWERTY keyboard layout, the former is all on the left hand, whereas the latter alternates left-right-left hands. At 140 WPM, you&#39;re typing around 14 keystrokes per second, so each finger only has 70 ms to get into position and press the key. Alternating hands leaves more time for the next finger to get into position while the previous finger is mid-keypress.)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We have to choose how deep to go when thinking about this. I think that there&#39;s clear ROI in thinking about 1-3, and in letting those inform both tool choice and practice. I don&#39;t think that (4) is worth a lot of thought. It seems like we naturally find &amp;quot;good enough&amp;quot; points there. But that also makes it a nice fence post to frame the others.&lt;/p&gt;

&lt;h3 id=&#34;appendix-more-examples&#34;&gt;Appendix: more examples&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=10529064&#34;&gt;In the comments on a post where Ben Kuhn notes that he got 50% more productive by allocating his time better, people are nearly uniformly negative about the post and say that he works too much&lt;/a&gt;. Although Ben clarified in multiple comments as well as in the post that not all time tracked was worked, the commenters are too busy taking the moral high ground to actually respond to the contents of the post&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=28879240&#34;&gt;Comments on Jamie Brandon&#39;s &amp;quot;Speed Matters&amp;quot;&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=28880190&#34;&gt;Working quickly is pointless because you will be forced to do more work&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=28881360&#34;&gt;Speed doesn&#39;t matter if you&#39;re doing the right thing, and also, if such a thing as speed did exist, it would be unmeasurable and therefore pointless to discuss&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=28879823&#34;&gt;Thinking about productivity is unhealthy. One should relax instead&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=28881320&#34;&gt;You can only choose 2 of &amp;quot;good, fast, cheap&amp;quot;, therefore it is counterproductive to work on speed&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=28880653&#34;&gt;A large speedup is impossible&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=28880173&#34;&gt;&amp;quot;The author mistakes coding for typing&amp;quot;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;li&gt;As with Ben&#39;s post, virtually all of these comments are addressed in the post itself. I&#39;m going to stop noting when this is true because it is generally true of the posts referred to here.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=22255996&#34;&gt;The #3 comment on a post by Michael Malis on &amp;quot;How to Improve Your Productivity as a Working Programmer
&amp;quot;&lt;/a&gt;: &amp;quot;Fuck it, the entire work environment seems designed to decrease productivity . . . Why should I bother . . .&amp;quot;

&lt;ul&gt;
&lt;li&gt;#4 comment: &amp;quot;What if I don&#39;t want to improve my productivity ? Just take time.&amp;quot;

&lt;ul&gt;
&lt;li&gt;After the initial indignation, this comment goes on and proves that the commenter missed the point entirely, as the rest of the comment explains how the commenter works productively, which the commenter apparently is ok with as long as it&#39;s not phrased as a way to work productively, because one is supposed to be morally outraged by someone wanting to be productive and sharing techniques about how to be productive with other people who might be interested in being productive&lt;/li&gt;
&lt;li&gt;In the responses, someone points out that someone who&#39;s more productive would be able to spend more time on leisure; that comment is uniformly panned because &amp;quot;work expands so as to fill the time available for its completion&amp;quot;, as if how one spends time is some sort of immutable law of nature and not something under anyone&#39;s control&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Another comment: &amp;quot;Alright. What are we optimizing for? Productivity? Or the end-goals of any of: achieving more, climbing the corporate ladder, making more money, etc..?&amp;quot;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=13752887&#34;&gt;Comments on a post by antirez about productivity&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=13753443&#34;&gt;The article is talking about the 10x programmer universe, not the normal universe most people live in&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=13753611&#34;&gt;It&#39;s pointless to work on productivity since your environment determines productivity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=13753465&#34;&gt;Productive programmers are selfish, don&#39;t mentor, etc., and are bad for their teams&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;If you read the entire comments to the post, you&#39;ll see that this is a common theme&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=20737304&#34;&gt;Comments on Alexy Guezy&#39;s thoughts on productivity&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=20737854&#34;&gt;&amp;quot;Serious question: Is anything less productive than reading other people&#39;s productivity thoughts? It&#39;s a combination of procrastination and finding out what works for someone who is presumably more productive than you (ie: guilt).&amp;quot;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=20737854&#34;&gt;An anti-productivity article titled &amp;quot;Against Productivity&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/b0rk/status/1367172498954059791&#34;&gt;Velocity doesn&#39;t matter&lt;/a&gt;, from the person who I believe has been the most widely read programming blogger since about 2015&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;etc.&lt;/p&gt;

&lt;p&gt;Some positive examples of people who have used their productivity to &amp;quot;fund&amp;quot; things that they value include Andy Kelley (Zig), Jamie Brandon (various), Andy Matuschak (mnemonic medium, various), Saul Pwanson (VisiData), Andy Chu (Oil Shell). I&#39;m drawing from programming examples, but you can find plenty of others, e.g., Nick Adnitt (&lt;a href=&#34;https://darksidecanoes.wordpress.com/&#34;&gt;Darkside Canoes&lt;/a&gt;) and, of course, numerous people who&#39;ve retired to pursue interests that aren&#39;t work-like at all.&lt;/p&gt;

&lt;h3 id=&#34;appendix-another-reason-to-avoid-being-productive&#34;&gt;Appendix: another reason to avoid being productive&lt;/h3&gt;

&lt;p&gt;An idea that&#39;s become increasingly popular in my extended social circles at major tech companies is that one should avoid doing work and &lt;a href=&#34;https://www.reddit.com/r/antiwork/comments/pvjc6f/they_dont_give_a_fuck_about_you/&#34;&gt;waste as much time as possible&lt;/a&gt;, often called &amp;quot;antiwork&amp;quot;, which seems like a natural extension of &amp;quot;tryhard&amp;quot; becoming an insult. The reason given is often something like, work mainly enriches upper management at your employer and/or shareholders, who are generally richer than you.&lt;/p&gt;

&lt;p&gt;I&#39;m sympathetic to the argument and &lt;a href=&#34;https://twitter.com/danluu/status/802971209176477696&#34;&gt;agree that upper management and shareholders capture most of the value from work&lt;/a&gt;. But as much as I sympathize with the idea of deliberately being unproductive to &amp;quot;stick it to the man&amp;quot;, I value spending my time on things that I want enough that I&#39;d rather get my work done quickly so I can do things I enjoy more than work. Additionally, having been productive in the past has given me good options for jobs, so I have work that I enjoy a lot more than my acquaintances in tech who have embraced the &amp;quot;antiwork&amp;quot; movement.&lt;/p&gt;

&lt;p&gt;The less control you have over your environment, the more it makes sense to embrace &amp;quot;antiwork&amp;quot;. Programmers at major tech companies have, relatively speaking, a lot of control over their environment, which is why I&#39;m not &amp;quot;antiwork&amp;quot; even though I&#39;m sympathetic to the cause.&lt;/p&gt;

&lt;p&gt;Although it&#39;s about a different topic, a related comment &lt;a href=&#34;https://twitter.com/PracheeAC/status/1448789430488092672&#34;&gt;from Prachee Avasthi about avoiding controversial work and avoiding pushing for necessary changes when pre-tenure ingrains habits that are hard break post-tenure&lt;/a&gt;. If one wants to be &amp;quot;antiwork&amp;quot; forever, that&#39;s not a problem, but if one wants to move the needle on something at some point, building &amp;quot;antiwork&amp;quot; habits while working for a major tech company will instill counterproductive habits.&lt;/p&gt;

&lt;p&gt;&lt;small&gt; Thanks to Fabian Giesen, Gary Bernhardt, Ben Kuhn, David Turner, Marek Majkowski, Anja Boskovic, Aaron Levin, Lifan Zeng, Justin Blank, Heath Borders, Tao L., Nehal Patel, and Jamie Brandon for comments/corrections/discussion&lt;/small&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:M&#34;&gt;When I look at the productiveness of meetings, there are some people who are very good at keeping meetings on track and useful. For example, one person who I&#39;ve been in meetings with who is extraordinarily good at ensuring meetings are productive is Bonnie Eisenman. Early on in my current job, I asked her how she was so effective at keeping meetings productive and have been using that advice since then (I&#39;m not nearly as good at it as she is, but even so, improving at this was a significant win for me).
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:M&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:T&#34;&gt;&lt;p&gt;10x might sound like an implausibly large speedup on writing, but in a discussion on writing speed on a private slack, a well-known newsletter author mentioned that their net writing speed for a 5k word newsletter was a little under 2 words per minute (WPM). My net rate (including time spent editing, etc.) is over 20 WPM per doc.&lt;/p&gt;

&lt;p&gt;With a measured typing speed of 110 WPM, that might sound like I spend a small fraction of my time typing, but it turns out it&#39;s roughly half the time. If I look at my writing speed, it&#39;s much slower than my typing test speed and it seems that it&#39;s perhaps half the rate. If I look at where the actual time goes, roughly half of it goes to typing and have goes to thinking, semi-serially, which creates long pauses in my typing.&lt;/p&gt;

&lt;p&gt;If I look at where the biggest win here could come, it would be from thinking and typing in parallel, which is something I&#39;d try to achieve by practicing typing more, not less. But even without being able to do that, and with above average typing speed, I still spend half of my time typing!&lt;/p&gt;

&lt;p&gt;The reason my net speed is well under the speed that I write is that I do multiple passes and re-write. Some time is spent reading as I re-write, but I read much more quickly than I write, so that&#39;s a pretty small fraction of time. In principle, I could adopt an approach that involves less re-writing, but I&#39;ve tried a number of things that one might expect would lead to that goal and haven&#39;t found one that works for me (yet?).&lt;/p&gt;

&lt;p&gt;Although the example here is about work, this also holds for my personal blog, where my velocity is similar. If I wrote ten times slower than I do, I don&#39;t think I&#39;d have much of a blog. My guess is that I would&#39;ve written a few posts or maybe even a few drafts and not gotten to the point where I&#39;d post and then stop.&lt;/p&gt;

&lt;p&gt;I enjoy writing and get a lot of value out of it in a variety of ways, but I value the other things in my life enough that I don&#39;t think writing would have a place in my life if my net writing speed were 2 WPM.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:T&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:S&#34;&gt;&lt;p&gt;Another strategy would be to write shorter docs. There&#39;s a style of doc where that works well, but I frequently write docs where I leverage my writing speed to discuss a problem that would be difficult to convincingly discuss without a long document.&lt;/p&gt;

&lt;p&gt;One example of a reason that my docs is that I frequently work on problems that span multiple levels of the stack, which means that I end up presenting data from multiple levels of the stack as well as providing enough context about why the problem at some level drives a problem up or down the stack for people who aren&#39;t deeply familiar with that level of the stack, which is necessary since few readers will have strong familiarity with every level needed to understand the problem.&lt;/p&gt;

&lt;p&gt;In most cases, there have been previous attempts to motivate/fund work on the problem that didn&#39;t get traction because there wasn&#39;t a case linking an issue at one level of the stack to important issues at other levels of the stack. I could avoid problems that span many levels of the stack, but there&#39;s a lot of low hanging fruit among those sorts of problems for technical and organizational reasons, so I don&#39;t think it makes sense to ignore them just because it takes a day to write a document explaining the problem (although it might make sense if it took ten days, at least in cases where people might be skeptical of the solution).&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:S&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:P&#34;&gt;Of course, promotions are highly unfair and being more productive doesn&#39;t guarantee promotion. If I just look at what things are correlated with level, &lt;a href=&#34;https://twitter.com/altluu/status/1448012821854257155&#34;&gt;it&#39;s not even clear to me that productivity is more strongly correlated with level than height&lt;/a&gt;, but among factors that are under my control, productivity is one of the easiest to change.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:P&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The value of in-house expertise</title>
      <link>https://danluu.com/in-house/</link>
      <pubDate>Wed, 29 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://danluu.com/in-house/</guid>
      <description>&lt;p&gt;An alternate title for this post might be, &amp;quot;Twitter has a kernel team!?&amp;quot;. At this point, I&#39;ve heard that surprised exclamation enough that I&#39;ve lost count of the number times that&#39;s been said to me (I&#39;d guess that it&#39;s more than ten but less than a hundred). If we look at trendy companies that are within a couple factors of two in size of Twitter (in terms of either market cap or number of engineers), they mostly don&#39;t have similar expertise, often as a result of path dependence — because they &amp;quot;grew up&amp;quot; in the cloud, they didn&#39;t need kernel expertise to keep the lights on the way an on prem company does. While that makes it socially understandable that people who&#39;ve spent their career at younger, trendier, companies, are surprised by Twitter having a kernel team, I don&#39;t think there&#39;s a technical reason for the surprise.&lt;/p&gt;

&lt;p&gt;Whether or not it has kernel expertise, a company Twitter&#39;s size is going to regularly run into kernel issues, from major production incidents to papercuts. Without a kernel team or the equivalent expertise, the company will muddle through the issues, running into unnecessary problems as well as taking an unnecessarily long time to mitigate incidents. As an example of a critical production incident, just because it&#39;s already been written up publicly, I&#39;ll cite &lt;a href=&#34;https://blog.twitter.com/engineering/en_us/topics/open-source/2020/hunting-a-linux-kernel-bug&#34;&gt;this post&lt;/a&gt;, which dryly notes:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Earlier last year, we identified a firewall misconfiguration which accidentally dropped most network traffic. We expected resetting the firewall configuration to fix the issue, but resetting the firewall configuration exposed a kernel bug&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;What this implies but doesn&#39;t explicitly say is that this firewall misconfiguration was the most severe incident that&#39;s occured during my time at Twitter and I believe it&#39;s actually the most severe outage that Twitter has had since 2013 or so. As a company, we would&#39;ve still been able to mitigate the issue without a kernel team or another team with deep Linux expertise, but it would&#39;ve taken longer to understand why the initial fix didn&#39;t work, which is the last thing you want when you&#39;re debugging a serious outage. Folks on the kernel team were already familiar with the various diagnostic tools and debugging techniques necessary to quickly understand why the initial fix didn&#39;t work, which is not common knowledge at some peer companies (I polled folks at a number of similar-scale peer companies to see if they thought they had at least one person with the knowledge necessary to quickly debug the bug and the answer was no at many companies).&lt;/p&gt;

&lt;p&gt;Another reason to have in-house expertise in various areas is that they easily pay for themselves, which is a special case of &lt;a href=&#34;https://danluu.com/sounds-easy/&#34;&gt;the generic argument that large companies should be larger than most people expect because tiny percentage gains are worth a large amount in absolute dollars&lt;/a&gt;. If, in the lifetime of the specialist team like the kernel team, a single person found something that persistently reduced &lt;a href=&#34;https://en.wikipedia.org/wiki/Total_cost_of_ownership&#34;&gt;TCO&lt;/a&gt; by 0.5%, that would pay for the team in perpetuity, and Twitter’s kernel team has found many such changes. In addition to &lt;a href=&#34;https://patchwork.ozlabs.org/project/netdev/list/?submitter=211&amp;amp;state=*&amp;amp;archive=both&amp;amp;param=4&amp;amp;page=1&#34;&gt;kernel patches&lt;/a&gt; that sometimes have that kind of impact, people will also find configuration issues, etc., that have that kind of impact.&lt;/p&gt;

&lt;p&gt;So far, I&#39;ve only talked about the kernel team because that&#39;s the one that most frequently elicits surprise from folks for merely existing, but I get similar reactions when people find out that Twitter has a bunch of ex-Sun JVM folks who worked on HotSpot, like Ramki Ramakrishna, Tony Printezis, and John Coomes. People wonder why a social media company would need such deep JVM expertise. As with the kernel team, companies our size that use the JVM run into weird issues and JVM bugs and it&#39;s helpful to have people with deep expertise to debug those kinds of issues. And, as with the kernel team, individual optimizations to the JVM can pay for the team in perpetuity. A concrete example is &lt;a href=&#34;https://github.com/oracle/graal/pull/636&#34;&gt;this patch by Flavio Brasil, which virtualizes compare and swap calls&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The context for this is that Twitter uses a lot of Scala. Despite a lot of claims otherwise, Scala uses more memory and is significantly slower than Java, which has a significant cost if you use Scala at scale, enough that it makes sense to do optimization work to reduce the performance gap between idiomatic Scala and idiomatic Java.&lt;/p&gt;

&lt;p&gt;Before the patch, if you profiled our Scala code, you would&#39;ve seen an unreasonably large amount of time spent in Future/Promise, including in cases where you might naively expect that the compiler would optimize the work away. One reason for this is that Futures use a &lt;a href=&#34;https://en.wikipedia.org/wiki/Compare-and-swap&#34;&gt;compare-and-swap&lt;/a&gt; (CAS) operation that&#39;s opaque to JVM optimization. The patch linked above avoids CAS operations when the Future doesn&#39;t escape the scope of the method. &lt;a href=&#34;https://github.com/twitter/util/commit/3245a8e1a98bd5eb308f366678528879d7140f5e&#34;&gt;This companion patch&lt;/a&gt; removes CAS operations in some places that are less amenable to compiler optimization. The two patches combined reduced the cost of typical major Twitter services using idiomatic Scala by 5% to 15%, paying for the JVM team in perpetuity many times over and that wasn&#39;t even the biggest win Flavio found that year.&lt;/p&gt;

&lt;p&gt;I&#39;m not going to do a team-by-team breakdown of teams that pay for themselves many times over because there are so many of them, even if I limit the scope to &amp;quot;teams that people are surprised that Twitter has&amp;quot;.&lt;/p&gt;

&lt;p&gt;A related topic is how people talk about &amp;quot;buy vs. build&amp;quot; discussions. I&#39;ve seen a number of discussions where someone has argued for &amp;quot;buy&amp;quot; because that would obviate the need for expertise in the area. This can be true, but I&#39;ve seen this argued for much more often than it is true. An example where I think this tends to be untrue is with distributed tracing. &lt;a href=&#34;https://danluu.com/tracing-analytics/&#34;&gt;We&#39;ve previously looked at some ways Twitter gets value out of tracing&lt;/a&gt;, which came out of the vision Rebecca Isaacs put into place. On the flip side, when I talk to people at peer companies with similar scale, most of them have not (yet?) succeeded at getting significant value from distributed tracing. This is so common that I see a viral Twitter thread about how useless distributed tracing is more than once a year. Even though we went with the more expensive &amp;quot;build&amp;quot; option, just off the top of my head, I can think of multiple uses of tracing that have returned between 10x and 100x the cost of building out tracing, whereas people at a number of companies that have chosen the cheaper &amp;quot;buy&amp;quot; option commonly complain that tracing isn&#39;t worth it.&lt;/p&gt;

&lt;p&gt;Coincidentally, I was just talking about this exact topic to Pam Wolf, a civil engineering professor with experience in (civil engineering) industry on multiple continents, who had a related opinion. For large scale systems (projects), you need an in-house expert (owner&#39;s-side engineer) for each area that you don&#39;t handle in your own firm. While it&#39;s technically possible to hire yet another firm to be the expert, that&#39;s more expensive than developing or hiring in-house expertise and, in the long run, also more risky. That&#39;s pretty analogous to my experience working as an electrical engineer as well, where orgs that outsource functions to other companies without retaining an in-house expert pay a very high cost, and not just monetarily. They often ship sub-par designs with long delays on top of having high costs. &amp;quot;Buying&amp;quot; can and often does reduce the amount of expertise necessary, but it often doesn&#39;t remove the need for expertise.&lt;/p&gt;

&lt;p&gt;This related to another common abstract argument that&#39;s commonly made, that companies should concentrate on &amp;quot;their area of comparative advantage&amp;quot; or &amp;quot;most important problems&amp;quot; or &amp;quot;core business need&amp;quot; and outsource everything else. We&#39;ve already seen a couple of examples where this isn&#39;t true because, at a large enough scale, it&#39;s more profitable to have in-house expertise than not regardless of whether or not something is core to the business (one could argue that all of the things that are moved in-house are core to the business, but that would make the concept of coreness useless). Another reason this abstract advice is too simplistic is that businesses can somewhat arbitrarily choose what their comparative advantage is. A large&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:L&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:L&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; example of this would be Apple bringing CPU design in-house. Since acquiring PA Semi (formerly the team from SiByte and, before that, a team from DEC) for $278M, Apple has been producing &lt;a href=&#34;https://twitter.com/danluu/status/1433297089866383364&#34;&gt;the best chips in the phone and laptop power envelope by a pretty large margin&lt;/a&gt;. But, before the purchase, there was nothing about Apple that made the purchase inevitable, that made CPU design an inherent comparative advantage of Apple. But if a firm can pick an area and make it an area of comparative advantage, saying that the firm should choose to concentrate on its comparative advantage(s) isn&#39;t very helpful advice.&lt;/p&gt;

&lt;p&gt;$278M is a lot of money in absolute terms, but as a fraction of Apple&#39;s resources, that was tiny and much smaller companies also have the capability to do cutting edge work by devoting a small fraction of their resources to it, e.g., Twitter, for a cost that any $100M company could afford, &lt;a href=&#34;https://twitter.com/danluu/status/1381687511362138113&#34;&gt;created novel cache algorithms and data structures&lt;/a&gt; and is doing other cutting edge cache work. Having great cache infra isn&#39;t any more core to Twitter&#39;s business than creating a great CPU is to Apple&#39;s, but it is a lever that Twitter can use to make more money than it could otherwise.&lt;/p&gt;

&lt;p&gt;For small companies, it doesn&#39;t make sense to have in-house experts for everything the company touches, but companies don&#39;t have to get all that large before it starts making sense to have in-house expertise in their operating system, language runtime, and other components that people often think of as being fairly specialized. Looking back at Twitter&#39;s history, Yao Yue has noted that when she was working on cache in Twitter&#39;s early days (when we had ~100 engineers), she would regularly go to the kernel team for help debugging production incidents and that, in some cases, debugging could&#39;ve easily taken 10x longer without help from the kernel team. Social media companies tend to have relatively high scale on a per-user and per-dollar basis, so not every company is going to need the same kind of expertise when they have 100 engineers, but there are going to be other areas that aren&#39;t obviously core business needs where expertise will pay off even for a startup that has 100 engineers.&lt;/p&gt;

&lt;p&gt;Thanks to Ben Kuhn, Yao Yue, Pam Wolf, John Hergenroeder, Julien Kirch, Tom Brearley, and Kevin Burke for comments/corrections/discussion.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:L&#34;&gt;&lt;p&gt;Some other large examples of this are Korean chaebols, like Hyundai. Looking at how Hyundai Group&#39;s companies are connected to Hyundai Motor Company isn&#39;t really the right lens with which to examine Hyundai, but I&#39;m going to use that lens anyway since most readers of this blog are probably already familiar with Hyundai Motor and will not be familiar with how Korean chaebols operate.&lt;/p&gt;

&lt;p&gt;Speaking very roughly, with many exceptions, American companies have tended to take the advice to specialize and concentrate on their competencies, at least since the 80s. This is the opposite of the direction that Korean chaebols have gone. Hyundai not only makes cars, they make the steel their cars use, the robots they use to automate production, the cement used for their factories, the construction equipment used to build their factories, the containers and ships used to ship cars (which they also operate), the transmissions for their cars, etc.&lt;/p&gt;

&lt;p&gt;If we look at a particular component, say, their 8-speed transmission vs. the widely used and lauded ZF 8HP transmission, reviewers typically slightly prefer the ZF transmission. But even so, having good-enough in-house transmissions, as well as many other in-house components that companies would typically buy, doesn&#39;t exactly seem to be a disadvantage for Hyundai.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:L&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Some reasons to measure</title>
      <link>https://danluu.com/why-benchmark/</link>
      <pubDate>Fri, 27 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://danluu.com/why-benchmark/</guid>
      <description>

&lt;p&gt;A question I get asked with some frequency is: why bother measuring X, why not build something instead? More bluntly, in a recent conversation with a newsletter author, his comment on some future measurement projects I wanted to do (in the same vein as other projects like &lt;a href=&#34;https://danluu.com/keyboard-v-mouse/&#34;&gt;keyboard vs. mouse&lt;/a&gt;, &lt;a href=&#34;https://danluu.com/keyboard-latency/&#34;&gt;keyboard&lt;/a&gt;, &lt;a href=&#34;https://danluu.com/term-latency/&#34;&gt;terminal&lt;/a&gt; and &lt;a href=&#34;https://danluu.com/input-lag/&#34;&gt;end-to-end&lt;/a&gt; latency measurements) was, &amp;quot;so you just want to get to the top of Hacker News?&amp;quot;
The implication for the former is that measuring is less valuable than building and for the latter that measuring isn&#39;t valuable at all (perhaps other than for fame), but I don&#39;t see measuring as lesser let alone worthless. If anything, because measurement is, &lt;a href=&#34;https://twitter.com/danluu/status/1082321431109795840&#34;&gt;like writing&lt;/a&gt;, not generally valued, it&#39;s much easier to find high ROI measurement projects than high ROI building projects.&lt;/p&gt;

&lt;p&gt;Let&#39;s start by looking at a few examples of high impact measurement projects. My go-to example for this is Kyle Kingsbury&#39;s work with &lt;a href=&#34;https://jepsen.io&#34;&gt;Jepsen&lt;/a&gt;. Before Jepsen, a handful of huge companies (the now $1T+ companies that people are calling &amp;quot;hyperscalers&amp;quot;) had decently tested distributed systems. They mostly didn&#39;t talk about testing methods in a way that really caused the knowledge to spread to the broader industry. Outside of those companies, most distributed systems were, &lt;a href=&#34;https://danluu.com/testing/&#34;&gt;by my standards&lt;/a&gt;, not particularly well tested.&lt;/p&gt;

&lt;p&gt;At the time, a common pattern in online discussions of distributed correctness was:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Person A&lt;/strong&gt;: Database X corrupted my data.&lt;br&gt;
&lt;strong&gt;Person B&lt;/strong&gt;: It works for me. It&#39;s never corrupted my data.&lt;br&gt;
&lt;strong&gt;A&lt;/strong&gt;: How do you know? Do you ever check for data corruption?&lt;br&gt;
&lt;strong&gt;B&lt;/strong&gt;: What do you mean? I&#39;d know if we had data corruption (alternate answer: &lt;a href=&#34;https://mobile.twitter.com/danluu/status/918845240240410624&#34;&gt;sure, we sometimes have data corruption, but it&#39;s probably a hardware problem and therefore not our fault&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Kyle&#39;s early work found critical flaws in nearly everything he tested, despite Jepsen being much less sophisticated then than it is now:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aphyr.com/posts/283-call-me-maybe-redis&#34;&gt;Redis Cluster / Redis Sentinel&lt;/a&gt;: &amp;quot;we demonstrate Redis losing 56% of writes during a partition&amp;quot;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aphyr.com/posts/284-call-me-maybe-mongodb&#34;&gt;MongoDB&lt;/a&gt;: &amp;quot;In this post, we’ll see MongoDB drop a phenomenal amount of data&amp;quot;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aphyr.com/posts/285-call-me-maybe-riak&#34;&gt;Riak&lt;/a&gt;: &amp;quot;we’ll see how last-write-wins in Riak can lead to unbounded data loss&amp;quot;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aphyr.com/posts/292-call-me-maybe-nuodb&#34;&gt;NuoDB&lt;/a&gt;: &amp;quot;If you are considering using NuoDB, be advised that the project’s marketing and documentation may exceed its present capabilities&amp;quot;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aphyr.com/posts/291-call-me-maybe-zookeeper&#34;&gt;Zookeeper&lt;/a&gt;: the one early Jepsen test of a distributed system that didn&#39;t find a catastrophic bug&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aphyr.com/posts/315-call-me-maybe-rabbitmq&#34;&gt;RabbitMQ clustering&lt;/a&gt;: &amp;quot;RabbitMQ lost ~35% of acknowledged writes ... This is not a theoretical problem. I know of at least two RabbitMQ deployments which have hit this in production.&amp;quot;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aphyr.com/posts/316-call-me-maybe-etcd-and-consul&#34;&gt;etcd &amp;amp; Consul&lt;/a&gt;: &amp;quot;etcd’s registers are not linearizable . . . &#39;consistent&#39; reads in Consul return the local state of any node that considers itself a leader, allowing stale reads.&amp;quot;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aphyr.com/posts/317-call-me-maybe-elasticsearch&#34;&gt;ElasticSearch&lt;/a&gt;: &amp;quot;the health endpoint will lie. It’s happy to report a green cluster during split-brain scenarios . . . 645 out of 1961 writes acknowledged then lost.&amp;quot;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Many of these problems had existed for quite a while&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;What’s really surprising about this problem is that it’s gone unaddressed for so long. The original issue was reported in July 2012; almost two full years ago. There’s no discussion on the website, nothing in the documentation, and users going through Elasticsearch training have told me these problems weren’t mentioned in their classes.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Kyle then quotes a number of users who ran into issues into production and then dryly notes&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Some people actually advocate using Elasticsearch as a primary data store; I think this is somewhat less than advisable at present&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Although we don&#39;t have an A/B test of universes where Kyle exists vs. not and can&#39;t say how long it would&#39;ve taken for distributed systems to get serious about correctness in a universe where Kyle didn&#39;t exist, from having spent many years looking at how developers treat correctness bugs, I would bet on distributed systems having rampant correctness problems until someone like Kyle came along. The typical response that I&#39;ve seen when a catastrophic bug is reported is that the project maintainers will assume that the bug report is incorrect (and you can see many examples of this if you look at responses from the first few years of Kyle&#39;s work). When the reporter doesn&#39;t have a repro for the bug, which is quite common when it comes to distributed systems, the bug will be written off as non-existent.&lt;/p&gt;

&lt;p&gt;When the reporter does have a repro, the next line of defense is to argue that the behavior is fine (you can also see many examples of these from looking at responses to Kyle&#39;s work). Once the bug is acknowledged as real, the next defense is to argue that the bug doesn&#39;t need to be fixed because it&#39;s so uncommon (e.g., &amp;quot;&lt;a href=&#34;https://news.ycombinator.com/item?id=5913610&#34;&gt;It can be tempting to stand on an ivory tower and proclaim theory, but what is the real world cost/benefit? Are you building a NASA Shuttle Crawler-transporter to get groceries?&lt;/a&gt;&amp;quot;). And then, after it&#39;s acknowledged that the bug should be fixed, the final line of defense is to argue that the project takes correctness very seriously and there&#39;s really nothing more that could have been done; development and test methodology doesn&#39;t need to change because it was just a fluke that the bug occurred, and analogous bugs won&#39;t occur in the future without changes in methodology.&lt;/p&gt;

&lt;p&gt;Kyle&#39;s work blew through these defenses and, without something like it, my opinion is that we&#39;d still see these as the main defense used against distributed systems bugs (as opposed to test methodologies that can actually produce pretty reliable systems).&lt;/p&gt;

&lt;p&gt;That&#39;s one particular example, but I find that it&#39;s generally true that, in areas where no one is publishing measurements/benchmarks of products, the products are generally sub-optimal, often in ways that are relatively straightforward to fix once measured. Here are a few examples:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Keyboards: after I published &lt;a href=&#34;https://danluu.com/keyboard-latency/&#34;&gt;this post on keyboard latency&lt;/a&gt;, at least one major manufacturer that advertises high-speed gaming devices actually started optimizing input device latency; most users probably don&#39;t care much about input device latency, but it would be nice if manufacturers lived up to their claims&lt;/li&gt;
&lt;li&gt;Computers: after I published some other posts on &lt;a href=&#34;https://danluu.com/input-lag/&#34;&gt;computer&lt;/a&gt; &lt;a href=&#34;https://danluu.com/term-latency/&#34;&gt;latency&lt;/a&gt;, an engineer at a major software company that wasn&#39;t previously doing serious UI latency work told me that some engineers had started measuring and optimizing UI latency; also, the author of alacritty &lt;a href=&#34;https://github.com/alacritty/alacritty/issues/673&#34;&gt;filed this ticket&lt;/a&gt; on how to reduce alacritty latency&lt;/li&gt;
&lt;li&gt;Vehicle headlights: Jennifer Stockburger has noted that, when Consumer Reports started testing headlights, engineers at auto manufacturers thanked CR for giving them the ammunition they needed to force their employers to let them to engineer better headlights; previously, they would often lose the argument to designers who wanted nicer looking but less effective headlights since making cars safer by desiging better headlights is a hard sell because there&#39;s no business case, but making cars score higher on Consumer Reports reviews is an easy sell because that impacts sales numbers&lt;/li&gt;
&lt;li&gt;Vehicle &lt;a href=&#34;https://en.wikipedia.org/wiki/Anti-lock_braking_system&#34;&gt;ABS&lt;/a&gt;: after Consumer Reports and Car and Driver found that the Tesla Model 3 had extremely long braking distances (152 ft. from 60mph and 196 ft. from 70mph), Tesla updated the algorithms used to modulate the brakes, which improved braking distances enough that Tesla went from worst in class to better than average&lt;/li&gt;
&lt;li&gt;Vehicle impact safety: Other than Volvo, car manufacturers generally design their cars to get the highest possible score on published crash tests; &lt;a href=&#34;https://danluu.com/car-safety/&#34;&gt;they&#39;ll add safety as necessary to score well on new tests when they&#39;re published, but not before&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This post has made some justifications for why measuring things is valuable but, to be honest, the impetus for my measurements is curiosity. I just want to know the answer to a question; most of the time, I don&#39;t write up my results. But even if you have no curiosity about what&#39;s actually happening when you interact with the world and you&#39;re &amp;quot;just&amp;quot; looking for something useful to do, the lack of measurements of almost everything means that it&#39;s easy to find high ROI measurement projects (at least in terms of impact on the world; if you want to make money, building something is probably easier to monetize).&lt;/p&gt;

&lt;h3 id=&#34;appendix-the-motivation-for-my-measurement-posts&#34;&gt;Appendix: the motivation for my measurement posts&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/The_Death_of_the_Author&#34;&gt;There&#39;s a sense in which it doesn&#39;t really matter why I decided to write these posts&lt;/a&gt;, but if I were reading someone else&#39;s post on this topic, I&#39;d still be curious what got them writing, so here&#39;s what prompted me to write my measurement posts (which, for the purposes of this list, include posts where I collate data and don&#39;t do any direct measurement).&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/car-safety/&#34;&gt;danluu.com/car-safety&lt;/a&gt;: I was thinking about buying a car and wanted to know if I should expect significant differences in safety between manufacturers given that cars mostly get top marks on tests done in the U.S.

&lt;ul&gt;
&lt;li&gt;This wasn&#39;t included in the post because I thought it was too trivial to include (because the order of magnitude is obvious even without carrying out the computation), but I also computed the probability of dying in a car accident as well as the expected change in life expectancy between an old used car and a new-ish used car&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/cli-complexity/&#34;&gt;danluu.com/cli-complexity&lt;/a&gt;: I had this idea when I saw something by Gary Berhardt where he showed off how to count the number of single-letter command line options that &lt;code&gt;ls&lt;/code&gt;, which made me wonder if that was a recent change or not&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/overwatch-gender/&#34;&gt;danluu.com/overwatch-gender&lt;/a&gt;: I had just seen two gigantic reddit threads debating whether or not there&#39;s a gender bias in how women are treated in online games and figured that I could get data on the matter in less time than was spent by people writing comments in those threads&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/input-lag/&#34;&gt;danluu.com/input-lag&lt;/a&gt;: I wanted to know if I could trust my feeling that modern computers that I use are much higher latency than older devices that I&#39;d used&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/keyboard-latency/&#34;&gt;danluu.com/keyboard-latency&lt;/a&gt;: I wanted to know how much latency came from keyboards (display latency is already well tested by &lt;a href=&#34;https://blurbusters.com&#34;&gt;https://blurbusters.com&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/bad-decisions/&#34;&gt;danluu.com/bad-decisions&lt;/a&gt;: I saw a comment by someone in the rationality community defending bad baseball coaching decisions, saying that they&#39;re not a big deal because they only cost you maybe four games a year, which isn&#39;t a big deal and wanted to know how big a deal bad coaching decisions were&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/android-updates/&#34;&gt;danluu.com/android-updates&lt;/a&gt;: I was curious how many insecure Android devices are out there due to most Android phones not being updatable&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/filesystem-errors/&#34;&gt;danluu.com/filesystem-errors&lt;/a&gt;: I was curious how much filesystems had improved with respect to data corruption errors found by a 2005 paper&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/term-latency/&#34;&gt;danluu.com/term-latency&lt;/a&gt;: I felt like terminal benchmarks were all benchmarking something that&#39;s basically irrelevant to user experience (throughput) and wanted to know what it would look like if someone benchmarked something that might matter more; I also wanted to know if my feeling that iTerm2 was slow was real or my imagination&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/keyboard-v-mouse/&#34;&gt;danluu.com/keyboard-v-mouse&lt;/a&gt;: the most widely cited sources for keyboard vs. mousing productivity were pretty obviously bogus as well as being stated with extremely high confidence; I wanted to see if non-bogus tests would turn up the same results or different results&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/web-bloat/&#34;&gt;danluu.com/web-bloat&lt;/a&gt;: I took a road trip across the U.S., where the web was basically unusable, and wanted to quantify the unusability of the web without access to very fast internet&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/bimodal-compensation/&#34;&gt;danluu.com/bimodal-compensation&lt;/a&gt;: I was curious if we were seeing a hollowing out of mid-tier jobs in programming like we saw with law jobs&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/yegge-predictions/&#34;&gt;danluu.com/yegge-predictions&lt;/a&gt;: I had the impression that Steve Yegge made unusually good predictions about the future of tech and wanted to see of my impression was correct&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/postmortem-lessons/&#34;&gt;danluu.com/postmortem-lessons&lt;/a&gt;: I wanted to see what data was out there on postmortem causes to see if I could change how I operate and become more effective&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/boring-languages/&#34;&gt;danluu.com/boring-languages&lt;/a&gt;: I was curious how much of the software I use was written in boring, old, languages&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/blog-ads/&#34;&gt;danluu.com/blog-ads&lt;/a&gt;: I was curious how much money I could make if I wanted to monetize the blog&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/everything-is-broken/&#34;&gt;danluu.com/everything-is-broken&lt;/a&gt;: I wanted to see if my impression of how many bugs I run into was correct&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/integer-overflow/&#34;&gt;danluu.com/integer-overflow&lt;/a&gt;: I had a discussion with a language designer who was convinced that integer overflow checking was too expensive to do for an obviously bogus reason (because it&#39;s expensive if you do a benchmark that&#39;s 100% integer operations) and I wanted to see if my quick mental-math estimate of overhead was the right order of magnitude&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/octopress-speedup/&#34;&gt;danluu.com/octopress-speedup&lt;/a&gt;: after watching a talk by Dan Espeset, I wanted to know if there were easy optimizations I could do to my then-Octopress site&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/broken-builds/&#34;&gt;danluu.com/broken-builds&lt;/a&gt;: I had a series of discussions with someone who claimed that their project had very good build uptime despite it being broken regularly; I wanted to know if their claim was correct with respect to other, similar, projects&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/empirical-pl/&#34;&gt;danluu.com/empirical-pl&lt;/a&gt;: I wanted to know what studies backed up claims from people who said that there was solid empirical proof of the superiority of &amp;quot;fancy&amp;quot; type systems&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/2choices-eviction/&#34;&gt;danluu.com/2choices-eviction&lt;/a&gt;: I was curious what would happen if &amp;quot;two random choices&amp;quot; was applied to cache eviction&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/gender-gap/&#34;&gt;danluu.com/gender-gap&lt;/a&gt;: I wanted to verify the claims in an article that claimed that there is no gender gap in tech salaries&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danluu.com/3c-conflict/&#34;&gt;danluu.com/3c-conflict&lt;/a&gt;: I wanted to create a simple example illustrating the impact of alignment on memory latency&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;BTW, writing up this list made me realize that a narrative I had in my head about how and when I started really looking at data seriously must be wrong. I thought that this was something that came out of my current job, but that clearly cannot be the case since a decent fraction of my posts from before my current job are about looking at data and/or measuring things (and I didn&#39;t even list some of the data-driven posts where I just read some papers and look at what data they present). Blogger, measure thyself.&lt;/p&gt;

&lt;h3 id=&#34;appendix-why-you-can-t-trust-some-reviews&#34;&gt;Appendix: why you can&#39;t trust some reviews&lt;/h3&gt;

&lt;p&gt;One thing that both increases and decreases the impact of doing good measurements is that most measurements that are published aren&#39;t very good. This increases the personal value of understanding how to do good measurements and of doing good measurements, but it blunts the impact on other people, since people generally don&#39;t understand what makes measurements invalid and don&#39;t have a good algorithm for deciding which measurements to trust.&lt;/p&gt;

&lt;p&gt;There are a variety of reasons that published measurements/reviews are often problematic. A major issue with reviews is that, in some industries, reviewers are highly dependent on manufacturers for review copies.&lt;/p&gt;

&lt;p&gt;Car reviews are one of the most extreme examples of this. Consumer Reports is the only major reviewer that independently sources their cars, which often causes them to disagree with other reviewers since they&#39;ll try to buy the trim level of the car that most people buy, which is often quite different from the trim level reviewers are given by manufacturers and Consumer Reports generally manages to avoid reviewing cars that are unrepresentatively picked or tuned. There have been a couple where Consumer Reports reviewers (who also buy the cars) have said that they thought someone realized they worked for Consumer Reports and then said that they needed to keep the car overnight before giving them the car they&#39;d just bought; when that&#39;s happened, the reviewer has walked away from the purchase.&lt;/p&gt;

&lt;p&gt;There&#39;s pretty significant copy-to-copy variation between cars and the cars reviewers get tend to be ones that were picked to avoid cosmetic issues (paint problems, panel gaps, etc.) as well as checked for more serious issues. Additionally, cars can have their software and firmware tweaked (e.g., it&#39;s common knowledge that review copies of BMWs have an engine &amp;quot;tune&amp;quot; that would void your warranty if you modified your car similarly).&lt;/p&gt;

&lt;p&gt;Also, because Consumer Reports isn&#39;t getting review copies from manufacturers, they don&#39;t have to pull their punches and can write reviews that are highly negative, something you rarely see from car magazines and don&#39;t often see from car youtubers, where you generally have to read between the lines to get an honest review since a review that explicitly mentions negative things about a car can mean losing access (the youtuber who goes by &amp;quot;savagegeese&amp;quot; has mentioned having trouble getting access to cars from some companies after giving honest reviews).&lt;/p&gt;

&lt;p&gt;Camera lenses are another area where it&#39;s been documented that reviewers get unusually good copies of the item. There&#39;s tremendous copy-to-copy variation between lenses so vendors pick out good copies and let reviewers borrow those. In many cases (e.g., any of the FE mount ZA Zeiss lenses or the Zeiss lens on the RX-1), based on how many copies of a lens people need to try and return to get a good copy, it appears that the median copy of the lens has noticeable manufacturing defects and that, in expectation, perhaps one in ten lenses has no obvious defect (this could also occur if only a few copies were bad and those were serially returned, but very few photographers really check to see if their lens has issues due to manufacturing variation). Because it&#39;s so expensive to obtain a large number of lenses, the amount of copy-to-copy variation was unquantified until &lt;a href=&#34;https://www.lensrentals.com/&#34;&gt;lensrentals&lt;/a&gt; started measuring it; they&#39;ve found that different manufacturers can have very different levels of copy-to-copy variation, which I hope will apply pressure to lens makers that are currently selling a lot of bad lenses while selecting good ones to hand to reviewers.&lt;/p&gt;

&lt;p&gt;Hard drives are yet another area where it&#39;s been documented that reviewers get copies of the item that aren&#39;t represnetative. Extreme Tech has reported, multiple times, that Adata, Crucial, and Western Digital have handed out review copies of SSDs that are not what you get as a consumer. One thing I find interesting about that case is that Extreme Tech says&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Agreeing to review a manufacturer’s product is an extension of trust on all sides. The manufacturer providing the sample is trusting that the review will be of good quality, thorough, and objective. The reviewer is trusting the manufacturer to provide a sample that accurately reflects the performance, power consumption, and overall design of the final product. When readers arrive to read a review, they are trusting that the reviewer in question has actually tested the hardware and that any benchmarks published were fairly run.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This makes it sound like the reviewer&#39;s job is to take a trusted handed to them by the vendor and then run good benchmarks, absolving the reviewer of the responsibility of obtaining representative devices and ensuring that they&#39;re representative. I&#39;m reminded of the SRE motto, &amp;quot;hope is not a strategy&amp;quot;. Trusting vendors is not a strategy. We know that vendors will lie and cheat to look better at benchmarks. Saying that it&#39;s a vendor&#39;s fault for lying or cheating can shift the blame, but it won&#39;t result in reviews being accurate or useful to consumers.&lt;/p&gt;

&lt;p&gt;While we&#39;ve only discussed a few specific areas where there&#39;s published evidence that reviews cannot be trusted because they&#39;re compromised by companies, but this isn&#39;t anything specific to those industries. As consumers, we should expect that any review that isn&#39;t performed by a trusted, independent, agency, that purchases its own review copies has been compromised and is not representative of the median consumer experience.&lt;/p&gt;

&lt;p&gt;Another issue with reviews is that most online reviews that are highly ranked in search are really just SEO affiliate farms.&lt;/p&gt;

&lt;p&gt;A more general issue is that reviews are also affected by the exact same problem as items that are not reviewed: people generally can&#39;t tell which reviews are actually good and which are not, so review sites are selected on things other than the quality of the review. A prime example of this is Wirecutter, which is so popular among tech folks that noting that so many tech apartments in SF have identical Wirecutter recommended items is a tired joke. For people who haven&#39;t lived in SF, you can get a peek into the mindset by reading the comments &lt;a href=&#34;https://www.reddit.com/r/fatFIRE/comments/iioq01/impossible_to_avoid_lifestyle_inflation_with/&#34;&gt;on this post about how it&#39;s &amp;quot;impossible&amp;quot; to not buy the wirecutter recommendation for anything&lt;/a&gt; which is full of comments from people who re-assure that poster that, due to the high value of the poster&#39;s time, it would be irresponsible to do anything else.&lt;/p&gt;

&lt;p&gt;The thing I find funny about this is that if you take benchmarking seriously (in any field) and just read the methodology for the median Wirecutter review, without even trying out the items reviewed you can see that the methodology is poor and that they&#39;ll generally select items that are mediocre and sometimes even worst in class. A thorough exploration of this really deserves its own post, but I&#39;ll cite one example of poorly reviewed items here: in &lt;a href=&#34;https://benkuhn.net/vc&#34;&gt;https://benkuhn.net/vc&lt;/a&gt;, Ben Kuhn looked into how to create a nice video call experience, which included trying out a variety of microphones and webcams. Naturally, Ben tried Wirecutter&#39;s recommended microphone and webcam. The webcam was quite poor, no better than using the camera from an ancient 2014 iMac or his 2020 Macbook (and, to my eye, actually much worse; more on this later). And the microphone was roughly comparable to using the built-in microphone on his laptop.&lt;/p&gt;

&lt;p&gt;I have a lot of experience with Wirecutter&#39;s recommended webcam because so many people have it and it is shockingly bad in a distinctive way. Ben noted that, if you look at a still image, the white balance is terrible when used in the house he was in, and if you talk to other people who&#39;ve used the camera, that is a common problem. But the issue I find to be worse is that, if you look at the video, under many conditions (and I think most, given how often I see this), the webcam will refocus regularly, making the entire video flash out of and then back into focus (another issue is that it often focuses on the wrong thing, but that&#39;s less common and I don&#39;t see that one with everybody who I talk to who uses Wirecutter&#39;s recommended webcam). I actually just had a call yesterday with a friend of mine who was using a different setup than I&#39;d normally seen him with, the mediocre but perfectly acceptable macbook webcam. His video was going in and out of focus every 10-30 seconds, so I asked him if he was using Wirecutter&#39;s recommended webcam and of course he was, because what other webcam would someone in tech buy that has the same problem?&lt;/p&gt;

&lt;p&gt;This level of review quality is pretty typical for Wirecutter reviews and they appear to generally be the most respected and widely used review site among people in tech.&lt;/p&gt;

&lt;h3 id=&#34;appendix-capitalism&#34;&gt;Appendix: capitalism&lt;/h3&gt;

&lt;p&gt;When I was in high school, there was a clique of proto-edgelords who did things like read The Bell Curve and argue its talking points to anyone who would listen.&lt;/p&gt;

&lt;p&gt;One of their favorite topics was how the free market would naturally cause companies that make good products rise to the top and companies that make poor products to disappear, resulting in things generally being safe, a good value, and so on and so forth. I still commonly see this opinion espoused by people working in tech, including people who fill their condos with Wirecutter recommended items. I find the juxtaposition of people arguing that the market will generally result in products being good while they themselves buy overpriced garbage to be deliciously ironic. To be fair, it&#39;s not all overpriced garbage. Some of it is overpriced mediocrity and some of it is actually good; it&#39;s just that it&#39;s not too different from what you&#39;d get if you just naively bought random stuff off of Amazon without reading third-party reviews.&lt;/p&gt;

&lt;p&gt;For a related discussion, &lt;a href=&#34;https://danluu.com/tech-discrimination/&#34;&gt;see this post on people who argue that markets eliminate discrimination even as they discriminate&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;appendix-other-examples-of-the-impact-of-measurement-or-lack-thereof&#34;&gt;Appendix: other examples of the impact of measurement (or lack thereof)&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Electronic stability control

&lt;ul&gt;
&lt;li&gt;Toyota RAV4: &lt;a href=&#34;https://www.youtube.com/watch?v=j3qrCNR4U9A&#34;&gt;before&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=VtQ24W_lamY&#34;&gt;reviews&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=xSRCJFCmvTk&#34;&gt;and after reviews&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Toyota Hilux &lt;a href=&#34;https://www.youtube.com/watch?v=xoHbn8-ROiQ&#34;&gt;before reviews&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=y2QSogJj3ec&#34;&gt; and after reviews&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Nissan Rogue: major improvements after Consumer Reports found issues with stability control.&lt;/li&gt;
&lt;li&gt;Jeep Grand Cherokee: &lt;a href=&#34;https://www.youtube.com/watch?v=zaYFLb8WMGM&#34;&gt;before reviews&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=_xFPdfcNmVc&#34;&gt;and after reviews&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Some boring stuff at work: a year ago, I wrote &lt;a href=&#34;https://danluu.com/metrics-analytics/&#34;&gt;this&lt;/a&gt; &lt;a href=&#34;https://danluu.com/tracing-analytics/&#34;&gt;pair&lt;/a&gt; of posts on observability infrastructure at work. At the time, that work had driven 8 figures of cost savings and that&#39;s now well into the 9 figure range. This probably deserves its own post at some point, but the majority of the work was straightforward once someone could actually observe what&#39;s going on.

&lt;ul&gt;
&lt;li&gt;Relatedly: after seeing a few issues impact production services, I wrote a little (5k LOC) parser to parse every line seen in various host-level logs as a check to see what issues were logged that we weren&#39;t catching in our metrics. This found major issues in clusters that weren&#39;t using an automated solution to catch and remediate host-level issues; for some clusters, over 90% of hosts were actively corrupting data or had a severe performance problem. This led to the creation of a new team to deal with issues like this&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Tires

&lt;ul&gt;
&lt;li&gt;Almost all manufacturers other than Michelin see severely reduced wet, snow, and ice, performance as the tire wears

&lt;ul&gt;
&lt;li&gt;Jason Fenske says that a technical reason for this (among others) is that the &lt;a href=&#34;https://en.wikipedia.org/wiki/Siping_(rubber)&#34;&gt;sipes&lt;/a&gt; that improve grip are generally not cut to the full depth because doing so significantly increases manufacturing cost because the device that cuts the sipes will need to be stronger as well as wear out faster&lt;/li&gt;
&lt;li&gt;A non-technical reason for this is that a lot of published tire tests are done on new tires, so tire manufacturers can get nearly the same marketing benchmark value by creating only partial-depth sipes&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;As Tire Rack has increased in prominence, some tire manufacturers have made their siping more multi-directional to improve handling while cornering instead of having siping mostly or only perpendicular to the direction of travel, which mostly only helps with acceleration and braking (Consumer Reports snow and ice scores are based on accelerating in a straight line on snow and braking in a straight line on ice, respectively, whereas Tire Rack&#39;s winter test scores emphasize all-around snow handling)&lt;/li&gt;
&lt;li&gt;An example of how measurement impact is bounded: Farrell Scott, the Project Category Manager for Michelin winter tires said that, when designing the successor to the Michelin X-ICE Xi3, one of the primary design criteria was to change how the tire looked because Michelin found that customers thought that the X-ICE Xi3, despite being up there with the Bridge Blizzak WS80 for being the best all-around winter tire (slightly better at some things, slightly worse at others), potential customers often chose other tires because they looked more like the popular conception of a winter tire, with &amp;quot;aggressive&amp;quot; looking tread blocks (this is one thing the famous Nokian Hakkapeliitta tire line was much better at). They also changed the name; instead of incrementing the number, the new tire was called Michelin X-ICE SNOW, to emphasize that the tire is suitable for snow as well as ice.&lt;/li&gt;
&lt;li&gt;Although some consumers do read reviews, many (and probably most) don&#39;t!&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;HDMI to USB converters for live video

&lt;ul&gt;
&lt;li&gt;If you read the docs for the &lt;a href=&#34;https://amzn.to/3gBdiRE&#34;&gt;Camlink 4k&lt;/a&gt;, they note that the device should use bulk transfers on Windows and Isochronous transfers on Mac (if you use their software, it will automatically make this adjustment)

&lt;ul&gt;
&lt;li&gt;Fabian Giesen informed me that this may be for the same reason that, when some colleagues of his tested a particular USB3 device on Windows, only 1 out of 5 chipsets tested supported isochronous properly (the rest would do things like bluescreen or hang the machine)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;I&#39;ve tried miscellaneous cheap HDMI to USB converters as alternatives to the Camlink 4k, and I have yet to find a cheap one that generally works across a wide variety of computers. They will generally work with at least one computer I have access to with at least one piece of software I want to use, but will simply not work or provide very distorted video in some cases. Perhaps someone should publish benchmarks on HDMI to USB converter quality!&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;HDMI to VGA converters

&lt;ul&gt;
&lt;li&gt;Many of these get very hot and then overheat and stop working in 15 minutes to 2 hours. Some aren&#39;t even warm to the touch. Good luck figuring out which ones work!

&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;small&gt;Thanks to Fabian Giesen, Ben Kuhn, Yuri Vishnevsky, @chordowl, Seth Newman, Justin Blank, Per Vognsen, John Hergenroeder, Pam Wolf, Ivan Echevarria, and Jamie Brandon for comments/corrections/discussion.&lt;/small&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Against essential and accidental complexity</title>
      <link>https://danluu.com/essential-complexity/</link>
      <pubDate>Tue, 29 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://danluu.com/essential-complexity/</guid>
      <description>

&lt;p&gt;In the classic 1986 essay, &lt;a href=&#34;http://worrydream.com/refs/Brooks-NoSilverBullet.pdf&#34;&gt;No Silver Bullet&lt;/a&gt;, Fred Brooks argued that there is, in some sense, not that much that can be done to improve programmer productivity. His line of reasoning is that programming tasks contain a core of essential/conceptual&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:C&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:C&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; complexity that&#39;s fundamentally not amenable to attack by any potential advances in technology (such as languages or tooling). He then uses an &lt;a href=&#34;https://en.wikipedia.org/wiki/Amdahl%27s_law&#34;&gt;Ahmdahl&#39;s law&lt;/a&gt; argument, saying that because 1/X of complexity is essential, it&#39;s impossible to ever get more than a factor of X improvement via technological improvements.&lt;/p&gt;

&lt;p&gt;Towards the end of the essay, Brooks claims that at least 1/2 (most) of complexity in programming is essential, bounding the potential improvement remaining for all technological programming innovations combined to, at most, a factor of 2&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:T&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:T&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;All of the technological attacks on the accidents of the software process are fundamentally limited by the productivity equation:&lt;/p&gt;

&lt;p&gt;Time of task = Sum over i { Frequency_i  Time_i }&lt;/p&gt;

&lt;p&gt;If, as I believe, the conceptual components of the task are now taking most of the time, then no amount of activity on the task components that are merely the expression of the concepts can give large productivity gains.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Let&#39;s see how this essential complexity claim holds for a couple of things I did recently at work:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;scp from a bunch of hosts to read and download logs, and then parse the logs to understand the scope of a problem&lt;/li&gt;
&lt;li&gt;Query two years of metrics data from every instance of every piece of software my employer has, for some classes of software and then generate a variety of plots that let me understand some questions I have about what our software is doing and how it&#39;s using computer resources&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;logs&#34;&gt;Logs&lt;/h4&gt;

&lt;p&gt;If we break this task down, we have&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;scp logs from a few hundred thousand machines to a local box

&lt;ul&gt;
&lt;li&gt;used a Python script for this to get parallelism with more robust error handling than you&#39;d get out of pssh/parallel-scp&lt;/li&gt;
&lt;li&gt;~1 minute to write the script&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;do other work while logs download&lt;/li&gt;
&lt;li&gt;parse downloaded logs (a few TB)

&lt;ul&gt;
&lt;li&gt;used a Rust script for this, a few minutes to write (used Rust instead of Python for performance reasons here — just opening the logs and scanning each line with idiomatic Python was already slower than I&#39;d want if I didn&#39;t want to farm the task out to multiple machines)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In 1986, perhaps I would have used telnet or ftp instead of scp. Modern scripting languages didn&#39;t exist yet (perl was created in 1987 and perl5, the first version that some argue is modern, was released in 1994), so writing code that would do this with parallelism and &amp;quot;good enough&amp;quot; error handling would have taken more than an order of magnitude more time than it takes today. In fact, I think just getting semi-decent error handling while managing a connection pool could have easily taken an order of magnitude longer than this entire task took me (not including time spent downloading logs in the background).&lt;/p&gt;

&lt;p&gt;Next up would be parsing the logs. It&#39;s not fair to compare an absolute number like &amp;quot;1 TB&amp;quot;, so let&#39;s just call this &amp;quot;enough that we care about performance&amp;quot; (we&#39;ll talk about scale in more detail in the metrics example). Today, we have our choice of high-performance languages where it&#39;s easy to write, fast, safe code and harness the power of libraries (e.g., a regexp library&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:L&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:L&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;) that make it easy to write a quick and dirty script to parse and classify logs, farming out the work to all of the cores on my computer (I think Zig would&#39;ve also made this easy, but I used Rust because my team has a critical mass of Rust programmers).&lt;/p&gt;

&lt;p&gt;In 1986, there would have been no comparable language, but more importantly, I wouldn&#39;t have been able to trivially find, download, and compile the appropriate libraries and would&#39;ve had to write all of the parsing code by hand, turning a task that took a few minutes into a task that I&#39;d be lucky to get done in an hour. Also, if I didn&#39;t know how to use the library or that I could use a library, I could easily find out how I should solve the problem on StackOverflow, which would massively reduce accidental complexity. Needless to say, there was no real equivalent to Googling for StackOverflow solutions in 1986.&lt;/p&gt;

&lt;p&gt;Moreover, even today, this task, a pretty standard programmer devops/SRE task, after at least an order of magnitude speedup over the analogous task in 1986, is still nearly entirely accidental complexity.&lt;/p&gt;

&lt;p&gt;If the data were exported into our metrics stack or if our centralized logging worked a bit differently, the entire task would be trivial. And if neither of those were true, but the log format were more uniform, I wouldn&#39;t have had to write any code after getting the logs; &lt;a href=&#34;https://github.com/BurntSushi/ripgrep&#34;&gt;rg&lt;/a&gt; or &lt;a href=&#34;https://github.com/ggreer/the_silver_searcher&#34;&gt;ag&lt;/a&gt; would have been sufficient. If I look for how much time I spent on the essential conceptual core of the task, it&#39;s so small that it&#39;s hard to estimate.&lt;/p&gt;

&lt;h4 id=&#34;query-metrics&#34;&gt;Query metrics&lt;/h4&gt;

&lt;p&gt;We really only need one counter-example, but I think it&#39;s illustrative to look at a more complex task to see how Brooks&#39; argument scales for a more involved task. If you&#39;d like to skip this lengthy example, &lt;a href=&#34;#summary&#34;&gt;click here to skip to the next section&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We can view my metrics querying task as being made up of the following sub-tasks:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Write a set of &lt;a href=&#34;https://en.wikipedia.org/wiki/Presto_(SQL_query_engine)&#34;&gt;Presto SQL&lt;/a&gt; queries that effectively scan on the order of 100 TB of data each, from a data set that would be on the order of 100 PB of data if I didn&#39;t &lt;a href=&#34;https://danluu.com/metrics-analytics/&#34;&gt;maintain tables that only contain a subset of data that&#39;s relevant&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Maybe 30 seconds to write the first query and a few minutes for queries to finish, using on the order of 1 CPU-year of CPU time&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Write some ggplot code to plot the various properties that I&#39;m curious about

&lt;ul&gt;
&lt;li&gt;Not sure how long this took; less time than the queries took to complete, so this didn&#39;t add to the total time of this task&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The first of these tasks is so many orders of magnitude quicker to accomplish today that I&#39;m not even able to hazard a guess to as to how much quicker it is today within one or two orders of magnitude, but let&#39;s break down the first task into component parts to get some idea about the ways in which the task has gotten easier.&lt;/p&gt;

&lt;p&gt;It&#39;s not fair to port absolute numbers like 100 PB into 1986, but just the idea of having a pipeline that collects and persists comprehensive data analogous to the data I was looking at for a consumer software company (various data on the resource usage and efficiency of our software) would have been considered absurd in 1986. Here we see one fatal flaw in the concept of accidental essential complexity providing an upper bound on productivity improvements: tasks with too much accidental complexity wouldn&#39;t have even been considered possible. The limit on how much accidental complexity Brooks sees is really a limit of his imagination, not something fundamental.&lt;/p&gt;

&lt;p&gt;Brooks explicitly dismisses increased computational power as something that will not improve productivity (&amp;quot;Well, how many MIPS can one use fruitfully?&amp;quot;, more on this later), but both storage and CPU power (not to mention network speed and RAM) were sources of accidental complexity so large that they bounded the space of problems Brooks was able to conceive of.&lt;/p&gt;

&lt;p&gt;In this example, let&#39;s say that we somehow had enough storage to keep the data we want to query in 1986. The next part would be to marshall on the order of 1 CPU-year worth of resources and have the query complete in minutes. As with the storage problem, this would have also been absurd in 1986&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:F&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:F&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;, so we&#39;ve run into a second piece of non-essential complexity so large that it would stop a person from 1986 from thinking of this problem at all.&lt;/p&gt;

&lt;p&gt;Next up would be writing the query. If I were writing for the Cray-2 and wanted to be productive, I probably would have written the queries in Cray&#39;s dialect of Fortran 77. Could I do that in less than 300 seconds per query? Not a chance; I couldn&#39;t even come close with Scala/Scalding and I think it would be a near thing even with Python/PySpark. This is the aspect where I think we see the smallest gain and we&#39;re still well above one order of magnitude here.&lt;/p&gt;

&lt;p&gt;After we have the data processed, we have to generate the plots. Even with today&#39;s technology, I think not using ggplot would cost me at least 2x in terms of productivity. I&#39;ve tried every major plotting library that&#39;s supposedly equivalent (in any language) and every library I&#39;ve tried either has multiple show-stopping bugs rendering plots that I consider to be basic in ggplot or is so low-level that I lose more than 2x productivity by being forced to do stuff manually that would be trivial in ggplot. In 2020, the existence of a single library already saves me 2x on this one step. If we go back to 1986, before the concept of &lt;a href=&#34;https://amzn.to/3r9Mvzw&#34;&gt;the grammar of graphics&lt;/a&gt; and any reasonable implementation, there&#39;s no way that I wouldn&#39;t lose at least two orders of magnitude of time on plotting even assuming some magical workstation hardware that was capable of doing the plotting operations I do in a reasonable amount of time (my machine is painfully slow at rendering the plots; a Cray-2 would not be able to do the rendering in anything resembling a reasonable timeframe).&lt;/p&gt;

&lt;p&gt;The number of orders of magnitude of accidental complexity reduction for this problem from 1986 to today is so large I can&#39;t even estimate it and yet this problem still contains such a large fraction of accidental complexity that it&#39;s once again difficult to even guess at what fraction of complexity is essential. To write it all down all of the accidental complexity I can think of would require at least 20k words, but just to provide a bit of the flavor of the complexity, let me write down a few things.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;SQL; this is one of those things that&#39;s superficially simple &lt;a href=&#34;https://scattered-thoughts.net/writing/select-wat-from-sql/&#34;&gt;but actually extremely complex&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Also, Presto SQL&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Arbitrary Presto limits, some of which are from Presto and some of which are from the specific ways we operate Presto and the version we&#39;re using

&lt;ul&gt;
&lt;li&gt;There&#39;s an internal Presto data structure assert fail that gets triggered when I use both &lt;code&gt;numeric_histogram&lt;/code&gt; and &lt;code&gt;cross join unnest&lt;/code&gt; in a particular way. Because it&#39;s a waste of time to write the bug-exposing query, wait for it to fail, and then re-write it, I have a mental heuristic I use to guess, for any query that uses both constructs, whether or not I&#39;ll hit the bug and I apply it to avoid having to write two queries. If the heuristic applies, I&#39;ll instead write a more verbose query that&#39;s slower to execute instead of the more straightforward query&lt;/li&gt;
&lt;li&gt;We partition data by date, but Presto throws this away when I join tables, resulting in very large and therefore expensive joins when I join data across a long period of time even though, in principle, this could be a series of cheap joins; if the join is large enough to cause my query to blow up, I&#39;ll write what&#39;s essentially a little query compiler to execute day-by-day queries and then post-process the data as necessary instead of writing the naive query

&lt;ul&gt;
&lt;li&gt;There are a bunch of cases where some kind of optimization in the query will make the query feasible without having to break the query across days (e.g., if I want to join host-level metrics data with the table that contains what cluster a host is in, that&#39;s a very slow join across years of data, but I also know what kinds of hosts are in which clusters, which, in some cases, lets me filter hosts out of the host-level metrics data that&#39;s in there, like core count and total memory, which can make the larger input to this join small enough that the query can succeed without manually partitioning the query)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;We have a Presto cluster that&#39;s &amp;quot;fast&amp;quot; but has &amp;quot;low&amp;quot; memory limits a cluster that&#39;s &amp;quot;slow&amp;quot; but has &amp;quot;high&amp;quot; memory limits, so I mentally estimate how much per-node memory a query will need so that I can schedule it to the right cluster&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;When, for performance reasons, I should compute the CDF or histogram in Presto vs. leaving it to the end for ggplot to compute&lt;/li&gt;
&lt;li&gt;How much I need to downsample the data, if at all, for ggplot to be able to handle it, and how that may impact analyses&lt;/li&gt;
&lt;li&gt;Arbitrary ggplot stuff

&lt;ul&gt;
&lt;li&gt;roughly how many points I need to put in a scatterplot before I should stop using &lt;code&gt;size = [number]&lt;/code&gt; and should switch to single-pixel plotting because plotting points as circles is too slow&lt;/li&gt;
&lt;li&gt;what the minimum allowable opacity for points is&lt;/li&gt;
&lt;li&gt;If I exceed the maximum density where you can see a gradient in a scatterplot due to this limit, how large I need to make the image to reduce the density appropriately (when I would do this instead of using a heatmap deserves its own post)&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;All of the above is about tools that I use to write and examine queries, but there&#39;s also the mental model of all of the data issues that must be taken into account when writing the query in order to generate a valid result, which includes things like clock skew, Linux accounting bugs, issues with our metrics pipeline, issues with data due to problems in the underlying data sources, etc.&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For each of Presto and ggplot I implicitly hold over a hundred things in my head to be able to get my queries and plots to work and I choose to use these because these are the lowest overhead tools that I know of that are available to me. If someone asked me to name the percentage of complexity I had to deal with that was essential, I&#39;d say that it was so low that there&#39;s no way to even estimate it. For some queries, it&#39;s arguably zero — my work was necessary only because of some arbitrary quirk and there would be no work to do without the quirk. But even in cases where some kind of query seems necessary, I think it&#39;s unbelievable that essential complexity could have been more than 1% of the complexity I had to deal with.&lt;/p&gt;

&lt;p&gt;Revisiting Brooks on computer performance, even though I deal with complexity due to the limitations of hardware performance in 2020 and would love to have faster computers today, Brooks wrote off faster hardware as pretty much not improving developer productivity in 1986:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;What gains are to be expected for the software art from the certain and rapid increase in the power and memory capacity of the individual workstation? Well, how many MIPS can one use fruitfully? The composition and editing of programs and documents is fully supported by today’s speeds. Compiling could stand a boost, but a factor of 10 in machine speed would surely . . .&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But this is wrong on at least two levels. First, if I had access to faster computers, a huge amount of my accidental complexity would go away (if computers were powerful enough, I wouldn&#39;t need complex tools like Presto; I could just run a query on my local computer). We have much faster computers now, but it&#39;s still true that having faster computers would make many involved engineering tasks trivial. As James Hague notes, in the mid-80s, &lt;a href=&#34;https://prog21.dadgum.com/29.html&#34;&gt;writing a spellchecker was a serious engineering problem due to performance constraints&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Second, (just for example) ggplot only exists because computers are so fast. A common complaint from people who work on performance is that tool X has somewhere between two and ten orders of magnitude of inefficiency when you look at the fundamental operations it does vs. the speed of hardware today&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:O&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:O&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;. But what fraction of programmers can realize even one half of the potential performance of a modern multi-socket machine? I would guess fewer than one in a thousand and I would say certainly fewer than one in a hundred. And performance knowledge isn&#39;t independent of other knowledge — controlling for age and experience, it&#39;s negatively correlated with knowledge of non-&amp;quot;systems&amp;quot; domains since time spent learning about the esoteric accidental complexity necessary to realize half of the potential of a computer is time spent not learning about &amp;quot;directly&amp;quot; applicable domain knowledge. When we look software that requires a significant amount of domain knowledge (e.g., ggplot) or that&#39;slarge enough that it requires a large team to implement (e.g., IntelliJ&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:V&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:V&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;), the vast majority of it wouldn&#39;t exist if machines were orders of magnitude slower and writing usable software required wringing most of the performance out of the machine. Luckily for us, hardware has gotten much faster, allowing the vast majority of developers to ignore performance-related accidental complexity and instead focus on all of the other accidental complexity necessary to be productive today.&lt;/p&gt;

&lt;p&gt;Faster computers both reduce the amount of accidental complexity tool users run into as well as the amount of accidental complexity that tool creators need to deal with, allowing more productive tools to come into existence.&lt;/p&gt;

&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;

&lt;p&gt;To summarize, Brooks states a bound on how much programmer productivity can improve. But, in practice, to state this bound correctly, one would have to be able to conceive of problems that no one would reasonably attempt to solve due to the amount of friction involved in solving the problem with current technologies.&lt;/p&gt;

&lt;p&gt;Without being able to predict the future, this is impossible to estimate. If we knew the future, it might turn out that there&#39;s some practical limit on how much computational power or storage programmers can productively use, bounding the resources available to a programmer, but getting a bound on the amount of accidental complexity would still require one to correctly reason about how programmers are going to be able to use zillions times more resources than are available today, which is so difficult we might as well call it impossible.&lt;/p&gt;

&lt;p&gt;Moreover, for each class of tool that could exist, one would have to effectively anticipate all possible innovations. Brooks&#39; strategy for this was to look at existing categories of tools and state, for each, that they would be ineffective or that they were effective but played out. This was wrong not only because it underestimated gains from classes of tools that didn&#39;t exist yet, &lt;a href=&#34;https://danluu.com/butler-lampson-1999/&#34;&gt;weren&#39;t yet effective&lt;/a&gt;, or he wasn&#39;t familiar with (e.g., he writes off formal methods, but it doesn&#39;t even occur to him to mention fuzzers, static analysis tools that don&#39;t fully formally verify code, tools like valgrind, etc.) but also because Brooks thought that every class of tool where there was major improvement was played out and it turns out that none of them were (e.g., programming languages, which Brooks wrote just before the rise of &amp;quot;scripting languages&amp;quot; as well as just before GC langauges took over the vast majority of programming).&lt;/p&gt;

&lt;p&gt;In some sense, this isn&#39;t too different from when &lt;a href=&#34;https://danluu.com/cli-complexity/#maven&#34;&gt;we looked at Unix and found the Unix mavens saying that we should write software like they did in the 70s&lt;/a&gt; and that &lt;a href=&#34;https://twitter.com/danluu/status/885214004649615360&#34;&gt;the languages they invented are as safe as any language can be&lt;/a&gt;. Long before computers were invented, elders have been telling the next generation that they&#39;ve done everything that there is to be done and that the next generation won&#39;t be able to achieve more. Even without knowing any specifics about programming, we can look at how well these kinds of arguments have held up historically and have decent confidence that the elders are not, in fact, correct this time.&lt;/p&gt;

&lt;p&gt;Looking at the specifics with the benefit of hindsight, we can see that Brooks&#39; 1986 claim that we&#39;ve basically captured all the productivity gains high-level languages can provide isn&#39;t too different from an assembly language programmer saying the same thing in 1955, thinking that assembly is as good as any language can be&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:A&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:A&#34;&gt;7&lt;/a&gt;&lt;/sup&gt; and that his claims about other categories are similar. The main thing these claims demonstrate are a lack of imagination. When Brooks referred to conceptual complexity, he was referring to complexity of using the conceptual building blocks that Brooks was familiar with in 1986 (on problems that Brooks would&#39;ve thought of as programming problems). There&#39;s no reason anyone should think that Brooks&#39; 1986 conception of programming is fundamental any more than they should think that how an assembly programmer from 1955 thought was fundamental. People often make fun of the apocryphal &amp;quot;640k should be enough for anybody&amp;quot; quote, but Brooks saying that, across all categories of potential productivity improvement, we&#39;ve done most of what&#39;s possible to do, is analogous and not apocryphal!&lt;/p&gt;

&lt;p&gt;We&#39;ve seen that, if we look at the future, the fraction of complexity that might be accidental is effectively unbounded. One might argue that, if we look at the present, these terms wouldn&#39;t be meaningless. But, while this will vary by domain, I&#39;ve personally never worked on a non-trivial problem that isn&#39;t completely dominated by accidental complexity, making the concept of essential complexity meaningless on any problem I&#39;ve worked on that&#39;s worth discussing.&lt;/p&gt;

&lt;p&gt;Thanks to Peter Bhat Harkins, Ben Kuhn, Yuri Vishnevsky, Chris Granger, Wesley Aptekar-Cassels, Lifan Zeng, Scott Wolchok, Martin Horenovsky, @realcmb, Kevin Burke, Aaron Brown, and Saul Pwanson for comments/corrections/discussion.&lt;/p&gt;

&lt;p&gt;&lt;link rel=&#34;prefetch&#34; href=&#34;https://danluu.com/cli-complexity/&#34;&gt;
&lt;link rel=&#34;prefetch&#34; href=&#34;https://danluu.com/metrics-analytics/&#34;&gt;
&lt;link rel=&#34;prefetch&#34; href=&#34;https://danluu.com/&#34;&gt;
&lt;link rel=&#34;prefetch&#34; href=&#34;https://danluu.com/about/&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:C&#34;&gt;&lt;blockquote&gt;
&lt;p&gt;The accidents I discuss in the next section. First let us consider the essence&lt;/p&gt;

&lt;p&gt;The essence of a software entity is a construct of interlocking concepts: data sets, relationships among data items, algorithms, and invocations of functions. This essence is abstract, in that the conceptual construct is the same under many different representations. It is nonetheless highly precise and richly detailed.&lt;/p&gt;

&lt;p&gt;I believe the hard part of building software to be the specification, design, and testing of this conceptual construct, not the labor of representing it and testing the fidelity of the representation. We still make syntax errors, to be sure; but they are fuzz compared to the conceptual errors in most systems.&lt;/p&gt;
&lt;/blockquote&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:C&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:T&#34;&gt;&lt;p&gt;Curiously, he also claims, in the same essay, that no individual improvement can yield a 10x improvement within one decade. While this technically doesn&#39;t contradict his Ahmdal&#39;s law argument plus the claim that &amp;quot;most&amp;quot; (i.e., at least half) of complexity is essential/conceptual, it&#39;s unclear why he would include this claim as well.&lt;/p&gt;

&lt;p&gt;When Brooks revisited his essay in 1995 in No Silver Bullet Refired, he claimed that he was correct by using the weakest form of the three claims he made in 1986, that within one decade, no single improvement would result in an order of magnitude improvement. However, he did then re-state the strongest form of the claim he made in 1986 and made it again in 1995, saying that this time, no set of technological improvements could improve productivity more than 2x, for real:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It is my opinion, and that is all, that the accidental or representational part of the work is now down to about half or less of the total. Since this fraction is a question of fact, its value could in principle be settled by measurement. Failing that, my estimate of it can be corrected by better informed and more current estimates. Significantly, no one who has written publicly or privately has asserted that the accidental part is as large as 9/10.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;By the way, I find it interesting that he says that no one disputed this 9/10ths figure. Per the body of this post, I would put it at far above 9/10th for my day-to-day work and, if I were to try to solve the same problems in 1986, the fraction would have been so high that people wouldn&#39;t have even conceived of the problem. As a side effect of having worked in hardware for a decade, I&#39;ve also done work that&#39;s not too different from what some people faced in 1986 (microcode, assembly &amp;amp; C written for DOS) and I would put that work as easily above 9/10th as well.&lt;/p&gt;

&lt;p&gt;Another part of his follow-up that I find interesting is that he quotes Harel&#39;s &amp;quot;Biting the Silver Bullet&amp;quot; from 1992, which, among other things, argues that that decade deadline for an order of magnitude improvement is arbitrary. Brooks&#39; response to this is&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;There are other reasons for the decade limit: the claims made for candidate bullets all have had a certain immediacy about them . . . We will surely make substantial progress over the next 40 years; an order of magnitude over 40 years is hardly magical.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But by Brooks&#39; own words when he revisits the argument in 1995, if 9/10th of complexity is essential, it would be impossible to get more than an order of magnitude improvement from reducing it, with no caveat on the timespan:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;quot;NSB&amp;quot; argues, indisputably, that if the accidental part of the work is less than 9/10 of the total, shrinking it to zero (which would take magic) will not give an order of magnitude productivity improvement.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Both his original essay and the 1995 follow-up are charismatically written and contain a sort of local logic, where each piece of the essay sounds somewhat reasonable if you don&#39;t think about it too hard and you forget everything else the essay says. As with the original, a pedant could argue that this is technically not incoherent — after all, Brooks could be saying:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;at most 9/10th of complexity is accidental (if we ignore the later 1/2 claim, which is the kind of suspension of memory/disbelief one must do to read the essay)&lt;/li&gt;
&lt;li&gt;it would not be surprising for us to eliminate 100% of accidental complexity after 40 years&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While this is technically consistent (again, if we ignore the part that&#39;s inconsistent) and is a set of claims one could make, this would imply that 40 years from 1986, i.e., in 2026, it wouldn&#39;t be implausible for there to be literally zero room for any sort of productivity improvement from tooling, languages, or any other potential source of improvement. But this is absurd. If we look at other sections of Brooks&#39; essay and combine their reasoning, we see other inconsistencies and absurdities.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:T&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:L&#34;&gt;&lt;p&gt;Another issue that we see here is Brooks&#39; insistence on bright-line distinctions between categories. Essential vs. accidental complexity. &amp;quot;Types&amp;quot; of solutions, such as languages vs. &amp;quot;build vs. buy&amp;quot;, etc.&lt;/p&gt;

&lt;p&gt;Brooks admits that &amp;quot;build vs. buy&amp;quot; is one avenue of attack on essential complexity. Perhaps he would agree that buying a regexp package would reduce the essential complexity since that would allow me to avoid keeping all of the concepts associated with writing a parser in my head for simple tasks. But what if, instead of buying regexes, I used a language where they&#39;re bundled into the standard library or is otherwise distributed with the language? Or what if, instead of having to write my own concurrency primitives, those are bundled into the language? Or for that matter, what about &lt;a href=&#34;https://golang.org/pkg/net/http/&#34;&gt;an entire HTTP server&lt;/a&gt;? There is no bright-line distinction between what&#39;s in a library one can &amp;quot;buy&amp;quot; (for free in many cases nowadays) and one that&#39;s bundled into the language, so there cannot be a bright-line distinction between what gains a language provides and what gains can be &amp;quot;bought&amp;quot;. But if there&#39;s no bright-line distinction here, then it&#39;s not possible to say that one of these can reduce essential complexity and the other can&#39;t and maintain a bright-line distinction between essential and accidental complexity (in a response to Brooks, Harel argued against there being a clear distinction in a response, and Brooks&#39; response was to say that there there is, in fact, a bright-line distinction, although he provided no new argument).&lt;/p&gt;

&lt;p&gt;Brooks&#39; repeated insistence on these false distinctions means that the reasoning in the essay isn&#39;t composable. As we&#39;ve already seen in another footnote, if you take reasoning from one part of the essay and apply it alongside reasoning from another part of the essay, it&#39;s easy to create absurd outcomes and sometimes outright contradictions.&lt;/p&gt;

&lt;p&gt;I suspect this is one reason discussions about essential vs. accidental complexity are so muddled. It&#39;s not just that &lt;a href=&#34;https://twitter.com/hillelogram/status/1211433465956196352&#34;&gt;Brooks is being vague and handwave-y&lt;/a&gt;, he&#39;s actually not self-consistent, so there isn&#39;t and cannot be a coherent takeaway. Michael Feathers has noted &lt;a href=&#34;https://twitter.com/mfeathers/status/1259295515532865543&#34;&gt;that people are generally not able to correct identify essential complexity&lt;/a&gt;; as he says, &lt;a href=&#34;https://twitter.com/mfeathers/status/1256995176959971329&#34;&gt;One person’s essential complexity is another person’s accidental complexity.&lt;/a&gt;. This is exactly what we should expect from the essay, since people who have different parts of it in mind will end up with incompatible views.&lt;/p&gt;

&lt;p&gt;This is also a problem when critisizing Brooks. Inevitably, someone will say that what Brooks really meant was something completely different. And that will be true. But Brooks will have meant something completely different while also having meant the things he said that I mention. In defense of the view I&#39;m presenting in the body of the text here, it&#39;s a coherent view that one could have had in 1986. Many of Brooks&#39; statements don&#39;t make sense even when considered as standalone statements, let alone when cross-referenced with the rest of his essay. For example, the statement that no single development will result in an order of magnitude improvement in the next decade. This statement is meaningless as Brooks does not define and no one can definitively say what a &amp;quot;single improvement&amp;quot; is. And, as mentioned above, Brooks&#39; essay reads quite oddly and basically does not make sense if that&#39;s what he&#39;s trying to claim. Another issue with most other readings of Brooks is that those are positions that are also meaningless even if Brooks had done the work to make them well defined. Why does it matter if one single improvement or two result in an order of magnitude improvement. If it&#39;s two improvements, we&#39;ll use them both.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:L&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:F&#34;&gt;&lt;p&gt;Let&#39;s arbitrarily use a Motorola 68k processor with an FP co-processor that could do 200 kFLOPS as a reference for how much power we might have in a consumer CPU (FLOPS is a bad metric for multiple reasons, but this is just to get an idea of what it would take to get 1 CPU-year of computational resources, and Brooks himself uses MIPS as a term as if it&#39;s meaningful). By comparison, the Cray-2 could achieve 1.9 GFLOPS, or roughly 10000x the performance (I think actually less if we were to do a comparable comparison instead of using non-comparable GFLOPS numbers, but let&#39;s be generous here). There are 525600 / 5 = 105120 five minute periods in a year, so to get 1 CPU year&#39;s worth of computation in five minutes we&#39;d need 105120 / 10000 = 10 Cray-2s per query, not including the overhead of aggregating results across Cray-2s.&lt;/p&gt;

&lt;p&gt;It&#39;s unreasonable to think that a consumer software company in 1986 would have enough Cray-2s lying around to allow for any random programmer to quickly run CPU years worth of queries whenever they wanted to do some data analysis. One sources claims that 27 Cray-2s were ever made over the production lifetime of the machine (1985 to 1990). Even if my employer owned all of them and they were all created by 1986, that still wouldn&#39;t be sufficient to allow the kind of ad hoc querying capacity that I have access to in 2020.&lt;/p&gt;

&lt;p&gt;Today, someone at a startup can even make an analogous argument when comparing to a decade ago. You used to have to operate a cluster that would be prohibitively annoying for a startup to operate unless the startup is very specialized, but you can now just use Snowflake and basically get Presto but only pay for the computational power you use (plus a healthy markup) instead of paying to own a cluster and for all of the employees necessary to make sure the cluster is operable.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:F&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:O&#34;&gt;I actually run into one of these every time I publish a new post. I write my posts in Google docs and then copy them into emacs running inside tmux running inside Alacritty. My posts are small enough to fit inside L2 cache, so I could have 64B/3.5 cycle write bandwidth. And yet, the copy+paste operation can take ~1 minute and is so slow I can watch the text get pasted in. Since my chip is working super hard to make sure the copy+paste happens, it&#39;s running at its full non-turbo frequency of 4.2Ghz, giving it 76.8GB/s of write bandwidth. For a 40kB post, 1 minute = 666B/s. 76.8G/666 =~ 8 orders of magnitude left on the table.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:O&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:V&#34;&gt;In this specific case, I&#39;m sure somebody will argue that Visual Studio was quite nice in 2000 and ran on much slower computers (and the debugger was arguably better than it is in the current version). But there was no comparable tool on Linux, nor was there anything comparable to today&#39;s options in the VSCode-like space of easy-to-learn programming editor that provides programming-specific facilities (as opposed to being a souped up version of notepad) without being a full-fledged IDE.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:V&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:A&#34;&gt;&lt;p&gt;And by the way, this didn&#39;t only happen in 1955. I&#39;ve worked with people who, this century, told me that assembly is basically as productive as any high level language. This probably sounds ridiculous to almost every reader of this blog, but if you talk to people who spend all day writing microcode or assembly, you&#39;ll occasionally meet somebody who believes this.&lt;/p&gt;

&lt;p&gt;Thinking that the tools you personally use are as good as it gets is an easy trap to fall into.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:A&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How do cars fare in crash tests they&#39;re not specifically optimized for?</title>
      <link>https://danluu.com/car-safety/</link>
      <pubDate>Tue, 30 Jun 2020 00:06:34 -0700</pubDate>
      
      <guid>https://danluu.com/car-safety/</guid>
      <description>

&lt;p&gt;Any time you have a benchmark that gets taken seriously, some people will start gaming the benchmark. Some famous examples in computing are the CPU benchmark &lt;a href=&#34;https://spec.org/benchmarks.html&#34;&gt;specfp&lt;/a&gt; and video game benchmarks. With specfp, Sun managed to increase its score on &lt;a href=&#34;https://www.spec.org/osg/cpu2000/CFP2000/179.art/docs/179.art.html&#34;&gt;179.art&lt;/a&gt; (a sub-benchmark of specfp) by 12x with a compiler tweak that essentially re-wrote the benchmark kernel, which increased the Sun &lt;a href=&#34;https://en.wikipedia.org/wiki/UltraSPARC_III&#34;&gt;UltraSPARC&lt;/a&gt;’s overall specfp score by 20%. At times, GPU vendors have added specialized benchmark-detecting code to their drivers that lowers image quality during benchmarking to produce higher benchmark scores. Of course, gaming the benchmark isn&#39;t unique to computing and we see people do this &lt;a href=&#34;https://danluu.com/discontinuities/&#34;&gt;in other fields&lt;/a&gt;. It’s not surprising that we see this kind of behavior since improving benchmark scores by cheating on benchmarks is much cheaper (and therefore higher ROI) than improving benchmark scores by actually improving the product.&lt;/p&gt;

&lt;p&gt;As a result, I&#39;m generally suspicious when people take highly specific and well-known benchmarks too seriously. Without other data, you don&#39;t know what happens when conditions aren&#39;t identical to the conditions in the benchmark. With GPU and CPU benchmarks, it’s possible for most people to run the standard benchmarks with slightly tweaked conditions. If the results change dramatically for small changes to the conditions, that’s evidence that the vendor is, if not cheating, at least shading the truth.&lt;/p&gt;

&lt;p&gt;Benchmarks of physical devices can be more difficult to reproduce. Vehicle crash tests are a prime example of this -- they&#39;re highly specific and well-known benchmarks that use up a car for some test runs.&lt;/p&gt;

&lt;p&gt;While there are multiple organizations that do crash tests, they each have particular protocols that they follow. Car manufacturers, if so inclined, could optimize their cars for crash test scores instead of actual safety. Checking to see if crash tests are being gamed with hyper-specific optimizations isn&#39;t really feasible for someone who isn&#39;t a billionaire. The easiest way we can check is by looking at what happens when new tests are added since that lets us see a crash test result that manufacturers weren&#39;t optimizing for just to get a good score.&lt;/p&gt;

&lt;p&gt;While having car crash test results is obviously better than not having them, the results themselves don&#39;t tell us what happens when we get into an accident that doesn&#39;t exactly match a benchmark. Unfortunately, if we get into a car accident, we don&#39;t get to ask the driver of the vehicle we&#39;re colliding with to change their location, angle of impact, and speed, in order for the collision to comply with an &lt;a href=&#34;https://en.wikipedia.org/wiki/Insurance_Institute_for_Highway_Safety&#34;&gt;IIHS&lt;/a&gt;, &lt;a href=&#34;https://en.wikipedia.org/wiki/National_Highway_Traffic_Safety_Administration&#34;&gt;NHTSA&lt;/a&gt;, or &lt;a href=&#34;https://en.wikipedia.org/wiki/New_Car_Assessment_Program&#34;&gt;*NCAP&lt;/a&gt;, test protocol.&lt;/p&gt;

&lt;p&gt;For this post, we&#39;re going to look at &lt;a href=&#34;https://en.wikipedia.org/wiki/Insurance_Institute_for_Highway_Safety&#34;&gt;IIHS&lt;/a&gt; test scores when they added the (driver side) small overlap and passenger side small overlap tests, which were added in 2012, and 2018, respectively. We&#39;ll start with a summary of the results and then discuss what those results mean and other factors to consider when evaluating car safety, followed by details of the methodology.&lt;/p&gt;

&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;

&lt;p&gt;The ranking below is mainly based on how well vehicles scored when the driver-side small overlap test was added in 2012 and how well models scored when they were modified to improve test results.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Tier 1&lt;/strong&gt;: good without modifications

&lt;ul&gt;
&lt;li&gt;Volvo&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tier 2&lt;/strong&gt;: mediocre without modifications; good with modifications

&lt;ul&gt;
&lt;li&gt;None&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tier 3&lt;/strong&gt;: poor without modifications; good with modifications

&lt;ul&gt;
&lt;li&gt;Mercedes&lt;/li&gt;
&lt;li&gt;BMW&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tier 4&lt;/strong&gt;: poor without modifications; mediocre with modifications

&lt;ul&gt;
&lt;li&gt;Honda&lt;/li&gt;
&lt;li&gt;Toyota&lt;/li&gt;
&lt;li&gt;Subaru&lt;/li&gt;
&lt;li&gt;Chevrolet&lt;/li&gt;
&lt;li&gt;Tesla&lt;/li&gt;
&lt;li&gt;Ford&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tier 5&lt;/strong&gt;: poor with modifications or modifications not made

&lt;ul&gt;
&lt;li&gt;Hyundai&lt;/li&gt;
&lt;li&gt;Dodge&lt;/li&gt;
&lt;li&gt;Nissan&lt;/li&gt;
&lt;li&gt;Jeep&lt;/li&gt;
&lt;li&gt;Volkswagen&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These descriptions are approximations. Honda, Ford, and Tesla are the poorest fits for these descriptions, with Ford arguably being halfway in between Tier 4 and Tier 5 but also arguably being better than Tier 4 and not fitting into the classification and Honda and Tesla not really properly fitting into any category (with their category being the closest fit), but some others are also imperfect. Details below.&lt;/p&gt;

&lt;h3 id=&#34;general-commentary&#34;&gt;General commentary&lt;/h3&gt;

&lt;p&gt;If we look at overall mortality in the U.S., there&#39;s a pretty large age range for which car accidents are the leading cause of death. Although the numbers will vary depending on what data set we look at, when the driver-side small overlap test was added, the IIHS estimated that 25% of vehicle fatalities came from small overlap crashes. It&#39;s also worth noting that small overlap crashes were thought to be implicated in a significant fraction of vehicle fatalities at least since the 90s; this was not a novel concept in 2012.&lt;/p&gt;

&lt;p&gt;Despite the importance of small overlap crashes, from looking at the results when the IIHS added the driver-side and passenger-side small overlap tests in 2012 and 2018, it looks like almost all car manufacturers were optimizing for benchmark and not overall safety. Except for Volvo, all carmakers examined produced cars that fared poorly on driver-side small overlap crashes until the driver-side small overlap test was added.&lt;/p&gt;

&lt;p&gt;When the driver-side small overlap test was added in 2012, most manufacturers modified their vehicles to improve driver-side small overlap test scores. However, until the IIHS added a passenger-side small overlap test in 2018, most manufacturers skimped on the passenger side. When the new test was added, they beefed up passenger safety as well. To be fair to car manufacturers, some of them got the hint about small overlap crashes when the driver-side test was added in 2012 and did not need to make further modifications to score well on the passenger-side test, including Mercedes, BMW, and Tesla (and arguably a couple of others, but the data is thinner in the other cases; Volvo didn&#39;t need a hint).&lt;/p&gt;

&lt;h3 id=&#34;other-benchmark-limitations&#34;&gt;Other benchmark limitations&lt;/h3&gt;

&lt;p&gt;There are a number of other areas where we can observe that most car makers are optimizing for benchmarks at the expensive of safety.&lt;/p&gt;

&lt;h4 id=&#34;gender-weight-and-height&#34;&gt;Gender, weight, and height&lt;/h4&gt;

&lt;p&gt;Another issue is crash test dummy overfitting. For a long time, adult NHSTA and IIHS tests used a 1970s 50%-ile male dummy, which is 5&#39;9&amp;quot; and 171lbs. Regulators called for a female dummy in 1980 but due to budget cutbacks during the Reagan era, initial plans were shelved and the NHSTA didn&#39;t put one in a car until 2003. The female dummy is a scaled down version of the male dummy, scaled down to 5%-ile 1970s height and weight (4&#39;11&amp;quot;, 108lbs; another model is 4&#39;11&amp;quot;, 97lbs). In frontal crash tests, when a female dummy is used, it&#39;s always a passenger (a 5%-ile woman is in the driver&#39;s seat in one NHSTA side crash test and the IIHS side crash test). For reference, in 2019, the average weight of a U.S. adult male was 198 lbs and the average weight of a U.S. adult female was 171 lbs.&lt;/p&gt;

&lt;p&gt;Using a 1970s U.S. adult male crash test dummy causes a degree of overfitting for 1970s 50%-ile men. For example, starting in the 90s, manufacturers started adding systems to protect against whiplash. Volvo and Toyota use a kind of system that reduces whiplash in men and women and appears to have slightly more benefit for women. Most car makers use a kind of system that reduces whiplash in men but, on average, has little impact on whiplash injuries in women.&lt;/p&gt;

&lt;p&gt;It appears that we also see a similar kind of optimization for crashes in general and not just whiplash. We don&#39;t have crash test data on this, and looking at real-world safety data is beyond the scope of this post, but I&#39;ll note that, until around the time the NHSTA put the 5%-ile female dummy into some crash tests, most car manufacturers not named Volvo had a significant fatality rate differential in side crashes based on gender (with men dying at a lower rate and women dying at a higher rate).&lt;/p&gt;

&lt;p&gt;Volvo claims to have been using computer models to simulate what would happen if women (including pregnant women) are involved in a car accident for decades.&lt;/p&gt;

&lt;h4 id=&#34;other-crashes&#34;&gt;Other crashes&lt;/h4&gt;

&lt;p&gt;Volvo is said to have a crash test facility where they do a number of other crash tests that aren&#39;t done by testing agencies. A reason that they scored well on the small overlap tests when they were added is that they were already doing small overlap crash tests before the IIHS started doing small overlap crash tests.&lt;/p&gt;

&lt;p&gt;Volvo also says that they test rollovers (the IIHS tests roof strength and the NHSTA computes how difficult a car is to roll based on properties of the car, but neither tests what happens in a real rollover accident), rear collisions (Volvo claims these are especially important to test if there are children in the 3rd row of a 3-row SUV), and driving off the road (Volvo has a &amp;quot;standard&amp;quot; ditch they use; they claim this test is important because running off the road is implicated in a large fraction of vehicle fatalities).&lt;/p&gt;

&lt;p&gt;If other car makers do similar tests, I couldn&#39;t find much out about the details. Based on crash test scores, it seems like they weren&#39;t doing or even considering small overlap crash tests before 2012. Based on how many car makers had poor scores when the passenger side small overlap test was added in 2018, I think it would be surprising if other car makers had a large suite of crash tests they ran that aren&#39;t being run by testing agencies, but it&#39;s theoretically possible that they do and just didn&#39;t include a passenger side small overlap test.&lt;/p&gt;

&lt;h3 id=&#34;caveats&#34;&gt;Caveats&lt;/h3&gt;

&lt;p&gt;We shouldn&#39;t overgeneralize from these test results. As we noted above, crash test results test very specific conditions. As a result, what we can conclude when a couple new crash tests are added is also very specific. Additionally, there are a number of other things we should keep in mind when interpreting these results.&lt;/p&gt;

&lt;h5 id=&#34;limited-sample-size&#34;&gt;Limited sample size&lt;/h5&gt;

&lt;p&gt;One limitation of this data is that we don&#39;t have results for a large number of copies of the same model, so we&#39;re unable to observe intra-model variation, which could occur due to minor, effectively random, differences in test conditions as well as manufacturing variations between different copies of same model. We can observe that these do matter since some cars will see different results when two copies of the same model are tested. For example, here&#39;s a quote from the IIHS report on the Dodge Dart:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The Dodge Dart was introduced in the 2013 model year. Two tests of the Dart were conducted because electrical power to the onboard (car interior) cameras was interrupted during the first test. In the second Dart test, the driver door opened when the hinges tore away from the door frame. In the first test, the hinges were severely damaged and the lower one tore away, but the door stayed shut. In each test, the Dart’s safety belt and front and side curtain airbags appeared to adequately protect the dummy’s head and upper body, and measures from the dummy showed little risk of head and chest injuries.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It looks like, had electrical power to the interior car cameras not been disconnected, there would have been only one test and it wouldn&#39;t have become known that there&#39;s a risk of the door coming off due to the hinges tearing away. In general, we have no direct information on what would happen if another copy of the same model were tested.&lt;/p&gt;

&lt;p&gt;Using IIHS data alone, one thing we might do here is to also consider results from different models made by the same manufacturer (or built on the same platform). Although this isn&#39;t as good as having multiple tests for the same model, test results between different models from the same manufacturer are correlated and knowing that, for example, a 2nd test of a model that happened by chance showed significantly worse results should probably reduce our confidence in other test scores from the same manufacturer. There are some things that complicate this, e.g., if looking at Toyota, the Yaris is actually a re-branded Mazda2, so perhaps that shouldn&#39;t be considered as part of a pooled test result, and doing this kind of statistical analysis is beyond the scope of this post.&lt;/p&gt;

&lt;h4 id=&#34;actual-vehicle-tested-may-be-different&#34;&gt;Actual vehicle tested may be different&lt;/h4&gt;

&lt;p&gt;Although I don&#39;t think this should impact the results in this post, another issue to consider when looking at crash test results is how results are shared between models. As we just saw, different copies of the same model can have different results. Vehicles that are somewhat similar are often considered the same for crash test purposes and will share the same score (only one of the models will be tested).&lt;/p&gt;

&lt;p&gt;For example, this is true of the Kia Stinger and the Genesis G70. The Kia Stinger is 6&amp;quot; longer than the G70 and a fully loaded AWD Stinger is about 500 lbs heavier than a base-model G70. The G70 is the model that IIHS tested -- if you look up a Kia Stinger, you&#39;ll get scores for a Stinger with a note that a base model G70 was tested. That&#39;s a pretty big difference considering that cars that are nominally identical (such as the Dodge Darts mentioned above) can get different scores.&lt;/p&gt;

&lt;h4 id=&#34;quality-may-change-over-time&#34;&gt;Quality may change over time&lt;/h4&gt;

&lt;p&gt;We should also be careful not to overgeneralize temporally. If we look at crash test scores of recent Volvos (vehicles on the Volvo P3 and Volvo SPA platforms), crash test scores are outstanding. However, if we look at Volvo models based on the older Ford C1 platform&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:F&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:F&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;, crash test scores for some of these aren&#39;t as good (in particular, while the S40 doesn&#39;t score poorly, it scores Acceptable in some categories instead of Good across the board). Although Volvo has had stellar crash test scores recently, this doesn&#39;t mean that they have always had or will always have stellar crash test scores.&lt;/p&gt;

&lt;h4 id=&#34;models-may-vary-across-markets&#34;&gt;Models may vary across markets&lt;/h4&gt;

&lt;p&gt;We also can&#39;t generalize across cars sold in different markets, even for vehicles that sound like they might be identical. For example, see &lt;a href=&#34;https://www.youtube.com/watch?v=UL_2MdSTM7g&#34;&gt;this crash test of a Nissan NP300 manufactured for sale in Europe vs. a Nissan NP300 manufactured for sale in Africa&lt;/a&gt;. Since European cars undergo EuroNCAP testing (similar to how U.S. cars undergo NHSTA and IIHS testing), vehicles sold in Europe are optimized to score well on EuroNCAP tests. Crash testing cars sold in Africa has only been done relatively recently, so car manufacturers haven&#39;t had PR pressure to optimize their cars for benchmarks and they&#39;ll produce cheaper models or cheaper variants of what superficially appear to be the same model. This appears to be no different from what most car manufacturers do in the U.S. or Europe -- they&#39;re optimizing for cost as long as they can do that without scoring poorly on benchmarks. It&#39;s just that, since there wasn&#39;t an African crash test benchmark, that meant they could go all-in on the cost side of the cost-safety tradeoff&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:A&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:A&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://deepblue.lib.umich.edu/bitstream/handle/2027.42/112977/103199.pdf&#34;&gt;This report&lt;/a&gt; compared U.S. and European car models and found differences in safety due to differences in regulations. They found that European models had lower injury risk in frontal/side crashes and that driver-side mirrors were designed in a way that reduced the risk of lane-change crashes relative to U.S. designs and that U.S. vehicles were safer in rollovers and had headlamps that made pedestrians more visible.&lt;/p&gt;

&lt;h4 id=&#34;non-crash-tests&#34;&gt;Non-crash tests&lt;/h4&gt;

&lt;p&gt;Over time, more and more of the &amp;quot;low hanging fruit&amp;quot; from crash safety has been picked, making crash avoidance relatively more important. Tests of crash mitigation are relatively primitive compared to crash tests and we&#39;ve seen that crash tests had and have major holes. One might expect, based on what we&#39;ve seen with crash tests, that Volvo has a particularly good set of tests they use for their crash avoidance technology (traction control, stability control, automatic braking, etc.), but I don&#39;t know of any direct evidence for that.&lt;/p&gt;

&lt;p&gt;Crash avoidance becoming more important might also favor companies that have safer driver assistance systems, e.g., in multiple generations of tests, Consumer Reports has given GM&#39;s Super Cruise system the highest rating while they&#39;ve repeatedly noted that Tesla&#39;s Autopilot system facilitates unsafe behavior.&lt;/p&gt;

&lt;h4 id=&#34;scores-of-vehicles-of-different-weights-aren-t-comparable&#34;&gt;Scores of vehicles of different weights aren&#39;t comparable&lt;/h4&gt;

&lt;p&gt;A 2700lb subcompact vehicle that scores Good may fare worse than a 5000lb SUV that scores Acceptable. This is because the small overlap tests involve driving the vehicle into a fixed obstacle, as opposed to a reference vehicle or vehicle-like obstacle of a specific weight. This is, in some sense, equivalent to crashing the vehicle into a vehicle of the same weight, so it&#39;s as if the 2700lb subcompact was tested by running it into a 2700lb subcompact and the 5000lb SUV was tested by running it into another 5000 lb SUV.&lt;/p&gt;

&lt;h4 id=&#34;how-to-increase-confidence&#34;&gt;How to increase confidence&lt;/h4&gt;

&lt;p&gt;We&#39;ve discussed some reasons we should reduce our confidence in crash test scores. If we wanted to increase our confidence in results, we could look at test results from other test agencies and aggregate them and also look at public crash fatality data (more on this later). I haven&#39;t looked at the terms and conditions of scores from other agencies, but one complication is that the IIHS does not allow you to display the result of any kind of aggregation if you use their API or data dumps (I, time consumingly, did not use their API for this post because of that).&lt;/p&gt;

&lt;h4 id=&#34;using-real-life-crash-data&#34;&gt;Using real life crash data&lt;/h4&gt;

&lt;p&gt;Public crash fatality data is complex and deserves its own post. In this post, I&#39;ll note that, if you look at the easiest relevant data for people in the U.S., this data does not show that Volvos are particularly safe (or unsafe). For example, if we look at &lt;a href=&#34;https://www.iihs.org/api/datastoredocument/status-report/pdf/52/3&#34;&gt;this report from 2017, which covers models from 2014&lt;/a&gt;, two Volvo models made it into the report and both score roughly middle of the pack for their class. In the previous report, one Volvo model is included and it&#39;s among the best in its class, in the next, one Volvo model is included and it&#39;s among the worst in its class. We can observe this kind of variance for other models, as well. For example, among 2014 models, the Volkswagen Golf had one of the highest fatality rates for all vehicles (not just in its class). But among 2017 vehicles, it had among the lowest fatality rates for all vehicles. It&#39;s unclear how much of that change is from random variation and how much is because of differences between a 2014 and 2017 Volkswagen Golf.&lt;/p&gt;

&lt;p&gt;Overall, it seems like noise is a pretty important factor in results. And if we look at the information that&#39;s provided, we can see a few things that are odd. First, there are a number of vehicles where the 95% confidence interval for the fatality rate runs from 0 to N. We should have pretty strong priors that there was no 2014 model vehicle that was so safe that the probability of being killed in a car accident was zero. If we were taking a Bayesian approach (though I believe the authors of the report are not), and someone told us that the uncertainty interval for the true fatality rate of a vehicle had a &amp;gt;= 5% of including zero, we would say that either we should use a more informative prior or we should use a model that can incorporate more data (in this case, perhaps we could try to understand the variance between fatality rates of different models in the same class and then use the base rate of fatalities for the class as a prior, or we could incorporate information from other models under the same make if those are believed to be correlated).&lt;/p&gt;

&lt;p&gt;Some people object to using informative priors as a form of bias laundering, but we should note that the prior that&#39;s used for the IIHS analysis is not completely uninformative. All of the intervals reported stop at zero because they&#39;re using the fact that a vehicle cannot create life to bound the interval at zero. But we have information that&#39;s nearly as strong that no 2014 vehicle is so safe that the expected fatality rate is zero, using that information is not fundamentally different from capping the interval at zero and not reporting negative numbers for the uncertainty interval of the fatality rate.&lt;/p&gt;

&lt;p&gt;Also, the IIHS data only includes driver fatalities. This is understandable since that&#39;s the easiest way to normalize for the number of passengers in the car, but it means that we can&#39;t possibly see the impact of car makers not improving passenger small-overlap safety until the passenger-side small overlap test was added in 2018, the result of lack of rear crash testing for the case Volvo considers important (kids in the back row of a 3rd row SUV). This also means that we cannot observe the impact of a number of things Volvo has done, e.g., being very early on pedestrian and then cyclist detection in their automatic braking system, adding a crumple zone to reduce back injuries in run-off-road accidients, which they observed often cause life-changing spinal injuries due to the impact from vehicles drop, etc.&lt;/p&gt;

&lt;p&gt;We can also observe that, in the IIHS analysis, many factors that one might want to control for aren&#39;t (e.g., miles driven isn&#39;t controlled for, which will make trucks look relatively worse and luxury vehicles look relatively better, rural vs. urban miles driven also isn&#39;t controlled for, which will also have the same directional impact). One way to see that the numbers are heavily influenced by confounding factors is by looking at AWD or 4WD vs. 2WD versions of cars. They often have wildly different fatalty rates even though the safety differences are not very large (and the difference is often in favor of the 2WD vehicle). Some plausible causes of that are random noise, differences in who buys different versions of the same vehicle, and differences in how the vehicle are used.&lt;/p&gt;

&lt;p&gt;If we&#39;d like to answer the question &amp;quot;which car makes or models are more or less safe&amp;quot;, I don&#39;t find any of the aggregations that are publicly available to be satisfying and I think we need to look at the source data and do our own analysis to see if the data are consistent with what we see in crash test results.&lt;/p&gt;

&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;We looked at 12 different car makes and how they fared when the IIHS added small overlap tests. We saw that only Volvo was taking this kind of accident seriously before companies were publicly shamed for having poor small overlap safety by the IIHS even though small overlap crashes were known to be a significant source of fatalities at least since the 90s.&lt;/p&gt;

&lt;p&gt;Although I don&#39;t have the budget to do other tests, such as a rear crash test in a fully occupied vehicle, it appears plausible and perhaps even likely that most car makers that aren&#39;t Volvo would have mediocre or poor test scores if a testing agency decided to add another kind of crash test.&lt;/p&gt;

&lt;h3 id=&#34;bonus-real-engineering-vs-programming&#34;&gt;Bonus: &amp;quot;real engineering&amp;quot; vs. programming&lt;/h3&gt;

&lt;p&gt;As Hillel Wayne has noted, although &lt;a href=&#34;https://twitter.com/danluu/status/1162469763374673920&#34;&gt;programmers often have an idealized view of what &amp;quot;real engineers&amp;quot; do&lt;/a&gt;, when you &lt;a href=&#34;https://youtu.be/3018ABlET1Y&#34;&gt;compare what &amp;quot;real engineers&amp;quot; do with what programmers do, it&#39;s frequently not all that different&lt;/a&gt;. In particular, a common lament of programmers is that we&#39;re not held liable for our mistakes or poor designs, even in cases where that costs lives.&lt;/p&gt;

&lt;p&gt;Although automotive companies can, in some cases, be held liable for unsafe designs, just optimizing for a small set of benchmarks, which must&#39;ve resulted in extra deaths over optimizing for safety instead of benchmark scores, isn&#39;t something that engineers or corporations were, in general, held liable for.&lt;/p&gt;

&lt;h3 id=&#34;bonus-reputation&#34;&gt;Bonus: reputation&lt;/h3&gt;

&lt;p&gt;If I look at what people in my extended social circles think about vehicle safety, Tesla has the best reputation by far. If you look at broad-based consumer polls, that&#39;s a different story, and Volvo usually wins there, with other manufacturers fighting for a distant second.&lt;/p&gt;

&lt;p&gt;I find the Tesla thing interesting since their responses are basically the opposite of what you&#39;d expect from a company that was serious about safety. When serious problems have occurred (with respect to safety or otherwise), they often have a very quick response that&#39;s basically &amp;quot;everything is fine&amp;quot;. I would expect an organization that&#39;s serious about safety or improvement to respond with &amp;quot;we&#39;re investigating&amp;quot;, followed by a detailed postmortem explaining what went wrong, but that doesn&#39;t appear to be Tesla&#39;s style.&lt;/p&gt;

&lt;p&gt;For example, on the driver-side small overlap test, Tesla had one model with a relevant score and it scored Acceptable (below Good, but above Poor and Marginal) even after modifications were made to improve the score. &lt;a href=&#34;https://www.businessinsider.com/tesla-responds-to-model-s-crash-test-findings-iihs-2017-7&#34;&gt;Tesla disputed the results, saying they make &amp;quot;the safest cars in history&amp;quot;&lt;/a&gt; and implying that IIHS should be ignored in favor of &lt;a href=&#34;https://en.wikipedia.org/wiki/National_Highway_Traffic_Safety_Administration&#34;&gt;NHSTA&lt;/a&gt; test scores:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;While IIHS and dozens of other private industry groups around the world have methods and motivations that suit their own subjective purposes, the most objective and accurate independent testing of vehicle safety is currently done by the U.S. Government which found Model S and Model X to be the two cars with the lowest probability of injury of any cars that it has ever tested, making them the safest cars in history.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;As we&#39;ve seen, Tesla isn&#39;t unusual for optimizing for a specific set of crash tests and achieving a mediocre score when an unexpected type of crash occurs, but their response is unusual. However, it makes sense from a cynical PR perspective. As we&#39;ve seen over the past few years, loudly proclaiming something, regardless of whether or not it&#39;s true, even when there&#39;s incontrovertible evidence that it&#39;s untrue, seems to not only work, that kind of bombastic rhetoric appears to attract superfans who will aggressively defend the brand. If you watch car reviewers on youtube, they&#39;ll sometimes mention that they get hate mail for reviewing Teslas just like they review any other car and that they don&#39;t see anything like it for any other make.&lt;/p&gt;

&lt;p&gt;Apple also used this playbook to good effect in the 90s and early &#39;00s, when they were rapidly falling behind in performance and responded not by improving performance, but by running a series of ad campaigns saying that had the best performance in the world and that they were shipping &amp;quot;supercomputers&amp;quot; on the desktop.&lt;/p&gt;

&lt;p&gt;Another reputational quirk is that I know a decent number of people who believe that the safest cars they can buy are &amp;quot;American Cars from the 60&#39;s and 70&#39;s that aren&#39;t made of plastic&amp;quot;. We don&#39;t have directly relevant small overlap crash test scores for old cars, but the test data we do have on old cars indicates that they fare extremely poorly in overall safety compared to modern cars. For a visually dramatic example, &lt;a href=&#34;https://www.youtube.com/watch?v=fPF4fBGNK0U&#34;&gt;see this crash test of a 1959 Chevrolet Bel Air vs. a 2009 Chevrolet Malibu&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;appendix-methodology-summary&#34;&gt;Appendix: methodology summary&lt;/h3&gt;

&lt;p&gt;The top-line results section uses scores for the small overlap test both because it&#39;s the one where I think it&#39;s the most difficult to justify skimping on safety as measured by the test and it&#39;s also been around for long enough that we can see the impact of modifications to existing models and changes to subsequent models, which isn&#39;t true of the passenger side small overlap test (where many models are still untested).&lt;/p&gt;

&lt;p&gt;For the passenger side small overlap test, someone might argue that the driver side is more important because you virtually always have a driver in a car accident and may or may not have a front passenger. Also, for small overlap collisions (which simulates a head-to-head collision where the vehicles only overlap by 25%), driver&#39;s side collisions are more likely than passenger side collisions.&lt;/p&gt;

&lt;p&gt;Except to check Volvo&#39;s scores, I didn&#39;t look at roof crash test scores (which were added in 2009). I&#39;m not going to describe the roof test in detail, but for the roof test, someone might argue that the roof test score should be used in conjunction with scoring the car for rollover probability since the roof test just tests roof strength, which is only relevant when a car has rolled over. I think, given what the data show, this objection doesn&#39;t hold in many cases (the vehicles with the worst roof test scores are often vehicles that have relatively high rollover rates), but it does in some cases, which would complicate the analysis.&lt;/p&gt;

&lt;p&gt;In most cases, we only get one reported test result for a model. However, there can be multiple versions of a model -- including before and after making safety changes intended to improve the test score. If changes were made to the model to improve safety, the test score is usually from after the changes were made and we usually don&#39;t get to see the score from before the model was changed. However, there are many exceptions to this, which are noted in the detailed results section.&lt;/p&gt;

&lt;p&gt;For this post, scores only count if the model was introduced before or near when the new test was introduced, since models introduced later could have design changes that optimize for the test.&lt;/p&gt;

&lt;h3 id=&#34;appendix-detailed-results&#34;&gt;Appendix: detailed results&lt;/h3&gt;

&lt;p&gt;On each test, IIHS gives an overall rating (from worst to best) of Poor, Marginal, Acceptable, or Good. The tests have sub-scores, but we&#39;re not going to use those for this analysis. In each sub-section, we&#39;ll look at how many models got each score when the small overlap tests were added.&lt;/p&gt;

&lt;h4 id=&#34;volvo&#34;&gt;Volvo&lt;/h4&gt;

&lt;p&gt;All Volvo models examined scored Good (the highest possible score) on the new tests when they were added (roof, driver-side small overlap, and passenger-side small overlap). One model, the 2008-2017 XC60, had a change made to trigger its side curtain airbag during a small overlap collision in 2013. Other models were tested without modifications.&lt;/p&gt;

&lt;h4 id=&#34;mercedes&#34;&gt;Mercedes&lt;/h4&gt;

&lt;p&gt;Of three pre-existing models with test results for driver-side small overlap, one scored Marginal without modifications and two scored Good after structural modifications. The model where we only have unmodified test scores (Mercedes C-Class) was fully re-designed after 2014, shortly after the driver-side small overlap test was introduced.&lt;/p&gt;

&lt;p&gt;As mentioned above, we often only get to see public results for models without modifications to improve results xor with modifications to improve results, so, for the models that scored Good, we don&#39;t actually know how they would&#39;ve scored if you bought a vehicle before Mercedes updated the design, but the Marginal score from the one unmodified model we have is a negative signal.&lt;/p&gt;

&lt;p&gt;Also, when the passenger side small overlap test was added, the Mercedes vehicles also generally scored Good. This is, indicating that Mercedes didn&#39;t only increase protection on the driver&#39;s side in order to improve test scores.&lt;/p&gt;

&lt;h4 id=&#34;bmw&#34;&gt;BMW&lt;/h4&gt;

&lt;p&gt;Of the two models where we have relevant test scores, both scored Marginal before modifications. In one of the cases, there&#39;s also a score after structural changes were made in the 2017 model (recall that the driver-side small overlap test was introduced in 2012) and the model scored Good afterwards. The other model was fully-redesigned after 2016.&lt;/p&gt;

&lt;p&gt;For the five models where we have relevant passenger-side small overlap scores, all scored Good, indicating that the changes made to improve driver-side small overlap test scores weren&#39;t only made on the driver&#39;s side.&lt;/p&gt;

&lt;h4 id=&#34;honda&#34;&gt;Honda&lt;/h4&gt;

&lt;p&gt;Of the five Honda models where we have relevant driver-side small overlap test scores, two scored Good, one scored Marginal, and two scored Poor. The model that scored Marginal had structural changes plus a seatbelt change in 2015 that changed its score to Good, other models weren&#39;t updated or don&#39;t have updated IIHS scores.&lt;/p&gt;

&lt;p&gt;Of the six Honda models where we have passenger driver-side small overlap test scores, two scored Good without modifications, two scored Acceptable without modifications, and one scored Good with modifications to the bumper.&lt;/p&gt;

&lt;p&gt;All of those models scored Good on the driver side small overlap test, indicating that when Honda increased the safety on the driver&#39;s side to score Good on the driver&#39;s side test, they didn&#39;t apply the same changes to the passenger side.&lt;/p&gt;

&lt;h4 id=&#34;toyota&#34;&gt;Toyota&lt;/h4&gt;

&lt;p&gt;Of the six Toyota models where we have relevant driver-side small overlap test scores for unmodified models, one score Acceptable, four scored Marginal, and one scored Poor.&lt;/p&gt;

&lt;p&gt;The model that scored Acceptable had structural changes made to improve its score to Good, but on the driver&#39;s side only. The model was later tested in the passenger-side small overlap test and scored Acceptable. Of the four models that scored Marginal, one had structural modifications made in 2017 that improved its score to Good and another had airbag and seatbelt changes that improved its score to to Acceptable. The vehicle that scored Poor had structural changes made that improved its score to acceptable in 2014, followed by later changes that improved its score to Good.&lt;/p&gt;

&lt;p&gt;There are four additional models where we only have scores from after modifications were made. Of those, one scored Good, one score Acceptable, one scored Marginal, and one scored Poor.&lt;/p&gt;

&lt;p&gt;In general, changes appear to have been made to the driver&#39;s side only and, on introduction of the passenger side small overlap test, vehicles had passenger side small overlap scores that were the same as the driver&#39;s side score before modifications.&lt;/p&gt;

&lt;h4 id=&#34;ford&#34;&gt;Ford&lt;/h4&gt;

&lt;p&gt;Of the two models with relevant driver-side small overlap test scores for unmodified models, one scored Marginal and one scored Poor. Both of those models were produced into 2019 and neither has an updated test result. Of the three models where we have relevant results for modified vehicles, two scored Acceptable and one score Marginal. Also, one model was released the year the small overlap test was introduced and one the year after; both of those scored Acceptable. It&#39;s unclear if those should be considered modified or not since the design may have had last-minute changes before release.&lt;/p&gt;

&lt;p&gt;We only have three relevant passenger-side small overlap tests. One is Good (for a model released in 2015) and the other two are Poor; these are the two models mentioned above as having scored Marginal and Poor, respectively, on the driver-side small overlap test. It appears that the models continued to be produced into 2019 without safety changes. Both of these unmodified models were trucks and this isn&#39;t very unusual for a truck and is one of a number of reasons that fatality rates are generally higher in trucks -- until recently, many of them are based on old platforms that hadn&#39;t been updated for a long time.&lt;/p&gt;

&lt;h4 id=&#34;chevrolet&#34;&gt;Chevrolet&lt;/h4&gt;

&lt;p&gt;Of the three Chevrolet models where we have relevant driver-side small overlap test scores before modifications, one scored Acceptable and two scored Marginal. One of the Marginal models had structural changes plus a change that caused side curtain airbags to deploy sooner in 2015, which improved its score to Good.&lt;/p&gt;

&lt;p&gt;Of the four Chevrolet models where we only have relevant driver-side small overlap test scores after the model was modified (all had structural modifications), two scored Good and two scored Acceptable.&lt;/p&gt;

&lt;p&gt;We only have one relevant score for the passenger-side small overlap test, that score is Marginal. That&#39;s on the model that was modified to improve its driver-side small overlap test score from Marginal to Good, indicating that the changes were made to improve the driver-side test score and not to improve passenger safety.&lt;/p&gt;

&lt;h4 id=&#34;subaru&#34;&gt;Subaru&lt;/h4&gt;

&lt;p&gt;We don&#39;t have any models where we have relevant passenger-side small overlap test scores for models before they were modified.&lt;/p&gt;

&lt;p&gt;One model had a change to cause its airbag to deploy during small overlap tests; it scored Acceptable. Two models had some kind of structural changes, one of which scored Good and one of which score Acceptable.&lt;/p&gt;

&lt;p&gt;The model that had airbag changes had structural changes made in 2015 that improved its score from Acceptable to Good.&lt;/p&gt;

&lt;p&gt;For the one model where we have relevant passenger-side small overlap test scores, the score was Marginal. Also, for one of the models with structural changes, it was indicated that, among the changes, were changes to the left part of the firewall, indicating that changes were made to improve the driver&#39;s side test score without improving safety for a passenger on a passenger-side small overlap crash.&lt;/p&gt;

&lt;h4 id=&#34;tesla&#34;&gt;Tesla&lt;/h4&gt;

&lt;p&gt;There&#39;s only one model with relevant results for the driver-side small overlap test. That model scored Acceptable before and after modifications were made to improve test scores.&lt;/p&gt;

&lt;h4 id=&#34;hyundai&#34;&gt;Hyundai&lt;/h4&gt;

&lt;p&gt;Of the five vehicles where we have relevant driver-side small overlap test scores, one scored Acceptable, three scored Marginal, and one scored Poor. We don&#39;t have any indication that models were modified to improve their test scores.&lt;/p&gt;

&lt;p&gt;Of the two vehicles where we have relevant passenger-side small overlap test scores for unmodified models, one scored Good and one scored Acceptable.&lt;/p&gt;

&lt;p&gt;We also have one score for a model that had structural modifications to score Acceptable, which later had further modifications that allowed it to score Good. That model was introduced in 2017 and had a Good score on the driver-side small overlap test without modifications, indicating that it was designed to achieve a good test score on the driver&#39;s side test without similar consideration for a passenger-side impact.&lt;/p&gt;

&lt;h4 id=&#34;dodge&#34;&gt;Dodge&lt;/h4&gt;

&lt;p&gt;Of the five models where we have relevant driver-side small overlap test scores for unmodified models, two scored Acceptable, one scored Marginal, and two scored Poor. There are also two models where we have test scores after structural changes were made for safety in 2015; both of those models scored Marginal.&lt;/p&gt;

&lt;p&gt;We don&#39;t have relevant passenger-side small overlap test scores for any model, but even if we did, the dismal scores on the modified models means that we might not be able to tell if similar changes were made to the passenger side.&lt;/p&gt;

&lt;h4 id=&#34;nissan&#34;&gt;Nissan&lt;/h4&gt;

&lt;p&gt;Of the seven models where we have relevant driver-side small overlap test scores for unmodified models, two scored Acceptable and five scored Poor.&lt;/p&gt;

&lt;p&gt;We have one model that only has test scores for a modified model; the frontal airbags and seatbelts were modified in 2013 and the side curtain airbags were modified in 2017. The score afterward modifications was Marginal.&lt;/p&gt;

&lt;p&gt;One of the models that scored Poor had structural changes made in 2015 that improved its score to Good.&lt;/p&gt;

&lt;p&gt;Of the four models where we have relevant passenger-side small overlap test scores, two scored Good, one scored Acceptable (that model scored good on the driver-side test), and one score Marginal (that model also scored Marginal on the driver-side test).&lt;/p&gt;

&lt;h4 id=&#34;jeep&#34;&gt;Jeep&lt;/h4&gt;

&lt;p&gt;Of the two models where we have relevant driver-side small overlap test scores for unmodified models, one scored Marginal and one scored Poor.&lt;/p&gt;

&lt;p&gt;There&#39;s one model where we only have test score after modifications; that model has changes to its airbags and seatbelts and it scored Marginal after the changes. This model was also later tested on the passenger-side small overlap test and scored Poor.&lt;/p&gt;

&lt;p&gt;One other model has a relevant passenger-side small overlap test score; it scored Good.&lt;/p&gt;

&lt;h4 id=&#34;volkswagen&#34;&gt;Volkswagen&lt;/h4&gt;

&lt;p&gt;The two models where we have relevant driver-side small overlap test scores for unmodified models both scored Marginal.&lt;/p&gt;

&lt;p&gt;Of the two models where we only have scores after modifications, one was modified 2013 and scored Marginal after modifications. It was then modified again in 2015 and scored Good after modifications. That model was later tested on the passenger side small-overlap test, where it scored Acceptable, indicating that the modifications differentially favored the driver&#39;s side. The other scored Acceptable after changes made in 2015 and then scored Good after further changes made in 2016. The 2016 model was later tested on the passenger-side small overlap test and scored Marginal, once again indicating that changes differentially favored the driver&#39;s side.&lt;/p&gt;

&lt;p&gt;We have passenger-side small overlap test for two other models, both of which scored Acceptable. These were models introduced in 2015 (well after the introduction of the driver-side small overlap test) and scored Good on the driver-side small overlap test.&lt;/p&gt;

&lt;h3 id=&#34;2021-update&#34;&gt;2021 update&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.iihs.org/news/detail/small-suvs-struggle-in-new-tougher-side-test&#34;&gt;The IIHS has released the first set of results for their new &amp;quot;upgraded&amp;quot; side-impact tests&lt;/a&gt;. They&#39;ve been making noises about doing this for quite and have mentioned that in real-world data on (some) bad crashes, they&#39;ve observed intrusion into the cabin that&#39;s significantly greater than is seen on their tests. They&#39;ve mentioned that some vehicles do relatively well on on the new tests and some less well but haven&#39;t released official scores until now.&lt;/p&gt;

&lt;p&gt;The results in the new side-impact tests are different from the results described in the posts above. So far, only small SUVs have had their results released and only the Mazda CX-5 has a result of &amp;quot;Good&amp;quot;. Of the three manufacturers that did well on the tests describe in this post, only Volvo has public results and they scored &amp;quot;Acceptable&amp;quot;. Some questions I have are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Will Volvo score better for their other vehicles (most of their vehicles are built on a different platform from the vehicle that has public results)?&lt;/li&gt;
&lt;li&gt;Will Volvo quickly update their vehicles to achieve the highest score on the test? Unlike a lot of other manufacturers, we don&#39;t have recent data from Volvo on how they responded to something like this because they didn&#39;t need to update their vehicles to achieve the highest score on the last two new tests&lt;/li&gt;
&lt;li&gt;Will BMW and Mercedes either score well and the new test or quickly update their vehicles to score well once again?&lt;/li&gt;
&lt;li&gt;Will other Mazda vehicles also score well without updates?&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;appendix-miscellania&#34;&gt;Appendix: miscellania&lt;/h3&gt;

&lt;p&gt;A number of name brand car makes weren&#39;t included. Some because they have relatively low sales in the U.S. are low and/or declining rapidly (Mitsubishi, Fiat, Alfa Romeo, etc.), some because there&#39;s very high overlap in what vehicles are tested (Kia, Mazda, Audi), and some because there aren&#39;t relevant models with driver-side small overlap test scores (Lexus). When a corporation owns an umbrella of makes, like FCA with Jeep, Dodge, Chrysler, Ram, etc., these weren&#39;t pooled since most people who aren&#39;t car nerds aren&#39;t going to recognize FCA, but may recognize Jeep, Dodge, and Chrysler.&lt;/p&gt;

&lt;p&gt;If the terms of service of the API allowed you to use IIHS data however you wanted, I would&#39;ve included smaller makes, but since the API comes with very restrictive terms on how you can display or discuss the data which aren&#39;t compatible with exploratory data analysis and I couldn&#39;t know how I would want to display or discuss the data before looking at the data, I pulled all of these results by hand (and didn&#39;t click through any EULAs, etc.), which was fairly time consuming, so there was a trade-off between more comprehensive coverage and the rest of my life.&lt;/p&gt;

&lt;h3 id=&#34;appendix-what-car-should-i-buy&#34;&gt;Appendix: what car should I buy?&lt;/h3&gt;

&lt;p&gt;That depends on what you&#39;re looking for, there&#39;s no way to make a blanket recommendation. For practical information about particular vehicles, &lt;a href=&#34;https://www.youtube.com/user/TTACVideo&#34;&gt;Alex on Autos&lt;/a&gt; is the best source that I know of. I don&#39;t generally like videos as a source of practical information, but car magazines tend to be much less informative than youtube car reviewers. There are car reviewers that are much more popular, but their popularity appears to come from having witty banter between charismatic co-hosts or other things that not only aren&#39;t directly related to providing information, they actually detract from providing information. If you just want to know about how cars work, &lt;a href=&#34;https://www.youtube.com/user/EngineeringExplained&#34;&gt;Engineering Explained&lt;/a&gt; is also quite good, but the information there is generally practical.&lt;/p&gt;

&lt;p&gt;For reliability information, Consumer Reports is probably your best bet (you can also look at J.D. Power, but the way they aggregate information makes it much less useful to consumers).&lt;/p&gt;

&lt;p&gt;&lt;small&gt;Thanks to Leah Hanson, Travis Downs, Prabin Paudel, Jeshua Smith, and Justin Blank for comments/corrections/discussion&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;link rel=&#34;prefetch&#34; href=&#34;https://danluu.com/&#34;&gt;
&lt;link rel=&#34;prefetch&#34; href=&#34;https://danluu.com/about/&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:F&#34;&gt;this includes the 2004-2012 Volvo S40/V50, 2006-2013 Volvo C70, and 2007-2013 Volvo C30, which were designed during the period when Ford owned Volvo. Although the C1 platform was a joint venture between Ford, Volvo, and Mazda engineers, the work was done under a Ford VP at a Ford facility.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:F&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:A&#34;&gt;&lt;p&gt;to be fair, as we saw with the IIHS small overlap tests, not every manufacturer did terribly. In 2017 and 2018, 8 vehicles sold in Africa were crash tested. One got what we would consider a mediocre to bad score in the U.S. or Europe, five got what we would consider to be a bad score, and &amp;quot;only&amp;quot; three got what we would consider to be an atrocious score. The Nissan NP300, Datsun Go, and Cherry QQ3 were the three vehicles that scored the worst. Datsun is a sub-brand of Nissan and Cherry is a Chinese brand, also known as Qirui.&lt;/p&gt;

&lt;p&gt;We see the same thing if we look at cars sold in India. Recently, some tests have been run on cars sent to the Indian market and a number of vehicles from Datsun, Renault, Chevrolet, Tata, Honda, Hyundai, Suzuki, Mahindra, and Volkswagen came in with atrocious scores that would be considered impossibly bad in the U.S. or Europe.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:A&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Finding the Story</title>
      <link>https://danluu.com/voyager-story/</link>
      <pubDate>Tue, 02 Jun 2020 00:05:34 -0700</pubDate>
      
      <guid>https://danluu.com/voyager-story/</guid>
      <description>&lt;p&gt;&lt;em&gt;This is an archive of an old pseudonymously written post from the 90s from someone whose former pseudonym seems to have disappeared from the internet.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I see that &lt;cite&gt;Star Trek: Voyager&lt;/cite&gt; has added a new character, a Borg.
(From the photos, I also see that they&#39;re still breeding women for breast size
in the 24th century.) What ticked me off was the producer&#39;s comment (I&#39;m
paraphrasing), &amp;quot;The addition of Seven of Nine will give us limitless
story possibilities.&amp;quot;&lt;/p&gt;

&lt;p&gt;Uh-huh. Riiiiiight.&lt;/p&gt;

&lt;p&gt;Look, they did&#39;t recognize the stories they &lt;i&gt;had&lt;/i&gt;.
I watched the first few episodes of &lt;cite&gt;Voyager&lt;/cite&gt;
and quit when my bullshit meter when off the scale.
(Maybe that&#39;s not fair, to judge them by only a few episodes.
But it&#39;s not fair to subject me to crap like the holographic lungs, either.)&lt;/p&gt;

&lt;p&gt;For those of you who don&#39;t watch &lt;cite&gt;Star Trek: Voyager&lt;/cite&gt;,
the premise is that the &lt;i&gt;Voyager&lt;/i&gt;, sort of a space corvette,
gets transported umpteen zillions of light years from where it should be.
It will take over seventy years at top speed for them to get home to their
loved ones.
For reasons we needn&#39;t go into here,
the crew consists of a mix of loyal Federation members and rebels.&lt;/p&gt;

&lt;p&gt;On paper, this looks good. There&#39;s an uneasy alliance in the crew,
there&#39;s exploration as they try to get home, there&#39;s the whole &amp;quot;island
in space&amp;quot; routine. And the &lt;cite&gt;Voyager&lt;/cite&gt; is nowhere near as big as the
Enterprise -- it&#39;s not mentally healthy for people to stay aboard for
that long.&lt;/p&gt;

&lt;p&gt;But can this idea actually sustain a whole series?  Would it be
interesting to watch five years of &amp;quot;the crew bickers&amp;quot; or &amp;quot;they find a
new clue to faster interstellar travel but it falls through&amp;quot;?  I don&#39;t
think so.&lt;/p&gt;

&lt;p&gt;(And, in fact, the crew settled down &lt;i&gt;awfully&lt;/i&gt; quickly.)&lt;/p&gt;

&lt;p&gt;The demands of series television subvert the premise.  The basic demand
of series television is that our regular characters are people we come
to know and to care about -- we want them to come into our living rooms
every week.  We must care about their changes, their needs, their
desires.  We must worry when they&#39;re put in jeopardy.  But we know it&#39;s a
series, so it&#39;s hard to make us worry.  We know that the characters will
be back next week.&lt;/p&gt;

&lt;p&gt;The demands of a &lt;i&gt;story&lt;/i&gt; require someone to &lt;i&gt;change&lt;/i&gt; of their own
accord, to recognize some difference.  The need to change can be imposed
from without, but the actual change must be self-motivated. (This is the
fundamental paradox of series television: the only character allowed to
change is a guest, but the instrument of that change has to be a series
regular, therefore depriving both characters of the chance to do
something interesting.)&lt;/p&gt;

&lt;p&gt;Series with strict continuity of episodes (episode 2 must follow episode
1) allow change -- but they&#39;re harder to sell in syndication after the
show goes off the air. Economics favour unchanging regular characters.&lt;/p&gt;

&lt;p&gt;Some series -- such as Hill Street Blues -- get around the jeopardy
problem by actually making characters disposable.  Some characters show
up for a few episodes and then die, reminding us that it could happen to
the regulars, too.  Sometimes it does happen to the regulars.&lt;/p&gt;

&lt;p&gt;(When the characters change in the pilot, there may be a problem.  A
writer who was approached to work on Mary Tyler Moore&#39;s last series saw
from the premise that it would be brilliant for six episodes and then
had noplace to go.  The first Fox series starring Tea Leoni,
&lt;cite&gt;Flying Blind&lt;/cite&gt;, had a very funny pilot and set up an untenable
situation.)&lt;/p&gt;

&lt;p&gt;I&#39;m told the only interesting character on &lt;cite&gt;Voyager&lt;/cite&gt;
has been the doctor, who can change.
He&#39;s the only character allowed to grow.&lt;/p&gt;

&lt;p&gt;The first problem with Voyager, then, is that characters aren&#39;t allowed
to change -- or the change is imposed from outside.
(By the way, an imposed change is a great way to &lt;i&gt;start&lt;/i&gt; a story.
The character then
fights it, and that&#39;s interesting. It&#39;s a terrible way to &lt;i&gt;end&lt;/i&gt; a story.)&lt;/p&gt;

&lt;p&gt;The second problem is that they don&#39;t make use of the elements they
have. Let&#39;s go back to the first season. There was an episode in which
there&#39;s a traitor on board who is as smart as Janeway herself. (How
psychiatric testing missed this, I don&#39;t know, but the Trek universe has
never had really good luck with psychiatry.) After leading Janeway by
the nose for fifty minutes, she figures out who it is, and
confronts him. He says yes -- &lt;i&gt;and beams off the ship&lt;/i&gt;, having
conveniently made a deal with the locals.&lt;/p&gt;

&lt;p&gt;Perfect for series television. We&#39;ve got a supposedly intelligent villain
out there who could come back and Janeway&#39;s been given a run for her money
-- except that I felt cheated. Where&#39;s the story? Where&#39;s the resolution?&lt;/p&gt;

&lt;p&gt;Here&#39;s what I think they should have done. It&#39;s not traditional series
television, but I think it would have been better stories.&lt;/p&gt;

&lt;p&gt;First of all, the episode ends when Janeway confronts the bad guy and
arrests him. He&#39;s put in the brig -- &lt;i&gt;and stays there&lt;/i&gt;. The viewer gets
some sense of victory here.&lt;/p&gt;

&lt;p&gt;But now there&#39;s someone as smart as Janeway in the brig. Suddenly we&#39;ve
set up &lt;cite&gt;Silence of the Lambs&lt;/cite&gt;.
(I don&#39;t mind stealing if I steal from good sources.)
Whenever a problem is &lt;i&gt;big enough&lt;/i&gt;,
Janeway has this option: she can go to the brig and try and make a deal
with the bad guy. &amp;quot;The ship dies, you die.&amp;quot; Not only that, here&#39;s someone
on board ship with whom she has a unique relationship -- one not formally
bounded by rank. What does the bad guy really want?&lt;/p&gt;

&lt;p&gt;And whenever Janeway&#39;s feeling low, he can taunt her.  &amp;quot;By the way, I
thought of a way to get everyone home in one-tenth the time.  Have you,
Captain?&amp;quot;&lt;/p&gt;

&lt;p&gt;You wouldn&#39;t put him in every episode.  But any time you need that extra
push, he&#39;s there.  Remember, we can have him escape any time we want,
through the same sleight used in the original episode.&lt;/p&gt;

&lt;p&gt;Furthermore, it&#39;s one thing to catch him;
it&#39;s another thing to keep him there.
You can generate another entire episode
out of an escape attempt by the prisoner. But that would be an
intermediate thing. Let&#39;s talk about the finish I would have liked to
have seen.&lt;/p&gt;

&lt;p&gt;Let&#39;s invent a crisis.  The balonium generator explodes; we&#39;re deep
in warp space; our crack engineering crew has jury-rigged a repair to
the sensors and found a Class M planet that might do for the repairs.
Except it&#39;s just too far away.  The margin is tight -- but can&#39;t be
done.  There are two too many people on board ship.  Each requires a
certain amount of food, air, water, etc.  Under pressure, Neelix admits
that his people can go into suspended animation, so he does.  The doctor
tries heroically but the engineer who was tending the balonium generator
dies.  (Hmmm.  Power&#39;s low.  The doctor can only be revived at certain
critical moments.) Looks good -- but they were using air until they
died; one more crew member &lt;i&gt;must&lt;/i&gt; die for the rest to live.&lt;/p&gt;

&lt;p&gt;And somebody remembers the guy in the brig. &amp;quot;The question of his guilt,&amp;quot;
says Tuvok, &amp;quot;is resolved. The authority of the Captain is absolute. You
are within your rights to hold a summary court martial and sentence him
to death.&amp;quot;&lt;/p&gt;

&lt;p&gt;And Janeway says no. &amp;quot;The Federation doesn&#39;t do that.&amp;quot;&lt;/p&gt;

&lt;p&gt;Except that everyone will die if she doesn&#39;t.  The pressure is on
Janeway, now.  Janeway being Janeway, she&#39;s looking for a technological
fix.  &amp;quot;Find an answer, dammit!&amp;quot; And the deadline is coming up.  After a
certain point, the prisoner has to die, along with someone else.&lt;/p&gt;

&lt;p&gt;A crewmember volunteers to die (a regular).  Before Janeway can accept,
yet another (regular) crewmember volunteers, and Janeway is forced to
decide.  -- And Tuvok points out that while morally it&#39;s defensible if
that member volunteered to die, the ship cannot continue without either
of those crewmembers.
It &lt;i&gt;can&lt;/i&gt; continue without the prisoner.  Clearly the
prisoner is not worth as much as those crewmembers, but she is the
captain.  She &lt;i&gt;must&lt;/i&gt; make this decision.&lt;/p&gt;

&lt;p&gt;Our fearless engineering crew thinks they might have a solution, but it
will use nearly everything they&#39;ve got, and they need another six hours
to work on the feasibility.  Someone in the crew tries to resolve the
problem for her by offing the prisoner -- the failure uses up more
valuable power.  Now the deadline moves up closer, past the six hours
deadline.  The engineering crew&#39;s idea is no longer feasible.&lt;/p&gt;

&lt;p&gt;For his part, the prisoner is now bargaining. He says he&#39;s got
ideas to help. Does he? He&#39;s tried to destroy the ship before. And he
won&#39;t reveal them until he gets a full pardon.&lt;/p&gt;

&lt;p&gt;(This is all basic plotting: keep piling on difficulties. Put a carrot in
front of the characters, keep jerking it away.)&lt;/p&gt;

&lt;p&gt;The tricky part is the ending.
It&#39;s a requirement that the ending derive logically
from what has gone before.  If you&#39;re going to invoke a technological
fix, you have to set the groundwork for it in the first half of the
show.  Otherwise it&#39;s technobabble.  It&#39;s deus ex machina.  (Any time
someone says just after the last commercial break, &amp;quot;Of course!  If we
vorpalize the antibogon flow, we&#39;re okay!&amp;quot; I want to smack a writer in
the head.)&lt;/p&gt;

&lt;p&gt;Given the situation set up here, we have three possible endings:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Some member of the crew tries to solve the problem by sacrificing
themselves. (Remember, McCoy and Spock did this.) This is a weak
solution (unless Janeway does it) because it takes the focus off
Janeway&#39;s decision.&lt;/li&gt;
&lt;li&gt;Janeway strikes a deal with the prisoner, and together they come up with
a solution (which doesn&#39;t involve the antibogon flow). This has the
interesting repercussions of granting the prisoner his freedom --
while everyone else on ship hates his guts. Grist for another episode,
anyway.&lt;/li&gt;
&lt;li&gt;Janeway kills the prisoner but refuses to hold the court martial.
She may luck out -- the prisoner might survive; that million-to-one-shot
they&#39;ve been praying for but couldn&#39;t rely on comes through -- but she
has decided to kill the prisoner rather than her crew.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;My preferred ending is the third one,
even though the prisoner need not die.
The decision we&#39;ve set up is a difficult one,
and it is meaningful. It is a command decision.
Whether she ends up killing the prisoner is not relevant; what is
relevant is that she &lt;i&gt;decides&lt;/i&gt; to do it.&lt;/p&gt;

&lt;p&gt;John Gallishaw once categorized all stories as either stories of
&lt;i&gt;achievement&lt;/i&gt; or of &lt;i&gt;decision&lt;/i&gt;.
A decision story is much harder to
write, because both choices have to matter.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>`;

export default { rss, sitemap };
